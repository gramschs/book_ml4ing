{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd546e97",
   "metadata": {},
   "source": [
    "# Übung\n",
    "\n",
    "```{admonition} Aufgabe 11.1\n",
    ":class: tip\n",
    "\n",
    "Auf der Internetseite\n",
    "https://archive.ics.uci.edu/dataset/151/connectionist+bench+sonar+mines+vs+rocks\n",
    "finden Sie einen Datensatz mit Sonarsignalen. Die Muster der Signals sind durch\n",
    "60 Zahlenwerte codiert (es handelt sich um die Energie zu bestimmten\n",
    "Frequenzen). Darüber hinaus wird angegeben, ob das Sonarsignal Gestein (= Stein)\n",
    "oder Metall detektiert hat.\n",
    "\n",
    "Laden Sie nun die Datei 'metall_oder_stein.csv'. Führen Sie eine explorative\n",
    "Datenanalyse durch. Lassen Sie dann alle Ihnen bekannten Klassifikations-Modelle\n",
    "trainieren und validieren, um die Materialeigenschaft Stein/Metall auf Basis der\n",
    "numerischen Werte zu prognostizieren.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung \n",
    ":class: tip, toggle\n",
    "\n",
    "Import der Daten (es gibt keine Spaltenüberschriften, daher wird das optionale Argument 'header=None' gesetzt):\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('metall_oder_stein.csv', header=None, skiprows=2)\n",
    "data.info()\n",
    "```\n",
    "\n",
    "Blick in die Daten:\n",
    "\n",
    "```python\n",
    "data.head()\n",
    "```\n",
    "\n",
    "Der Datensatz enthält 208 Einträge und 61 Eigenschaften. Die ersten 60\n",
    "Eigenschaften werden durch Floats repräsentiert, die Eigenschaft '60' wird durch\n",
    "Objekte repräsentiert. \n",
    "\n",
    "Allerdings ist die Ausgabe beschränkt, so dass wir nicht mehr ablesen können, ob\n",
    "alle Einträge gefüllt sind. Wir nutzen daher die Methode '.isnull()', um\n",
    "NA-Werte aufzuspüren. Die Methode liefert Booleans zurück. Wir summieren über\n",
    "das Ergebnis spaltenweise (False = 0, True = 1).\n",
    "\n",
    "```python\n",
    "anzahl_ungueltige_eintraege = data.isnull().sum()\n",
    "anzahl_ungueltige_eintraege.describe()\n",
    "```\n",
    "\n",
    "Offensichtlich sind alle Spalten in der Summe 0, bestehen also nur aus False.\n",
    "Daher sind alle Einträge gültig.\n",
    "\n",
    "Als nächstes untersuchen wir, welche Einträge in der 61. Spalte, also\n",
    "Eigenschaft 60 enthalten sind.\n",
    "\n",
    "```python\n",
    "data[60].unique()\n",
    "```\n",
    "\n",
    "Die letzte Spalte enthält nur zwei verschiedene String-Werte: Stein oder Metall.\n",
    "\n",
    "```python\n",
    "data.describe()\n",
    "```\n",
    "\n",
    "Die statistischen Kennzahlen lassen sich so kaum interpretieren. Daher hilft hier ein Boxplot.\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(data.loc[:, 0:59], \n",
    "             title='Stein oder Metall',\n",
    "             labels={'variable': 'Eigenschaft', 'value':'Wert'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Die Median-Werte scheinen einem Muster zu folgen. Beginnend bei Eigenschaft 0 steigen sie bis zu Eigenschaft 25, wo der Median den Wert 0.7545 erreicht, um dann wieder abzufallen. Ab Eigenschaft 49 liegt der Median unter 0.0179. Bei Eigenschaften mit einem größeren Median ist auch der Interquartilsabstand größer, dafür gibt es keine Ausreißer. Das Maximum scheint bei 1 zu liegen, wobei man das noch genauer untersuchen müsste. \n",
    "\n",
    "Als nächstes schauen wir uns, wie die Zielgröße verteilt ist.\n",
    "\n",
    "```python\n",
    "fig = px.bar(data[60].value_counts(),\n",
    "             title='Stein oder Metall',\n",
    "             labels={'index': 'Material', 'value': 'Anzahl', 'variable': 'Eigenschaft'})\n",
    "\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Die beiden Materialen sind ungefähr gleich verteilt, 53 % der untersuchten\n",
    "Proben sind Metall, 47 % sind Stein.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.loc[:,0 : 59]\n",
    "y = data.loc[:, 60]\n",
    "y.replace('Stein', 0, inplace=True)\n",
    "y.replace('Metall', 1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "```\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "\n",
    "model_perceptron = Perceptron()\n",
    "model_perceptron.fit(X_train, y_train)\n",
    "score_perceptron_train = model_perceptron.score(X_train, y_train)\n",
    "score_perceptron_test = model_perceptron.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten Perzeptron: {score_perceptron_train :.2f}')\n",
    "print(f'Score Testdaten Perzeptron: {score_perceptron_test :.2f}')\n",
    "\n",
    "model_log_reg = LogisticRegression()\n",
    "model_log_reg.fit(X_train, y_train)\n",
    "score_log_reg_train = model_log_reg.score(X_train, y_train)\n",
    "score_log_reg_test = model_log_reg.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten logistische Regression: {score_log_reg_train :.2f}')\n",
    "print(f'Score Testdaten logistische Regression: {score_log_reg_test :.2f}')\n",
    "```\n",
    "\n",
    "```python\n",
    "from sklearn.svm  import SVC\n",
    "\n",
    "model_svm_linear = SVC(kernel='linear')\n",
    "model_svm_linear.fit(X_train, y_train)\n",
    "score_svm_linear_train = model_svm_linear.score(X_train, y_train)\n",
    "score_svm_linear_test = model_svm_linear.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten lineare SVM: {score_svm_linear_train :.2f}')\n",
    "print(f'Score Testdaten lineare SVM: {score_svm_linear_test :.2f}')\n",
    "\n",
    "model_svm_rbf = SVC(kernel='rbf')\n",
    "model_svm_rbf.fit(X_train, y_train)\n",
    "score_svm_rbf_train = model_svm_rbf.score(X_train, y_train)\n",
    "score_svm_rbf_test = model_svm_rbf.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten RBF SVM: {score_svm_rbf_train :.2f}')\n",
    "print(f'Score Testdaten RBF SVM: {score_svm_rbf_test :.2f}')\n",
    "```\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_decision_tree = DecisionTreeClassifier()\n",
    "model_decision_tree.fit(X_train,y_train)\n",
    "\n",
    "score_decision_tree_train = model_decision_tree.score(X_train, y_train)\n",
    "score_decision_tree_test = model_decision_tree.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten Entscheidungsbaum: {score_decision_tree_train :.2f}')\n",
    "print(f'Score Testdaten Entscheidungsbaum: {score_decision_tree_test :.2f}')\n",
    "```\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "list_score_train = []\n",
    "list_score_test = []\n",
    "for n in range(1,101):\n",
    "    model_random_forest = RandomForestClassifier(n_estimators=n, random_state=0)\n",
    "    model_random_forest.fit(X_train, y_train)\n",
    "\n",
    "    score_random_forest_train = model_random_forest.score(X_train, y_train)\n",
    "    score_random_forest_test = model_random_forest.score(X_test, y_test)\n",
    "\n",
    "    print(f'Anzahl Entscheidungsbäume: {n} \\t Score Training: {score_random_forest_train :.2f} | Score Test: {score_random_forest_test :.2f}')\n",
    "\n",
    "    list_score_train.append(score_random_forest_train)\n",
    "    list_score_test.append(score_random_forest_test)\n",
    "\n",
    "score_random_forest = pd.DataFrame({'Trainingsscore': list_score_train, 'Testscore': list_score_test})\n",
    "fig = px.scatter(score_random_forest)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Ab Index 51 scheint sich Trainingsscore und Testscore zu stabilisieren, wir\n",
    "wählen daher 'n_estimators' = 51. Damit hat der Random Forest den höchsten \n",
    "Trainings- und Testscore.\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.7"
   }
  },
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "source_map": [
   12
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}