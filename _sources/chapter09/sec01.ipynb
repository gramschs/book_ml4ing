{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b23f5ad",
   "metadata": {},
   "source": [
    "# 9.1 Stacking, Bagging und Boosting\n",
    "\n",
    "```{admonition} Warnung\n",
    ":class: warning\n",
    "Dieser Abschnitt wird gerade überarbeitet.\n",
    "```\n",
    "\n",
    "```{admonition} Lernziele\n",
    ":class: goals\n",
    "* Sie können in eigenen Worten erklären, was **Ensemble-Methoden** sind.\n",
    "* Sie können die drei Ensemble-Methoden\n",
    "  * **Stacking**,\n",
    "  * **Bagging** und \n",
    "  * **Boosting**\n",
    "\n",
    "  mit Hilfe einer Skizze erklären.\n",
    "```\n",
    "\n",
    "## Ensemble-Methoden\n",
    "\n",
    "Der Begriff »Ensemble« wird im Allgemeinen eher mit Musik und Kunst in\n",
    "Verbindung gebracht als mit Informatik. In der Musik bezeichnet ein Ensemble\n",
    "eine kleine Gruppe von Musikern, die entweder das gleiche Instrument spielen\n",
    "oder verschiedene Instrumente kombinieren. Im Theater bezeichnet man eine Gruppe\n",
    "von Schauspielern ebenfalls als Ensemble, und in der Architektur beschreibt der\n",
    "Begriff eine Gruppe von Gebäuden, die in einem besonderen Zusammenhang\n",
    "zueinander stehen.   \n",
    "\n",
    "Auch im Bereich des maschinellen Lernens hat sich der Begriff Ensemble\n",
    "etabliert. Mit **Ensemble-Methoden** (Ensemble Learning) wird eine Gruppe von\n",
    "maschinellen Modellen bezeichnet, die zusammen eine Prognose treffen sollen.\n",
    "Ähnlich wie bei Musik-Ensembles können beim **Ensemble Learning** entweder\n",
    "identische Modelle oder verschiedene Modelle kombiniert werden. Diese Modelle\n",
    "können entweder gleichzeitig eine Prognose treffen, die dann kombiniert wird,\n",
    "oder nacheinander verwendet werden, wobei ein Modell auf den Ergebnissen eines\n",
    "anderen aufbaut. Je nach Vorgehensweise unterscheidet man im maschinellen Lernen\n",
    "zwischen **Stacking**, **Bagging** und **Boosting**.\n",
    "\n",
    "In dieser Vorlesung konzentrieren wir uns auf Bagging und Boosting mit ihren\n",
    "bekanntesten Vertretern, den Random Forests und XGBoost. Das Konzept des\n",
    "Stackings wird hier nur kurz ohne weitere Details vorgestellt. Eine allgemeine\n",
    "Einführung in Ensemble-Methoden mit Scikit-Learn findet sich in der\n",
    "[Dokumentation Scikit-Learn →\n",
    "Ensemble](https://scikit-learn.org/stable/modules/ensemble.html).\n",
    "\n",
    "\n",
    "## Stacking\n",
    "\n",
    "```{figure} pics/concept_stacking.svg\n",
    "---\n",
    "width: 100%\n",
    "---\n",
    "Die Prognosen von mehreren *unterschiedlichen* ML-Modellen werden zu einer\n",
    "finalen Prognose kombiniert. Die Kombination kann beispielsweise durch\n",
    "Mehrheitsentscheidung (Voting) oder Mittelwertbildung (Averaging) erfolgen.\n",
    "Werden die Einzelprognosen durch ein weiteres ML-Modell zu einer finalen\n",
    "Prognose kombiniert, nennt man das *Stacking*.\n",
    "```\n",
    "\n",
    "Stacking bedeutet auf Deutsch »Stapeln«, es werden sozusagen verschiedene\n",
    "ML-Modelle gestapelt. In einem ersten Schritt werden mehrere ML-Modelle\n",
    "unabhängig voneinander auf den Trainingsdaten trainiert. Jedes dieser Modelle\n",
    "liefert eine Prognose, die dann auf verschiedene Arten miteinander kombiniert\n",
    "werden können. Bei Klassifikationsaufgaben ist **Voting**, also die Wahl durch\n",
    "**Mehrheitsentscheidung**, eine beliebte Methode, um die Einzelprognosen zu\n",
    "kombinieren. Wurden beispielsweie für das Stacking drei ML-Modellen gewählt, die\n",
    "jeweils ja oder nein prognostizieren, dann wird für die finale Prognose das\n",
    "Ergebnis genommen, das die Mehrheit der einzelnen Modelle vorausgesagt hat.\n",
    "Scikit-Learn bietet dafür einen Voting Classifier an, siehe [Dokumentation\n",
    "Scikit-Learn → Voting\n",
    "Classifier](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier). \n",
    "\n",
    "Bei Regressionsaufgaben werden die einzelnen Prognosen häufig gemittelt. Dabei\n",
    "kann entweder der übliche arithmetische Mittelwert verwendet werden oder ein\n",
    "**gewichteter Mittelwert**, was als  **Weighted Averaging** bezeichnet wird.\n",
    "Nichtsdestotrotz wird die Mittelwertbildung bei Regressionsaufgaben von\n",
    "Scikit-Learn ebenfalls als Voting bezeichnet, siehe [Dokumentation Scikit-Learn\n",
    "→ Voting\n",
    "Regressor](https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor). \n",
    "\n",
    "Eine alternative Kombinationsmethode ist die Verwendung eines weiteren\n",
    "ML-Modells. In diesem Fall werden die Modelle, die die einzelnen Prognosen\n",
    "liefern, als Basismodelle bezeichnet. In der ML-Community ist auch der\n",
    "Fachbegriff **Weak Learner**, also schwache Lerner, für diese Basismodelle\n",
    "gebräuchlich. Die Prognosen der Basismodelle dienen dann als Trainingsdaten für\n",
    "ein weiteres ML-Modell, das als **Meta-Modell** bezeichnet wird. Diese\n",
    "Ensemble-Methode wird **Stacking** genannt. Weitere Informationen liefert die\n",
    "[Scikit-Learn Dokumentation → Stacked\n",
    "Generalization](https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization).\n",
    "\n",
    "Stacking bietet viele Vorteile. Der wichtigste Vorteil ist, dass die\n",
    "Prognosefähigkeit des Gesamtmodells in der Regel deutlich besser ist als die der\n",
    "einzelnen Basismodelle. Die Stärken der Basismodelle werden kombiniert und die\n",
    "Schwächen ausgeglichen. Allerdings erfordert Stacking sehr viel Feinarbeit. Auch\n",
    "steigt die Trainingszeit für das Gesamtmodell, selbst wenn die Basismodelle bei\n",
    "genügend Rechenleistung parallel trainiert werden können. Aus diesem Grund\n",
    "werden wir in dieser Vorlesung kein Stacking verwenden.\n",
    "\n",
    "\n",
    "## Bagging\n",
    "\n",
    "TODO\n",
    "\n",
    "Es gibt verschiedene Methoden, mit denen die Trainingsdaten beim Training eines\n",
    "Random Forests zufällig ausgewählt werden können:\n",
    "\n",
    "1. **Bootstrapping**: Dies ist die gängigste Methode zur Auswahl der\n",
    "Trainingsdaten für jeden Entscheidungsbaum in einem Random Forest. Dabei werden\n",
    "einzelne Datenpunkte aus der Menge der Trainignsdaten zufällig ausgewählt,\n",
    "jedoch sofort wieder zurückgelegt. Dadurch können Datenpunkte auch mehrfach\n",
    "auftauchen, während andere Datenpunkte vielleicht gar nicht zum Training des\n",
    "Entscheidungsbaumes genutzt werden.\n",
    "\n",
    "2. **Stratifiziertes Sampling**: Bei dieser Methode werden die Trainingsdaten\n",
    "anhand eines Kriteriums in verschiedene \"Schichten\" eingeteilt, aus denen dann\n",
    "zufällig eine Teilmenge von Beispielen ausgewählt wird. Dies kann nützlich sein,\n",
    "wenn die Trainingsdaten unausgewogen sind, d. h. es gibt deutlich mehr Beispiele\n",
    "für eine Klasse als für die andere. Das Stratified Sampling kann dazu beitragen,\n",
    "dass jeder Baum im Random Forest auf einer repräsentativen Stichprobe der Daten\n",
    "trainiert wird.\n",
    "\n",
    "3. **Cluster-Stichproben**: Bei dieser Methode werden die Trainingsdaten in\n",
    "separate Cluster unterteilt und dann eine Teilmenge der Cluster zufällig\n",
    "ausgewählt, die für das Training verwendet wird. Dies kann nützlich sein, wenn\n",
    "die Trainingsdaten auf natürliche Weise in verschiedene Cluster unterteilt sind\n",
    "und Sie sicherstellen möchten, dass jeder Baum im Random Forest auf einer\n",
    "repräsentativen Stichprobe der Daten trainiert wird.\n",
    "\n",
    "Es gibt auch andere Methoden, die zur zufälligen Auswahl der Trainingsdaten\n",
    "verwendet werden können, wie z. B. das systematische Sampling, bei dem Beispiele\n",
    "in regelmäßigen Abständen aus dem Trainingssatz ausgewählt werden, und das\n",
    "einfache Zufallsstichprobenverfahren, bei dem Beispiele ohne Ersetzung zufällig\n",
    "ausgewählt werden. Die Wahl der Methode hängt von den Besonderheiten der Daten\n",
    "und den Zielen des Modells ab.\n",
    "\n",
    "\n",
    "## Boosting\n",
    "\n",
    "TODO\n",
    "\n",
    "\n",
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "source_map": [
   13
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}