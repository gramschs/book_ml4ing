{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb943a8",
   "metadata": {},
   "source": [
    "# 7.1 Theorie der linearen Regression \n",
    "\n",
    "Die lineare Regression gehört zu den überwachten maschinellen Lernverfahren\n",
    "(Supervised Learning). Meist ist sie das erste ML-Modell, das eingesetzt wird,\n",
    "um Regressionsprobleme zu lösen. In diesem Kapitel stellen wir die theoretischen\n",
    "Grundlagen der linearen Regression vor.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "```{admonition} Lernziele\n",
    ":class: goals\n",
    "* Sie kennen das **lineare Regressionsmodell**.\n",
    "* Sie können erklären, was die **Fehlerquadratsumme** ist.\n",
    "* Sie wissen, dass das Training des lineare Regressionsmodells durch die\n",
    "  **Minimierung** der Fehlerquadratsumme (Kleinste-Quadrate-Schätzer) erfolgt.\n",
    "* Sie können mit dem **Bestimmtheitsmaß** bzw. **R²-Score** beurteilen, ob das\n",
    "  lineare Regressionsmodell geeignet zur Erklärung der Daten ist.\n",
    "```\n",
    "\n",
    "\n",
    "## Regression kommt aus der Statistik\n",
    "\n",
    "In der Statistik beschäftigen sich Mathematikerinnen und Mathematiker bereits\n",
    "seit Jahrhunderten damit, Analyseverfahren zu entwickeln, mit denen\n",
    "experimentelle Daten gut erklärt werden können. Falls wir eine “erklärende”\n",
    "Variable haben und wir versuchen, die Abhängigkeit einer Messgröße von der\n",
    "erklärenden Variable zu beschreiben, nennen wir das Regressionsanalyse oder kurz\n",
    "**Regression**. Bei vielen Problemen suchen wir nach einem linearen Zusammenhang\n",
    "und sprechen daher von **linearer Regression**. Mehr Details finden Sie auch bei\n",
    "[Wikipedia → Regressionsanalyse](https://de.wikipedia.org/wiki/Regressionsanalyse).\n",
    "\n",
    "Etwas präziser formuliert ist lineare Regression ein Verfahren, bei dem es eine\n",
    "Einflussgröße $x$ und eine Zielgröße $y$ gibt. In der ML-Sprechweise wird die\n",
    "Einflussgröße $x$ typischerweise als Merkmal (oder englisch Feature) bezeichnet.\n",
    "Die Zielgröße (manchmal auch Output oder Target genannt), soll stetig sein\n",
    "(manchmal auch kontinuierlich, metrisch oder quantitativ genannt). Zu dem\n",
    "Merkmal oder den Merkmalen liegen $M$ Datenpunkte mit den dazugehörigen Werte\n",
    "der Zielgröße vor. Diese werden üblicherweise als Paare (wenn nur ein Merkmal\n",
    "vorliegt) zusammengefasst:\n",
    "\n",
    "$$(x^{(1)},y^{(1)}), \\, (x^{(2)},y^{(2)}), \\, \\ldots, \\, (x^{(M)},y^{(M)}).$$ \n",
    "\n",
    "Ziel der linearen Regression ist es, zwei Parameter $w_0$ und $w_1$ so zu\n",
    "bestimmen, dass möglichst für alle Datenpunkte $(x^{(i)}, y^{(i)})$ die lineare\n",
    "Gleichung \n",
    "\n",
    "$$y^{(i)} \\approx w_0 + w_1 x^{(i)}$$\n",
    "\n",
    "gilt. Geometrisch ausgedrückt: durch die Daten soll eine Gerade gelegt werden,\n",
    "wie die folgende Abbildung zeigt. Die Datenpunkte sind blau, die\n",
    "Regressionsgerade ist in rot visualisiert.\n",
    "\n",
    "```{figure} pics/Linear_regression.svg\n",
    "---\n",
    "name: fig_linear_regression\n",
    "---\n",
    "Lineare Regression: die erklärende Variable (= Input oder unabhängige Variable oder Ursache) ist auf der x-Achse, die\n",
    "abhängige Variable (= Output oder Wirkung) ist auf der y-Achse aufgetragen, Paare von Messungen sind in blau\n",
    "gekennzeichnet, das Modell in rot. \n",
    "([Quelle:](https://en.wikipedia.org/wiki/Linear_regression#/media/File:Linear_regression.svg) \"Example of simple linear regression, which has one independent variable\" von Sewaqu. Lizenz: Public domain))\n",
    "```\n",
    "\n",
    "In der Praxis werden die Daten nicht perfekt auf der Geraden liegen. Die Fehler\n",
    "zwischen dem echten $y^{(i)}$ und dem Funktionswert der Gerade $f(x^{(i)}) = w_0 +\n",
    "w_1 x^{(i)}$ werden unterschiedlich groß sein, je nachdem, welche Parameter\n",
    "$w_0$ und $w_1$ gewählt werden. Wie finden wir jetzt die beste Kombination $w_0$\n",
    "und $w_1$, so dass diese Fehler möglichst klein sind?\n",
    "\n",
    "\n",
    "## Wie groß ist der Fehler?\n",
    "\n",
    "Das Prinzip für das lineare Regressionsmodell und auch die folgenden ML-Modelle\n",
    "ist jedesmal gleich. Das Modell ist eine mathematische Funktion, die aber noch\n",
    "Parameter (hier beispielsweise die Koeffizienten der Gerade) enthält. Dann wird\n",
    "festgelegt, was eine gute Prognose ist, also wie Fehler berechnet und beurteilt\n",
    "werden sollen. Das hängt jeweils von dem bettrachteten Problem ab. Sobald das\n",
    "sogenannte Fehlermaß feststeht, werden die Parameter der Modellfunktion so\n",
    "berechnet, dass das Fehlermaß (z.B. Summe der Fehler oder Mittelwert der Fehler)\n",
    "möglichst klein wird. In der Mathematik sagt man dazu **Minimierungsproblem**. \n",
    "\n",
    "Für die lineare Regression wird als Fehlermaß die Kleinste-Quadrate-Schätzung\n",
    "verwendet (siehe [Wikipedia  → Methode der kleinsten\n",
    "Quadrate](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate)). Dazu\n",
    "berechnen wir, wie weit weg die Gerade von den Messpunkten ist. Wie das geht,\n",
    "veranschaulichen wir uns mit der folgenden Grafik.\n",
    "\n",
    "```{figure} pics/kq_regression.png\n",
    "---\n",
    "width: 600px\n",
    "name: kq_regression\n",
    "---\n",
    "Messpunkte (blau) und der Abstand (grün) zu einer Modellfunktion (rot)\n",
    "\n",
    "([Quelle:](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate#/media/Datei:MDKQ1.svg) Autor: Christian Schirm, Lizenz: CC0) \n",
    "```\n",
    "\n",
    "Unsere rote Modellfunktion trifft die Messpunkte mal mehr und mal weniger gut.\n",
    "Wir können jetzt für jeden Messpunkt berechnen, wie weit die rote Kurve von ihm\n",
    "weg ist (= grüne Strecke), indem wir die Differenz der y-Koordinaten errechnen:\n",
    "$r = y_{\\text{blau}}-y_{\\text{rot}}$. Diese Differenz nennt man **Residuum**.\n",
    "Danach summieren wir die Fehler (also die Residuen) auf und erhalten den\n",
    "Gesamtfehler. Leider kann es dabei passieren, dass am Ende als Gesamtfehler 0\n",
    "herauskommt, weil beispielsweise für den 1. Messpunkt die blaue y-Koordinate\n",
    "unter der roten y-Koordinate liegt und damit ein negatives Residuum herauskommt,\n",
    "aber für den 5. Messpunkt ein positives Residuum. Daher quadrieren wir die\n",
    "Residuen. Dann wird diese **Fehlerquadratsumme** minimiert, um die Koeffizienten\n",
    "des Regressionsmodells zu berechnen.\n",
    "\n",
    "\n",
    "## Ist das beste Modell gut genug?\n",
    "\n",
    "Auch wenn wir mit der Minimierung der Fehlerquadratsumme bzw. der\n",
    "Kleinsten-Quadrate-Methode die besten Parameter für unsere Modellfunktion\n",
    "gefunden haben, heißt das noch lange nicht, dass unser Modell gut ist. Bereits\n",
    "die Modellfunktion kann ja völlig falsch gewählt sein. Beispielsweise könnten\n",
    "wir Messungen rund um eine sinus-förmige Wechselspannung vornehmen und dann wäre\n",
    "ein lineares Regressionsmodell völlig ungeeignet, auch wenn die\n",
    "Fehlerquadratsumme minimal wäre.\n",
    "\n",
    "Wir brauchen daher noch ein Kriterium dafür, ob das trainierte Modell auch\n",
    "valide ist. Über die Validierung eines ML-Modells werden wir auch in den\n",
    "nächsten Vorlesungen noch intensiv sprechen. Für die lineare Regression\n",
    "betrachten wir erstmal das **Bestimmtheitsmaß**, das in der ML-Community auch\n",
    "**R²-Score** genannt wird.\n",
    "\n",
    "Beim R²-Score wird zunächst der Mittelwert der Fehlerquadratsumme mit der\n",
    "Modellfunktion $f$ gebildet:\n",
    "\n",
    "$$\\frac{1}{M}\\sum_{i=1}^M (y^{(i)} - f(x^{(i)})^2. $$\n",
    "\n",
    "Danach wird der Mittelwert der Output-Daten gebildet, nämlich\n",
    "\n",
    "$$\\bar{y} = \\frac{1}{M} \\sum_{i=1}^{M} y^{(i)}.$$\n",
    "\n",
    "Nun wird dieser Mittelwert in die Fehlerquadratsumme eingesetzt, als ob die\n",
    "Modellfunktion die konstante Funktion $f(x)=\\bar{y}$ wäre.\n",
    "\n",
    "$$\\frac{1}{M}\\sum_{i=1}^M (y^{(i)} - \\bar{y})^2.$$\n",
    "\n",
    "Diese beiden Fehlerquadratsummen werden nun miteinander ins Verhältnis gesetzt.\n",
    "Wir vergleichen sozusgen den mittleren Fehler bei Wahl der Modellfunktion mit\n",
    "dem mittleren Fehler, wenn wir machen würden, wenn wir einfach nur den\n",
    "Mittelwert als Schätzer für unser Modell nehmen würden. \n",
    "\n",
    "In der Statistik wurde dieses Verhältnis (Gesamtfehler geteilt durch\n",
    "Gesamtfehler Mittelwert) als Qualitätkriterium für ein lineares\n",
    "Regressionsproblem festgelegt. Genaugenommen, rechnet man 1 - Gesamtfehler /\n",
    "(Gesamtfehler Mittelwert) und nennt diese Zahl Bestimmtheitsmaß oder R²-Score.\n",
    "Die Formel zur Berechnung des R²-Scores lautet:\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^M (y^{(i)} - f(x^{(i)}))^2}{\\sum_{i=1}^M(y^{(i)}-\\bar{y})}. $$\n",
    "\n",
    "Dabei kürzt sich das $\\frac{1}{M}$ im Zähler und Nenner weg. Nachdem der\n",
    "R²-Score ausgerechnet wurde, können wir nun die Qualität der Anpassung\n",
    "beurteilen:\n",
    "\n",
    "* Wenn $R^2 = 1$  ist, dann gibt es den perfekten linearen Zusammenhang und die\n",
    "  Modellfunktion ist eine sehr gute Anpassung an die Messdaten.\n",
    "* Wenn $R^2 = 0$ oder gar negativ ist, dann funktioniert die lineare\n",
    "  Modellfunktion überhaupt nicht.\n",
    "\n",
    "\n",
    "## Interaktive Visualisierung R²-Score\n",
    "\n",
    "Auf der Seite [https://mathweb.de](https://mathweb.de) finden Sie eine Reihe von\n",
    "Aufgaben und interaktiven Demonstrationen rund um die Mathematik. Insbesondere\n",
    "gibt es dort auch eine interaktive Demonstration des R²-Scores.\n",
    "\n",
    "Drücken Sie auf den zwei kreisförmigen Pfeile rechts oben. Dadurch wird ein\n",
    "neuer Datensatz erzeugt. Die Messdaten sind durch grüne Punkte dargestellt, das\n",
    "lineare Regressionsmodell durch eine blaue Gerade. Im Titel wird der aktuelle\n",
    "und der optimale R²-Wert angezeigt. Ziehen Sie an den weißen Punkten, um die\n",
    "Gerade zu verändern. Schaffen Sie es, den optimalen R²-Score zu treffen?\n",
    "Beobachten Sie dabei, wie die Fehler (rot) kleiner werden.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://lti.mint-web.de/examples/index.php?id=01010320\"  allowfullscreen>\n",
    "</iframe>\n",
    "\n",
    "\n",
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "In diesem Abschnitt haben Sie das theoretische Modell der linearen Regression\n",
    "kennengelernt. Im nächsten Kapitel trainieren wir ein lineares Regressionsmodell\n",
    "mit Scikit-Learn."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "source_map": [
   13
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}