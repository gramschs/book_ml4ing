{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53dcdbbc",
   "metadata": {},
   "source": [
    "# Übung\n",
    "\n",
    "Der folgende Datensatz enthält die Preise und Eigenschaften von Diamanten. Die\n",
    "Eigenschaften sind:\n",
    "\n",
    "* Karat (Gewicht des Diamanten)\n",
    "* Schliff (Qualität: befriedigend, gut, sehr gut, erstklassig, ideal)\n",
    "* Farbe des Diamanten (von J (schlechteste) bis D (beste))\n",
    "* Reinheit - ein Maß für die Klarheit des Diamanten (I1 (schlechteste), SI2,\n",
    "  SI1, VS2, VS1, VVS2, VVS1, IF (beste))\n",
    "* Tiefe (Gesamttiefe in Prozent = z / Mittelwert (x, y) = 2 * z / (x + y))\n",
    "* Tafel (Breite der Oberseite des Diamanten im Verhältnis zur breitesten Stelle)\n",
    "* Preis (in US-Dollar)\n",
    "* x - Länge in mm\n",
    "* y - Breite in mm\n",
    "* z - Tiefe in mm\n",
    "\n",
    "Bearbeiten Sie die folgenden Aufgaben. Vorab können Sie die folgenden Module\n",
    "importieren. Schreiben Sie Ihre Antworten als Kommentar oder in eine\n",
    "Markdown-Zelle. Lassen Sie das Jupyter Notebook am Ende noch einmal komplett\n",
    "ausführen, bevor Sie es abgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17da2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron\n",
    "# from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "# from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "# from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "# from sklearn.svm  import SVC, SVR\n",
    "# from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3028b",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse\n",
    "\n",
    "```{admonition} Import und Bereinigung der Daten\n",
    ":class: miniexercise\n",
    "Importieren Sie die Daten 'diamonds_DE.csv'. Verschaffen Sie sich einen\n",
    "Überblick und beantworten Sie folgende Fragen in einer Markdown-Zelle:\n",
    "\n",
    "* Wie viele Diamanten enthält die Datei?\n",
    "* Wie viele Merkmale/Attribute/Eigenschaften/Features sind in den Daten enthalten?\n",
    "* Sind alle Einträge gültig? Wenn nein, wie viele Einträge sind nicht gültig?\n",
    "* Welchen Datentyp haben die einzelnen Attribute/Eigenschaften/Features?\n",
    "\n",
    "Falls der Datensatz ungültige Werte aufweist oder Unstimmigkeiten enthält,\n",
    "bereinigen Sie ihn.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, dropdown\n",
    "```python\n",
    "daten = pd.read_csv('diamonds_DE.csv', skiprows=3)\n",
    "daten.info()\n",
    "```\n",
    "\n",
    "```python\n",
    "daten.head()\n",
    "```\n",
    "\n",
    "Der Datensatz enthält 53940 Diamanten mit 11 Attributen/Eigenschaften. Alle\n",
    "Einträge sind gültige Einträge. Die Eigenschaften 'Unnamed: 0' und 'Preis' sind\n",
    "Integers. Die Eigenschaften 'Karat', 'Tiefe', 'Tafel', 'x', 'y' und 'z' sind\n",
    "Floats. Die Eigenschaften 'Schliff', 'Farbe' und 'Reinheit' sind Objekte.\n",
    "\n",
    "Der Datensatz enthält nur gültige Werte, aber sollte dennoch bereinigt werden,\n",
    "da die ersten fünf Zeilen des Datensatzes nahelegen, dass die Eigenschaft\n",
    "'Unnamed: 0' ein Index ist. Wir visualisieren diese Eigeschaft, um die Hypothese\n",
    "zu überprüfen.\n",
    "\n",
    "```python\n",
    "fig = px.scatter(daten, y = 'Unnamed: 0',\n",
    "                 title='Diamanten')\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Tatsächlich stimmen (zumindest visuell) der automatisch erzeugte Index des\n",
    "DataFrame-Objektes und die Werte von 'Unnamed: 0' überein. Die überflüssige\n",
    "Spalte wird gelöscht.\n",
    "\n",
    "```python\n",
    "daten = daten.drop(columns='Unnamed: 0')\n",
    "daten.info()\n",
    "```\n",
    "````\n",
    "\n",
    "```{admonition} Statistische Kennzahlen der numerischen Eigenschaften\n",
    ":class: miniexercise\n",
    "* Ermitteln Sie von den numerischen Eigenschaften die statistischen Kennzahlen\n",
    "  und visualisieren Sie sie. Verwenden Sie beim Plot eine aussagefähige\n",
    "  Beschriftung.\n",
    "* Interpretieren Sie jede Eigenschaft anhand der statistischen Kennzahlen und\n",
    "  der Plots.\n",
    "* Bereinigen Sie bei Ungereimtheiten den Datensatz weiter.\n",
    "* Entfernen Sie Ausreißer.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, dropdown\n",
    "```python\n",
    "numerische_merkmale = ['Karat', 'Tiefe', 'Tafel', 'Preis', 'x', 'y', 'z']\n",
    "daten.describe()\n",
    "```\n",
    "\n",
    "```python\n",
    "fig = px.box(daten, y = numerische_merkmale,\n",
    "             title='Diamanten: numerische Eigenschaften',\n",
    "             labels={'variable': 'Eigenschaft', 'value': 'Wert'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Die Skalen der einzelnen Eigenschaften sind stark verschieden, so dass ein\n",
    "gemeinsamer Boxplot nicht möglich ist. Daher werden die Eigenschaften einzeln\n",
    "oder in vergleichbaren Gruppen sortiert.\n",
    "\n",
    "```python\n",
    "fig = px.box(daten, y = 'Karat',\n",
    "             title='Diamanten')\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "75 % der Diamanten haben ein Karat und weniger, wobei der Median bei 0.7 Karat\n",
    "liegt. Das ist etwas niedriger als der Mittelwert von 0.8 Karat. Der höhere\n",
    "Mittelwert wird sicherlich bedingt durch die vielen Ausreißer nach oben ab 2 bis\n",
    "ca. 5 Karat.\n",
    "\n",
    "Als nächstes werden Tiefe und Tafel untersucht.\n",
    "\n",
    "```python\n",
    "fig = px.box(daten, y = ['Tiefe', 'Tafel'],\n",
    "             title='Diamanten: numerische Eigenschaften',\n",
    "             labels={'variable': 'Eigenschaft', 'value': 'Größe'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "50 % aller Diamanten haben eine Tiefe zwischen 61 % und 62 %. Der Median ist mit\n",
    "61.8 % mittig zwischen Q1 und Q3 und stimmt mit dem Mittelwert 61.7 % überein.\n",
    "Es gibt Ausreißer nach oben und unten.\n",
    "\n",
    "Bei der Breite ist der Median 57 näher am Q1-Wert 56 und und liegt auch etwas\n",
    "unterhalb des Mittelwertes von 57.4.\n",
    "\n",
    "```python\n",
    "fig = px.box(daten, y = ['x', 'y', 'z'],\n",
    "             title='Diamanten: numerische Eigeschaften',\n",
    "             labels={'variable': 'Eigenschaft', 'value': 'Wert'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Der Boxplot sowie die statistischen Kennzahlen der Eigenschaften x, y und z\n",
    "zeigen Ungereimtheiten. Bei allen drei Eigenschaften wird auch der Wert Null\n",
    "angenommen. Das ist unmöglich, daher müssen diese Diamanten aus dem Datensatz\n",
    "entfernt werden.\n",
    "\n",
    "```python\n",
    "daten[ daten['x'] == 0 ] \n",
    "```\n",
    "\n",
    "```python\n",
    "daten[ daten['y'] == 0 ]\n",
    "```\n",
    "\n",
    "```python\n",
    "daten[ daten['z'] == 0 ]\n",
    "```\n",
    "\n",
    "Es ist mühsam, die Indizes (Zeilennummern) abzuschreiben. Daher benutzen wir das\n",
    "Attribut `.index`, um die Indizes direkt der drop()-Methode als Argument zu\n",
    "übergeben.\n",
    "\n",
    "```python\n",
    "zeilen = daten[ daten['x'] == 0 ].index\n",
    "daten = daten.drop(zeilen)\n",
    "\n",
    "zeilen = daten[ daten['y'] == 0 ].index\n",
    "daten = daten.drop(zeilen)\n",
    "\n",
    "zeilen = daten[ daten['z'] == 0 ].index\n",
    "daten = daten.drop(zeilen)\n",
    "\n",
    "daten.info()\n",
    "```\n",
    "\n",
    "Darüber hinaus gibt es bei der Größe in y-Richtung zwei deutliche Ausreißer mit\n",
    "31.8 mm und 58.9 mm. Auch bei der Größe in z-Richtung gibt es einen deutlichen\n",
    "Ausreißer nach oben mit z = 31.8 mm. Diese Diamanten werden ebenfalls entfernt.\n",
    "\n",
    "```python\n",
    "zeilen = daten[ daten['y'] > 31.0 ].index\n",
    "daten = daten.drop(zeilen)\n",
    "\n",
    "zeilen = daten[ daten['z'] > 31.0 ].index\n",
    "daten = daten.drop(zeilen)\n",
    "\n",
    "daten.info()\n",
    "```\n",
    "\n",
    "Somit sind es nur 53917 Einträge von ehemals 53940 Einträgen. Es wurden 23\n",
    "Diamanten entfernt.\n",
    "\n",
    "Zuletzt betrachten wir noch den Preis.\n",
    "\n",
    "```python\n",
    "fig = px.box(daten, y = 'Preis',\n",
    "             title='Diamanten: numerische Eigenschaften')\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Der Median von 2401 US-Dollar liegt nicht mittig zwischen Q1 und Q3 und ist deutlich niedriger als der Mittelwert von 3932 US-Dollar. Die Preise müssen sehr asymmetrisch verteilt sein.\n",
    "\n",
    "```python\n",
    "fig = px.histogram(daten['Preis'],\n",
    "                   title='Histogramm des Diamantenpreises',\n",
    "                   labels={'value':'Preis in US-Dollar', 'count': 'Anzahl'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Die Verteilung der Preise ist rechtsschief (linkssteil).\n",
    "````\n",
    "\n",
    "```{admonition} Statistische Kennzahlen (kategoriale Eigenschaften)\n",
    ":class: miniexercise\n",
    "* Ermitteln Sie, wie häufig jeder Wert einer Kategorie in der jeweiligen Spalte\n",
    "  vorkommt.\n",
    "* Lassen Sie die Anzahl der Werte auch visualisieren. Beschriften Sie die\n",
    "  Diagramme mit einem aussagefähigen Titel.\n",
    "* Fassen Sie die Ergebnisse bzw. die Interpretation davon jeweils kurz zusammen\n",
    "  (in einer Markdown-Zelle).\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, dropdown\n",
    "```python\n",
    "for kategorie in ['Schliff', 'Farbe', 'Reinheit']:\n",
    "    print(f'Eigenschaft {kategorie}: {daten[kategorie].unique()}')\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "daten['Schliff'].unique()\n",
    "daten['Schliff'].value_counts()\n",
    "```\n",
    "\n",
    "```python\n",
    "fig = px.bar(daten['Schliff'].value_counts(),\n",
    "             title='Schliff der Diamanten',\n",
    "             labels={'value': 'Anzahl', 'index': 'Qualität', 'variable':'Legende'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "In dem Datensatz kommen überraschend viele Diamanten der Qualität ideal vor. Die\n",
    "Anzahl der Diamanten in den einzelnen Qualitätsstufen nimmt immer weiter ab.\n",
    "\n",
    "```python\n",
    "fig = px.bar(daten['Farbe'].value_counts(),\n",
    "             title='Farbe der Diamanten',\n",
    "             labels={'value': 'Anzahl', 'index': 'Farbname', 'variable':'Legende'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Am häufigsten kommt die Farbe G vor, am seltesten ist Farbe J.\n",
    "\n",
    "```python\n",
    "fig = px.bar(daten['Reinheit'].value_counts(),\n",
    "             title='Reinheit der Diamanten',\n",
    "             labels={'value': 'Anzahl', 'index': 'Reinheitskategorie', 'variable':'Legende'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "I1 ist die schlechteste Reinheit und kommt auch am seltesten vor. IF ist die\n",
    "beste Reinheitskategorie und kommt am zweitseltesten vor. Die meisten Diamanten\n",
    "im Datensatz haben eine mittlere Reinheitsstufe SI1.\n",
    "````\n",
    "\n",
    "## ML-Modelle\n",
    "\n",
    "```{admonition} Regression\n",
    ":class: miniexercise\n",
    "Ziel der Regressionsaufgabe ist es, den Preis der Diamanten zu prognostizieren.\n",
    "\n",
    "* Wählen Sie zwei Regressionsmodelle aus.\n",
    "* Wählen Sie für jedes der zwei Modelle eine oder mehrere Eigenschaften aus, die\n",
    "  Einfluss auf den Preis haben könnten. Begründen Sie Ihre Auswahl.\n",
    "* Adaptieren Sie die Daten jeweils passend zu den von Ihnen gewählten Modellen.\n",
    "* Falls notwendig, skalieren Sie die Daten.\n",
    "* Führen Sie einen Split der Daten in Trainings- und Testdaten durch.\n",
    "* Trainieren Sie jedes ML-Modell.\n",
    "* Validieren Sie jedes ML-Modell bzgl. der Trainingsdaten und der Testdaten.\n",
    "* Bewerten Sie abschließend: welches der zwei Modelle würden Sie empfehlen?\n",
    "  Begründen Sie Ihre Empfehlung.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, dropdown\n",
    "Wahl der Regressionsmodelle: lineare Regression und SVM.\n",
    "\n",
    "```python\n",
    "fig = px.scatter_matrix(daten.loc[:, ['Karat', 'Tiefe', 'Tafel', 'x', 'y', 'z', 'Preis']])\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Karat (Gewicht des Diamanten) scheint von der Größe (x, y und z) abzuhängen. Es\n",
    "ist zunächst kein linearer Zusammenhang zwischen Tiefe/Tafel und dem Preis\n",
    "erkennbar. Im Folgenden wird daher für die lineare Regression nur Karat als\n",
    "Input gewählt.\n",
    "\n",
    "```python\n",
    "selected_data = daten.loc[:, ['Karat']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(selected_data)\n",
    "input_numerical = scaler.transform(selected_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_numerical, daten['Preis'])\n",
    "```\n",
    "\n",
    "```python\n",
    "model_linear_regression = LinearRegression()\n",
    "model_linear_regression.fit(X_train, y_train)\n",
    "\n",
    "score_train = model_linear_regression.score(X_train, y_train)\n",
    "score_test = model_linear_regression.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score Testdaten: {score_test:.2f}')\n",
    "```\n",
    "\n",
    "Support Vector Machines beherrschen auch nichtlineare Zusammenhänge. Es werden\n",
    "daher alle Features verwendet.\n",
    "\n",
    "```python\n",
    "selected_data = daten.loc[:, ['Karat', 'Tiefe', 'Tafel', 'x', 'y', 'z']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(selected_data)\n",
    "input_numerical = scaler.transform(selected_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_numerical, daten['Preis'])\n",
    "```\n",
    "\n",
    "```python\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_train, y_train)\n",
    "\n",
    "score_train = model_svr.score(X_train, y_train)\n",
    "score_test = model_svr.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score Testdaten: {score_test:.2f}')\n",
    "```\n",
    "\n",
    "Zusammenfassung der Scores für die Testdaten:\n",
    "\n",
    "lineare Regression: 0.85\n",
    "Support Vector Machines: 0.55\n",
    "\n",
    "Die lineare Regression erreicht bessere Testscores als die SVM, daher ist dieses\n",
    "Modell zu bevorzugen.\n",
    "````\n",
    "\n",
    "```{admonition} Klassifikation\n",
    ":class: miniexercise\n",
    "Ziel der Klassifikationsaufgabe ist es, die Preisklasse \"billig\" oder \"teuer\"\n",
    "der Diamanten zu prognostizieren.\n",
    "\n",
    "* Vorbereitung: Filtern Sie die Daten nach den Diamanten, deren Preis kleiner\n",
    "oder gleich dem Median aller Preise ist. Diese Diamanten sollen als \"billig\"\n",
    "klassfiziert werden. Diamanten, deren Preis größer als der Median aller Preise\n",
    "ist, sollen als \"teuer\" klassifiziert werden. Speichern Sie dieses neue Merkmal\n",
    "in einer neuen Spalte \"Preisklasse\".\n",
    "* Trainieren Sie einen Entscheidungsbaum (Decision Tree) mit den Merkmalen\n",
    "  \"Karat\" und \"Schliff\".\n",
    "* Adaptieren Sie die Daten.\n",
    "* Falls notwendig, skalieren Sie die Daten.\n",
    "* Führen Sie einen Split der Daten in Trainings- und Testdaten durch.\n",
    "* Führen Sie eine Gittersuche für\n",
    "  * die Baumtiefe (2, 3) und\n",
    "  * die minimale Anzahl an Samples pro Blatt (1, 2, 5) durch.\n",
    "* Lassen Sie das beste Modell als Baum visualisieren.\n",
    "* Bewerten Sie abschließend: ist das Modell für den Produktiveinsatz geeignet?\n",
    "  Begründen Sie Ihre Bewertung.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, dropdown\n",
    "\n",
    "Vorbereitung: Filterung der Daten bezogen auf den Median des Preises\n",
    "\n",
    "```python\n",
    "median_preis = daten['Preis'].median()\n",
    "print(f'Median Preis: {median_preis} US-Dollar')\n",
    "\n",
    "daten.loc[daten['Preis'] <= median_preis].index\n",
    "```\n",
    "\n",
    "```python\n",
    "daten.loc[ daten['Preis'] <= median_preis, 'Preisklasse'] = \"billig\"\n",
    "daten.loc[ daten['Preis'] >  median_preis, 'Preisklasse'] = \"teuer\"\n",
    "\n",
    "daten['Preisklasse'].unique()\n",
    "daten.head()\n",
    "```\n",
    "\n",
    "Die kategorialen Werte müssen durch Zahlen ersetzt werden. Wir wählen 0 für den\n",
    "schlechtesten Schliff (fair) und 4 für den besten Schliff (ideal).\n",
    "\n",
    "```python\n",
    "schliff_kodierung = {\n",
    "  'fair': 0,\n",
    "  'gut': 1,\n",
    "  'sehr gut': 2,\n",
    "  'erstklassig': 3,\n",
    "  'ideal': 4 \n",
    "}\n",
    "\n",
    "daten['Schliff'] = daten['Schliff'].replace(schliff_kodierung).astype('int')\n",
    "daten['Schliff'].unique()\n",
    "\n",
    "preisklasse_kodierung = {\n",
    "    'billig': 0,\n",
    "    'teuer': 1\n",
    "}\n",
    "daten['Preisklasse'] = daten['Preisklasse'].replace(preisklasse_kodierung).astype('int')\n",
    "daten['Preisklasse'].unique()\n",
    "```\n",
    "\n",
    "Die Werte für Karat liegen zwischen 0.2 und 5 und sind daher vergleichbar den\n",
    "Werten für die Schliffqualität von 0 bis 4. Letztere dürfen nicht skaliert\n",
    "werden und bei der Eigenschaft Karat ist es nicht notwendig. Daher erfolgt keine\n",
    "Skalierung der Daten.\n",
    "\n",
    "```python\n",
    "input_categorical = daten[['Karat', 'Schliff']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_categorical, daten['Preisklasse'])\n",
    "```\n",
    "\n",
    "Training Entscheidungsbaum mit Gittersuche\n",
    "\n",
    "```python\n",
    "gitter = {\n",
    "    'max_depth': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "kfold = KFold()\n",
    "\n",
    "suche_modell = GridSearchCV(DecisionTreeClassifier(), param_grid=gitter, cv=kfold)\n",
    "\n",
    "suche_modell.fit(X_train, y_train)\n",
    "score_train = suche_modell.score(X_train, y_train)\n",
    "score_test = suche_modell.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score Testdaten: {score_test:.2f}')\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "suche_modell.best_params_\n",
    "```\n",
    "\n",
    "```python\n",
    "bestes_modell = DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 1)\n",
    "\n",
    "bestes_modell.fit(X_train, y_train)\n",
    "score_train = bestes_modell.score(X_train, y_train)\n",
    "score_test = bestes_modell.score(X_test, y_test)\n",
    "\n",
    "plot_tree(bestes_modell);\n",
    "```\n",
    "\n",
    "Dieses Modell ist nicht für den Produktiveinsatz geeignet, da Trainings- und\n",
    "Testscore bei 0.1 liegen.\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "source_map": [
   12,
   36,
   51
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}