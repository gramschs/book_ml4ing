{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1de388c",
   "metadata": {},
   "source": [
    "# 8.3 Training eines Perzeptrons mit Scikit-Learn\n",
    "\n",
    "Nachdem wir im letzten Abschnitt ein Perzeptron händisch für die Klassifikationsaufgabe des logischen Oders trainiert haben, benutzen wir nun Scikit-Learn.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "```{admonition} Lernziele\n",
    ":class: important\n",
    "* Sie können das Perzeptron-Modell von Scikit-Learn laden und mit den gegebenen Trainingsdaten trainieren.\n",
    "* Sie wissen, wie Sie auf die Gewichte des gelernten Modells zugreifen.\n",
    "```\n",
    "\n",
    "\n",
    "## Das logische Oder Klassifikationsproblem - diesmal mit Scikit-Learn \n",
    "\n",
    "Im letzten Abschnitt {ref}`perzeptron_training_logisches_oder` haben wir\n",
    "händisch ein Perzeptron trainiert. Zur Erinnerung, wenn wir die Bias-Einheit\n",
    "weglassen, lautet das logische Oder in Tabellenform wie folgt:\n",
    "\n",
    "x1 | x2 | y\n",
    "---|----|---\n",
    " 0 | 0  | 0\n",
    " 0 | 1  | 1\n",
    " 1 | 0  | 1\n",
    " 1 | 1  | 1\n",
    "\n",
    "Diese Daten formulieren wir nun als eine Inputmatrix $X$ mit den Spalten x1 und\n",
    "x2. Für die Erzeugung und Weiterverarbeitung der Matrizen laden wir das Modul\n",
    "Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f373bd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec383d98",
   "metadata": {},
   "source": [
    "Den Output formulieren wir als Vektor, ebenfalls mit Hilfe des Numpy-Moduls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276d8b9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array([0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06705267",
   "metadata": {},
   "source": [
    "Nun wählen wir das Perzeptron als das zu trainierende ML-Modell aus. Direkt beim\n",
    "Laden des Modells legen wir die Hyperparameter des Modells fest. Welche\n",
    "Hyperparameter ein Modell hat, steht in der\n",
    "[Perzeptron-Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html?highlight=perceptron#sklearn.linear_model.Perceptron).\n",
    "In diesem Fall wäre beispielsweise die Lernrate ein Hyperparameter. Laut\n",
    "Dokumentation wird die Lernrate beim Scikit-Learn-Perzeptron mit `eta0`\n",
    "bezeichnet. Der Python-Code, um das Perzeptron-Modell mit einer Lernrate von 1\n",
    "zu laden, lautet also wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87620bd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron \n",
    "modell = Perceptron(eta0 = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70086d",
   "metadata": {},
   "source": [
    "Nun können wir das Perzeptron-Modell mit den Input- und Outputdaten trainieren, indem wir die `.fit()`-Methode aufrufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed3695",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "modell.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdcf03b",
   "metadata": {},
   "source": [
    "Nachdem wir den letzten Python-Befehl ausgeführt haben, passiert scheinbar\n",
    "nichts. Nur der Klassenname `Perceptron()` des Objekts `modell` wird ausgegeben\n",
    "(wenn Sie den Code interaktiv ausführen). Intern wurde jedoch das\n",
    "Perzeptron-Modell trainiert, d.h. die Gewichte des Perzeptrons wurden iterativ\n",
    "bestimmt. Die Gewichte sind nun in dem Objekt `modell` gespeichert. Davon können\n",
    "wir uns überzeugen, indem wir auf die Attribute des Objekts zugreifen und diese\n",
    "anzeigen lassen. Die Gewichte sind in dem Attribut `.coef_` gespeichert, während\n",
    "das Gewicht der Bias-Einheit sich im Attribut `.intercept_` befindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86c1c8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(modell.coef_)\n",
    "print(modell.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10ba07",
   "metadata": {},
   "source": [
    "Zuletzt können wir das trainierte Perzeptron-Modell Prognosen treffen lassen.\n",
    "Was prognostiziert das Modell beispielsweise für $x_1=0$ und $x_2=1$? Das\n",
    "tatsächliche Ergebnis der logischen Oder-Verknüpfung ist $y=1$, was liefert das\n",
    "Perzeptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ac7af",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "y_prognose = modell.predict(np.array([[0, 1]]))\n",
    "print(y_prognose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e5a4e",
   "metadata": {},
   "source": [
    "Wir können auch gleich für alle Datensätze eine Prognose erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08796462",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "y_prognose = modell.predict(X)\n",
    "print(y_prognose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2e526",
   "metadata": {},
   "source": [
    "Tatsächlich funktioniert unser trainiertes Perzeptron zu 100 % korrekt und ist\n",
    "damit validiert. Bei nur vier Datensätzen lässt sich relativ leicht überblicken,\n",
    "dass alle vier Prognosen korrekt sind. Sobald die Datenanzahl zunimmt, wird es\n",
    "schwieriger, den Überblick zu behalten. Daher stellt Scikit-Learn die Methode\n",
    "`.score()` zur Verfügung, die bei Klassifikatoren die Anzahl der korrekt\n",
    "prognostizierten Outputs im Verhältnis zur Gesamtanzahl berechnet. Das Ergbnis\n",
    "ist also eine Bewertung zwischen 0 (keine einzige korrekte Prognose) und 1\n",
    "(perfekt Prognose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc323bd2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "genauigkeit = modell.score(X, y)\n",
    "print(genauigkeit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7f835",
   "metadata": {},
   "source": [
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "Mit Scikit-Learn steht schon eine Implementierung des Perzeptrons zur Verfügung,\n",
    "die auch bei größeren Datenmengen eine binäre Klassifikation erlaubt. Welche\n",
    "Daten dabei überhaupt binär klassifiziert können, klären wir in einem der\n",
    "folgenden Abschnitte."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
