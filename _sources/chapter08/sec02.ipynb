{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a06e4aa",
   "metadata": {},
   "source": [
    "# Die Perzeptron-Lernregel\n",
    "\n",
    "In dem Abschnitt über das Perzeptron waren die Gewichte und der Schwellenwert vorgegeben. Aber wie kommt man dazu? In diesem Abschnitt beschäftigen wir uns damit, wie die Gewichte und der Schwellenwert gewählt werden müssen, damit das Perzeptron seine binäre Klassifikationsaufgabe erfüllen kann. \n",
    "\n",
    "```{admonition} Lernziele\n",
    ":class: hint\n",
    "* Sie kennen die drei Phasen, in denen ein Perzeptron trainiert wird:\n",
    "  * Initialisierung der Gewichte und Festlegung der Lernrate;\n",
    "  * Berechnung des prognostizierten Outputs und Aktualisierung der Gewichte sowie\n",
    "  * Terminierung des Trainings.\n",
    "* In Zusammenhang mit dem Training von ML-Verfahren kennen Sie die Fachbegriffe Lernrate und Epoche.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d1577",
   "metadata": {},
   "source": [
    "## Hebbsche Regel\n",
    "\n",
    "Kaum zu glauben, aber die Idee zum Lernen der Gewichte eines Perzeptrons stammt\n",
    "nicht von Informatiker:innen, sondern von einem Psychologen namens [Donald\n",
    "Olding Hebb](https://de.wikipedia.org/wiki/Donald_O._Hebb). Im Englischen wird\n",
    "seine Arbeit meist durch das Zitat \n",
    "\n",
    ">\"what fires together, wires together\" \n",
    "\n",
    "kurz zusammengefasst. Hebb hat die Veränderung der synaptischen Übertragung von\n",
    "Neuronen untersucht und dabei festgestellt, dass je häufiger zwei Neuronen\n",
    "gemeinsam aktiv sind, desto eher werden die beiden aufeinander reagieren.\n",
    "\n",
    "Die Hebbsche Regel wird beim maschinellen Lernen dadurch umgesetzt, dass der\n",
    "Lernprozess mit zufälligen Gewichten startet und dann der prognostizierte Output\n",
    "mit dem echten Output verglichen wird. Je nachdem, ob der echte Output erreicht\n",
    "wurde oder nicht, werden nun die Gewichte und damit der Einfluss eines einzelnen\n",
    "Inputs verstärkt oder nicht. Dieser Prozess — Vergleichen und Abändern der\n",
    "Gewichte — wird solange wiederholt, bis die passenden Gewichte gefunden sind. \n",
    "\n",
    "```{admonition} Mini-Übung\n",
    ":class: miniexercise\n",
    "Angenommen, in unserem \"Ist-der-Rasen-nass-Problem\" (siehe [](rasen_nass_problem)) sind die Gewichte alle Null, also $\\omega_0 = \\omega_1 = \\omega_2 = 0$. Was prognostiziert das Perzeptron für \"es regnet nicht\" ($x_1=0$) und \"der Rasensprenger ist aus\" ($x_2=0$)?\n",
    "```\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "Das Perzeptron prognostiziert fälschlicherweise, dass der Rasen nass ist. Die gewichtete Summe wird zu\n",
    "\n",
    "$$\\mathbf{x}^{T} \\boldsymbol{\\omega} = \\begin{pmatrix} 0, 0, 0 \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = 0$$\n",
    "\n",
    "berechnet. Da aber dann noch die Aktivierungsfunktion (Heaviside-Funktion) angewendet werden muss, erhalten wir\n",
    "\n",
    "$$\\Phi(0)=1,$$\n",
    "\n",
    "also der Rasen ist nass.\n",
    "````\n",
    "\n",
    "## Lernregel für das Perzeptron\n",
    "\n",
    "Wie werden die Gewichte konkret verstärkt oder abgeschwächt, wenn der\n",
    "prognostizierte Output nicht mit dem echten Output übereinstimmt? Die Lernregel\n",
    "für das Perzeptron sieht zunächst einmal kompliziert aus: \n",
    "\n",
    "$$\\omega_i^{\\text{neu}} = \\omega_i^{\\text{aktuell}} + \\alpha \\cdot(y -\n",
    "\\hat{y}^{\\text{aktuell}}) \\cdot x_i.\\strut$$\n",
    "\n",
    "Gehen wir die Rechenvorschrift Stück für Stück durch. Zunächst einmal fällt auf,\n",
    "dass ein Index $i$ auftaucht. Das liegt daran, dass wir mehrere Eingabewerte\n",
    "haben und damit mehrere Gewichte — ein Gewicht pro Eingabewert. Da die\n",
    "Lernvorschrift allgemeingültig formuliert werden soll, gehen wir jetzt einfach\n",
    "mal davon aus, dass wir $m$ verschiedene Eingabewerte haben. $x_i$ meint also\n",
    "den i-ten Eingabewert und mit $\\omega_i$ bezeichnen wir das dazugehörige\n",
    "Gewicht. Dabei dürfen wir den Bias nicht vergessen.\n",
    "\n",
    "Bisher hatten wir den Output einfach mit $y$ gekennzeichnet. Jetzt müssen wir\n",
    "aber etwas sorgfältiger vorgehen und genau unterscheiden, ob wir den Output\n",
    "meinen, den das Perzeptron prognostiziert oder den echten (gemessenen) Output.\n",
    "Über berechnete bzw. prognostizierte Outputs setzen wir ein kleines Dachsymbol\n",
    "$\\wedge$. Etwas präziser bezeichnen wir den prognostizierten Output, den das\n",
    "Perzeptron mit den aktuellen Gewichten $(\\omega_0^{\\text{aktuell}},\n",
    "\\omega_1^{\\text{aktuell}}, \\ldots, \\omega_m^{\\text{aktuell}})$ berechnen würde,\n",
    "mit der Abkürzung $\\hat{y}^{\\text{aktuell}}$ . Für den echten Output bleiben wir\n",
    "einfach bei der Bezeichnung $y$. \n",
    "\n",
    "Fehlt noch das $\\alpha$, doch dazu kommen wir gleich. Schauen wir uns erst\n",
    "einmal an, wie sich die Differenz $y - \\hat{y}^{\\text{aktuell}}$ auf die\n",
    "Verstärkung oder Abschwächung der Gewichte auswirkt. \n",
    "\n",
    "Wenn der echte Output und der prognostizierte Output gleich sind, ist deren\n",
    "Differenz Null und es ändert sich nichts. Ansonsten gibt es zwei Möglichkeiten:\n",
    "\n",
    "* Wenn der *echte Output größer ist als der prognostizierte Output*, dann ist \n",
    "  $y - \\hat{y}^{\\text{aktuell}} > 0$. Indem wir nun zu den alten Gewichten den Term\n",
    "  $ \\alpha \\cdot(y - \\hat{y}^{\\text{aktuell}})$ addieren, verstärken wir die\n",
    "  alten Gewichte. Dabei berücksichtigen wir, ob der Input überhaupt einen\n",
    "  Beitrag zum Output liefert, indem wir zusätzlich mit $x_i$ multiplizieren. Ist\n",
    "  nämlich der Input $x_i=0$, wird so nichts an den Gewichten geändert. \n",
    "* Ist jedoch *der echte Output kleiner als der prognostizierte Output*, dann ist\n",
    "  $y - \\hat{y}^{\\text{aktuell}} < 0$. Daher werden nun die alten Gewichte durch\n",
    "  die Addition des negativen Terms $\\alpha \\cdot(y - \\hat{y}^{\\text{aktuell}})\n",
    "  \\cdot x_i$ abgeschwächt. \n",
    "\n",
    "Damit die Schritte zwischen der Abschwächung und der Verstärkung nicht zu groß\n",
    "werden, werden sie noch mit einem Vorfaktor $\\alpha$ multipliziert, der zwischen\n",
    "0 und 1 liegt. Ein typischer Wert von $\\alpha$ ist $0.0001$. Dieser Vorfaktor\n",
    "$\\alpha$ wird **Lernrate** genannt.\n",
    "\n",
    "```{admonition} Was ist ... die Lernrate?\n",
    "Die Lernrate ist eine Zahl, die zu Beginn des ML-Trainings gesetzt wird (ein sogenannter Hyperparameter). Sie bestimmt, wie stark die neuen Gewichte auf Fehler zwischen Prognose und tatsächlichem Output des aktuellen Durchgangs reagieren.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91b2d4",
   "metadata": {},
   "source": [
    "(perzeptron_training_logisches_oder)=\n",
    "## Perzeptron-Training am Beispiel des logischen ODER\n",
    "\n",
    "Das logische Oder ist bereits durch die Angabe der folgenden vier Datensätzen\n",
    "komplett definiert. Dabei haben wir noch die Bias-Einheit $x_0=1$ ergänzt.\n",
    "        \n",
    "x0 | x1 | x2 | y\n",
    "---|---|----|---\n",
    "1  | 0 | 0  | 0\n",
    "1  | 0 | 1  | 1\n",
    "1  | 1 | 0  | 1\n",
    "1  | 1 | 1  | 1\n",
    "\n",
    "Im Folgenden wird das Training eines Perzeptrons Schritt für Schritt vorgerechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4f4aa",
   "metadata": {},
   "source": [
    "### Schritt 1: Initialisierung der Gewichte und der Lernrate\n",
    "\n",
    "Wir brauchen für die drei Inputs drei Gewichte und setzen diese drei Gewichte\n",
    "jeweils auf 0. Wir sammeln die Gewichte als Vektor, also\n",
    "\n",
    "$$\\boldsymbol{\\omega} = \\begin{pmatrix}\\omega_0 \\\\ \\omega_1 \\\\ \\omega_2\\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0\\end{pmatrix}.$$\n",
    "\n",
    "Darüber hinaus müssen wir uns für eine Lernrate $\\alpha$ entscheiden. Obwohl\n",
    "normalerweise ein kleiner (aber positiver) Wert gewählt wird, setzen wir der\n",
    "Einfachheit halber die Lernrate auf 1, also $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4fac2",
   "metadata": {},
   "source": [
    "### Schritt 2: Berechnung des Outputs und ggf. Anpassung der Gewichte\n",
    "\n",
    "Wir setzen nun solange nacheinander den ersten, zweiten, dritten und vierten\n",
    "Trainingsdatensatz in die Berechnungsvorschrift unseres Perzeptrons ein, bis die\n",
    "Gewichte für alle vier Trainingsdatensätze zu einer korrekten Prognose führen.\n",
    "Zur Erinnerung, wir berechnen den aktuellen Output des Perzeptrons mit der\n",
    "Formel\n",
    "\n",
    "$$\\hat{y}^{aktuell} = \\Phi(\\mathbf{x}^{T}\\boldsymbol{\\omega}) = \\Phi(x_0\n",
    "\\omega_0 + x_1 \\omega_1 + x_2 \\omega_2 ).\\strut$$\n",
    "\n",
    "Blättern Sie Seite für Seite durch. Jede Seite entspricht einem Durchgang. Ein Durchgang wird im ML (wie auch in der Mathematik) als eine **Iteration** bezeichnet.\n",
    "\n",
    "````{carousel}\n",
    ":show_controls:\n",
    ":show_shadows:\n",
    "\n",
    "\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0001.pdf\n",
    "\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0002.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0003.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0004.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0005.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0006.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0007.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0008.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0009.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0010.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0011.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0012.pdf\n",
    "```\n",
    "\n",
    "```{figure} pics/part08_training_perceptron_0013.pdf\n",
    "```\n",
    "````\n",
    "\n",
    "### Schritt 3: Terminierung\n",
    "\n",
    "Die letzten vier Iterationen mit den Gewichten $(-1,1,1)$ prognostizierten\n",
    "jeweils das richtige Ergebnis. Daher können wir nun mit den Iterationen stoppen.\n",
    "\n",
    "Insgesamt brauchten wir 13 Iterationen, bis wir die Gewichte für unser Perzeptron gefunden haben. Die finalen Gewichte haben wir bereits nach neun Iterationen gefunden. Weitere vier Iterationen brauchten wir, um zu überprüfen, ob das Perzeptron die vier Datensätze korrekt prognostiziert. Oder anders ausgedrückt, mussten alle vier Datensätze noch einmal durchlaufen werden. Das Durchlaufen aller Datensätze kommt beim mschinellen Lernen häufig vor, so dass es dafür einen eigenen Fachbegriff gibt, nämlich die Epoche.\n",
    "\n",
    "```{admonition} Was ist ... eine Epoche?\n",
    "Das komplette Durchlaufen aller Trainingsdaten wird eine Epoche genannt.\n",
    "```\n",
    "\n",
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "In diesem Abschnitt haben wir uns mit dem händischen Training eines Perzeptrons beschäftigt. Als nächstes werden wir dazu eine Bibliothek kennenlernen, die diese Arbeit für uns übernimmt."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.13.8"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   13,
   28,
   121,
   138,
   151
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}