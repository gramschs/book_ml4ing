{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60c3584",
   "metadata": {},
   "source": [
    "# Übung\n",
    "\n",
    "Auf der Internetseite\n",
    "[https://archive.ics.uci.edu/dataset/151/connectionist+bench+sonar+mines+vs+rocks]\n",
    "finden Sie einen Datensatz mit Sonarsignalen. Die Muster der Signale sind durch\n",
    "60 Zahlenwerte codiert (es handelt sich um die Energie zu bestimmten Frequenzen,\n",
    "normalisiert auf \\[0,1\\]). Darüber hinaus wird angegeben, ob das Sonarsignal\n",
    "Gestein (= Stein) oder Metall detektiert hat.\n",
    "\n",
    "Laden Sie nun die Datei 'metall_oder_stein.csv'. Führen Sie eine explorative\n",
    "Datenanalyse durch. Lassen Sie dann alle Ihnen bekannten Klassifikationsmodelle\n",
    "trainieren und validieren, um die Materialeigenschaft Stein/Metall auf Basis der\n",
    "numerischen Werte zu prognostizieren.\n",
    "\n",
    "```{admonition} Überblick über die Daten\n",
    ":class: miniexercise\n",
    "* Welche Daten enthält der Datensatz?\n",
    "* Wie viele Datenpunkte und Merkmale gibt es?\n",
    "* Sind die Daten vollständig?\n",
    "* Welche Datentypen haben die Merkmale?\n",
    "* Gibt es Merkmale mit unerwarteten Datentypen?\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Import der Daten (zwei Kommentarzeilen werden übersprungen)\n",
    "daten = pd.read_csv('metall_oder_stein.csv', skiprows=2)\n",
    "daten.info()\n",
    "\n",
    "# Check der Vollständigkeit:\n",
    "print(daten.isnull().sum())\n",
    "\n",
    "# Blick in die Daten:\n",
    "daten.head(10)\n",
    "```\n",
    "Der Datensatz enthält 208 Einträge (Datenpunkte) und 61 Merkmale. Die ersten 60\n",
    "Merkmale Signal01 bis Signal60 werden durch Floats repräsentiert, das Merkmal\n",
    "Material wird durch Objekte repräsentiert.\n",
    "\n",
    "Die Daten sind vollständig.\n",
    "\n",
    "Die ersten 10 Zeilen zeigen in den Spalten Signal01 bis Signal60 numerische\n",
    "Werte. In der letzten Spalte Material wird der String 'Stein' aufgelistet. Ein\n",
    "kurzer Test mit\n",
    "\n",
    "```python\n",
    "daten['Material'].unique()\n",
    "```\n",
    "\n",
    "zeigt, dass in dieser Spalte lediglich die beiden Einträge 'Stein' und 'Metall'\n",
    "auftreten. Insgesamt sind die Werte der Merkmale für die Datentypen plausibel.\n",
    "````\n",
    "\n",
    "```{admonition} Statistik der numerischen Daten\n",
    ":class: miniexercise\n",
    "Erstellen Sie eine Übersicht der statistischen Kennzahlen für die numerischen\n",
    "Daten. Interpretieren Sie die statistischen Kennzahlen. Gibt es Auffälligkeiten?\n",
    "Sind die Werte plausibel?\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "daten.describe()\n",
    "```\n",
    "Die statistischen Kennzahlen lassen sich aufgrund der großen Anzahl an Merkmalen\n",
    "so kaum interpretieren. Daher hilft hier ein Boxplot der numerischen Daten\n",
    "weiter.\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(daten.drop('Material', axis=1), \n",
    "             title='Stein oder Metall',\n",
    "             labels={'variable': 'Merkmal', 'value':'Wert'})\n",
    "fig.show()\n",
    "```\n",
    "Die Medianwerte scheinen einem Muster zu folgen. Beginnend bei Merkmal Signal01\n",
    "steigen sie bis zu Signal26, wo der Median den Wert 0.7545 erreicht, um dann\n",
    "wieder abzufallen. Ab Signal50 liegt der Median unter 0.0179. Bei Eigenschaften\n",
    "mit einem größeren Median ist auch der Interquartilsabstand (IQR) größer, dafür\n",
    "gibt es keine Ausreißer. Das Maximum liegt bei 1, was konsistent mit der\n",
    "Normalisierung auf \\[0,1\\] ist.\n",
    "````\n",
    "\n",
    "```{admonition} Statistik der kategorialen Merkmale\n",
    ":class: miniexercise\n",
    "Wie viele Einträge gibt es für Metall oder Stein? Visualisieren Sie die\n",
    "Verteilung mit einem Balkendiagramm der Klassenverteilung. Ist der Datensatz\n",
    "ausgewogen?\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "# Berechnung der Anzahl der Einträge\n",
    "print(daten['Material'].value_counts())\n",
    "\n",
    "# Visualisierung als Balkendiagramm\n",
    "fig = px.bar(daten['Material'].value_counts(),\n",
    "             title='Stein oder Metall')\n",
    "fig.update_layout(\n",
    "    yaxis_title='Anzahl',\n",
    "    xaxis_title='Material',\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n",
    "```\n",
    "Im Datensatz sind 111 Proben Metall und 97 Stein. Damit sind 53 % der Proben\n",
    "Metall und 47 % Stein, was ungefähr gleichverteilt ist.\n",
    "````\n",
    "\n",
    "```{admonition} Vorbereitung der Daten für das Training\n",
    ":class: miniexercise\n",
    "Bereiten Sie die Daten für das maschinelle Lernen vor:\n",
    "1. Kodieren Sie die kategoriale Variable Material mit `replace()`.\n",
    "2. Trennen Sie die Merkmale (Input X) und die Zielgröße (Output y).\n",
    "3. Teilen Sie die Daten in Trainings- und Testdaten im Verhältnis 80:20 auf.\n",
    "4. Skalieren Sie - falls notwendig - die Trainingsdaten mit `fit_transform()`\n",
    "   und die Testdaten mit `transform()`.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Kodierung mit Check (sollte [0 1] ausgeben)\n",
    "daten['Material'] = daten['Material'].replace({'Stein': '0', 'Metall': '1'}).astype(int)\n",
    "print(daten['Material'].unique())\n",
    "\n",
    "# Aufteilung in Input/Output\n",
    "X = daten.drop('Material', axis=1)\n",
    "y = daten['Material']\n",
    "\n",
    "# Split 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Prüfen der Wertebereiche\n",
    "print(X.min().min(), X.max().max())\n",
    "```\n",
    "Da die Signaldaten alle im Intervall \\[0,1\\] liegen, brauchen wir die Daten\n",
    "nicht skalieren.\n",
    "````\n",
    "\n",
    "```{admonition} ML-Modell Entscheidungsbaum\n",
    ":class: miniexercise\n",
    "Trainieren Sie einen Entscheidungsbaum und bewerten Sie das trainierte Modell.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instanziierung des Entscheidungsbaums mit Training\n",
    "modell_baum = DecisionTreeClassifier()\n",
    "modell_baum.fit(X_train,y_train)\n",
    "\n",
    "# Bewertung\n",
    "score_train = modell_baum.score(X_train, y_train)\n",
    "score_test = modell_baum.score(X_test, y_test)\n",
    "print(f'Score Trainingsdaten Entscheidungsbaum: {score_train :.2f}')\n",
    "print(f'Score Testdaten Entscheidungsbaum: {score_test :.2f}')\n",
    "```\n",
    "Der Trainingsscore ist 1.00, der Testscore 0.79; ein Zeichen für Overfitting.\n",
    "````\n",
    "\n",
    "```{admonition} ML-Modell Random Forest\n",
    ":class: miniexercise\n",
    "Trainieren Sie nun einen Random Forest mit 1, 5, 10, 20, 50 und 100 Bäumen auf\n",
    "denselben Daten. Berechnen Sie wieder die Scores für Training und Test. Wie\n",
    "unterscheiden sich die Ergebnisse vom einzelnen Entscheidungsbaum? Welches\n",
    "Random-Forest-Modell würden Sie wählen?\n",
    "\n",
    "Bewerten Sie darüber hinaus mit der Feature Importance, welche Signale am\n",
    "wichtigsten sind.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for n in [1, 5, 10, 20, 50, 100]:\n",
    "    # Instanziierung des Random-Forest-Modells und Training\n",
    "    modell_rf = RandomForestClassifier(n_estimators=n, random_state=0)\n",
    "    modell_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Bewertung\n",
    "    score_train = modell_rf.score(X_train, y_train)\n",
    "    score_test = modell_rf.score(X_test, y_test)\n",
    "    print(f'Anzahl Entscheidungsbäume: {n}')\n",
    "    print(f'Score Training: {score_train :.2f} | Score Test: {score_test :.2f}')\n",
    "    print('')\n",
    "\n",
    "# bestes RF-Modell wählen\n",
    "modell_rf_final = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "modell_rf_final.fit(X_train, y_train)\n",
    "\n",
    "# Feature Importance extrahieren\n",
    "importance = pd.DataFrame({\n",
    "    'Merkmal': X_train.columns,\n",
    "    'Feature Importance': modell_rf_final.feature_importances_\n",
    "}).sort_values('Feature Importance', ascending=False)\n",
    "\n",
    "# die 5 wichtigsten Merkmale anzeigen\n",
    "importance.head(5)\n",
    "```\n",
    "Das Random-Forest-Modell ist besser verallgemeinerbar als der Entscheidungsbaum.\n",
    "Für einen Random Forest aus 50 Entscheidungsbäumen erhalten wir einen\n",
    "Trainingsscore von 1.00 und einen Testscore von 0.88. Noch mehr\n",
    "Entscheidungsbäume führen zu keinem besseren Ergebnis, so dass wir dieses\n",
    "Modell wählen würden.\n",
    "\n",
    "Mit dem besten Modell berechnen wir dann die Feature Importance. Am wichtigsten\n",
    "sind die Signale Signal09 bis Signal12 und Signal52.\n",
    "````\n",
    "\n",
    "```{admonition} ML-Modelle SVM und finales Modell\n",
    ":class: miniexercise\n",
    "Trainieren Sie nun sowohl eine lineare SVM als auch eine nichtlineare SVM.\n",
    "Ordnen Sie ein: welches ML-Modell würden Sie final wählen?\n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: minisolution, toggle\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instanziierung einer linearen SVM und Training\n",
    "svm_linear = SVC(kernel='linear', random_state=0)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# Bewertung lineare SVM\n",
    "score_train = svm_linear.score(X_train, y_train)\n",
    "score_test = svm_linear.score(X_test, y_test)\n",
    "print(f'Score Trainingsdaten lineare SVM: {score_train :.2f}')\n",
    "print(f'Score Testdaten lineare SVM: {score_test :.2f}')\n",
    "\n",
    "# Instanziierung einer nichtlinearen SVM und Training\n",
    "svm_rbf = SVC(kernel='rbf', random_state=0)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Bewertung nichtlineare SVM\n",
    "score_train = svm_rbf.score(X_train, y_train)\n",
    "score_test = svm_rbf.score(X_test, y_test)\n",
    "print(f'Score Trainingsdaten nichtlineare SVM: {score_train :.2f}')\n",
    "print(f'Score Testdaten nichtlineare SVM: {score_test :.2f}')\n",
    "```\n",
    "Wir erhalten die folgenden Scores (zusammen mit den vorherigen):\n",
    "\n",
    "\n",
    "| ML-Modell | Score Training | Score Test |\n",
    "| --- | --- | --- |\n",
    "| Entscheidungsbaum | 1.00 | 0.79 |\n",
    "| Random Forest | 1.00 | 0.88 |\n",
    "| lineare SVM | 0.86 | 0.86 |\n",
    "| nichtlineare SVM (RBF-Kernel) | 0.88 | 0.79 |\n",
    "\n",
    "Die lineare SVM generalisiert am besten (gleicher Score auf Train/Test), während\n",
    "die nichtlineare SVM (mit RBF-Kernel) leichtes Overfitting zeigt (0.88 vs. 0.79)\n",
    "\n",
    "Obwohl der Random Forest das beste Ergebnis auf den Testdaten erzielt (Testscore\n",
    "0.88), entscheiden wir uns nicht für dieses Modell. Der Random Forest besteht\n",
    "aus vielen Entscheidungsbäumen und ist dadurch zwar leistungsstark, aber nur\n",
    "eingeschränkt interpretierbar.\n",
    "\n",
    "Die lineare SVM erreicht mit einem Trainings- und Testscore von jeweils 0.86\n",
    "eine ähnlich gute Prognosegüte wie der Random Forest, zeigt aber keinerlei\n",
    "Overfitting. Außerdem ist sie deutlich einfacher interpretierbar, da die\n",
    "Entscheidungsregel auf einem linearen Modell basiert. Die gelernten Gewichte\n",
    "geben direkt an, wie stark und in welche Richtung jedes Signal die\n",
    "Klassifikation beeinflusst. Das macht das lineare SVM-Modell transparent.\n",
    "\n",
    "Daher wählen wir als finales Modell die lineare SVM, da sie stabile Ergebnisse\n",
    "liefert, gut verallgemeinert und die zugrunde liegende Entscheidungslogik\n",
    "nachvollziehbar bleibt.\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "source_map": [
   13
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}