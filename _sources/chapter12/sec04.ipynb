{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fbf1bb",
   "metadata": {},
   "source": [
    "# Übungen logistische Regression\n",
    "\n",
    "\n",
    "```{admonition} Aufgabe 1\n",
    ":class: tip\n",
    "\n",
    "Ein sehr berühmter Datensatz für maschinelles Lernen ist die Irisblütensammlung,\n",
    "siehe auch https://de.wikipedia.org/wiki/Portal:Statistik/Datens%C3%A4tze#Iris .\n",
    "In dem Datensatz sind Beispiele für die drei Irisarten\n",
    "\n",
    "* Iris Setosa,\n",
    "* Iris Virginica und \n",
    "* Iris Versicolor.\n",
    "\n",
    "1. Laden Sie den Datensatz ('iris.csv') und verschaffen Sie sich einen\n",
    "   Überblick.\n",
    "    * Durch welche Eigenschaften/Attribute werden die Iris-Blumen beschrieben?\n",
    "      Lesen Sie dazu auch die oben angegebene Wikipedia-Seite.\n",
    "    * Welche Spalte enthält die Bezeichnung der Irisart?\n",
    "    * Wie viele Blumen sind pro Irisart in dem Datensatz enthalten?\n",
    "2. Bestimmen Sie die statistischen Kennzahlen der Eigenschaften getrennt nach\n",
    "   Irisart und visualisieren Sie die Eigenschaften jeweils als Boxplots.\n",
    "   Interpretieren Sie die Ergebnisse.\n",
    "3. Geben Sie eine Einschätzung basierend auf den statistischen Analysen aus\n",
    "   Punkt 2 ab und einer Scattermatrix (color = 'species'). Lassen sich die drei\n",
    "   Irisarten durch ein Perzeptron klassifizieren?\n",
    "4. Vergleichen Sie ein trainiertes Perzeptron mit einem trainierten logistischen Regressionsmodell.\n",
    "```\n",
    "\n",
    "````{admonition} Lösung \n",
    ":class: tip, toggle\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Datenimport \n",
    "data = pd.read_csv('iris.csv')\n",
    "data.info()\n",
    "```\n",
    "\n",
    "Es gibt vier Spalten mit den Eigenschaften:\n",
    "\n",
    "* sepal_length: Länge Sepalum (= Kelchblatt)\n",
    "* sepal_width: Breite Sepalum\n",
    "* petal_length: Länge Petalum (= Kronblatt)\n",
    "* petal_width: Breite Petalum\n",
    "\n",
    "Alle vier Größenangaben werden durch Floats repräsentiert. Die Spalten sind\n",
    "vollständig. Die Spalte species gibt die Irisart an.\n",
    "  \n",
    "\n",
    "```python\n",
    "data.head()\n",
    "```\n",
    "\n",
    "```python\n",
    "data['species'].value_counts()\n",
    "```\n",
    "\n",
    "Es gibt drei verschiedene Irisarten, jede kommt 50 x vor.\n",
    "\n",
    "Statistische Kennzahlen:\n",
    "\n",
    "```python\n",
    "data_by_species = data.groupby('species')\n",
    "\n",
    "print('Iris setosa: ')\n",
    "data_by_species.get_group('Iris-setosa').describe()\n",
    "```\n",
    "\n",
    "```python\n",
    "print('Iris versicolor: ')\n",
    "data_by_species.get_group('Iris-versicolor').describe()\n",
    "```\n",
    "\n",
    "```python\n",
    "print('Iris virginica: ')\n",
    "data_by_species.get_group('Iris-virginica').describe()\n",
    "```\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(data, x = 'species', y = 'sepal_length',\n",
    "             title='Länge Sepalum (Kelchblatt)',\n",
    "             labels={'species': 'Irisart', 'sepal_length': 'Länge in cm'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Die drei Irisarten unterscheiden sich bzgl. der Länge des Sepalums: Iris Setosa\n",
    "hat einen Median von 5 cm, Iris Versicolor einen Median von 5,9 cm und Iris\n",
    "Virginica einen Median von 6,5 cm. Es gibt nur einen Ausreißer bei der Irisart\n",
    "Iris Virginica.\n",
    "\n",
    "```python\n",
    "fig = px.box(data, x = 'species', y = 'sepal_width',\n",
    "             title='Breite Sepalum (Kelchblatt)',\n",
    "             labels={'sepal_width': 'Breite in cm', 'species': 'Irisart'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Dafür hat Iris Setosa breitere Kelchblätter (Median 3.4 cm) im Vergleich zu Iris\n",
    "Versicolor (Median 2.8 cm) und Iris Virginica (Median 3 cm). Es gibt keine\n",
    "Ausreißer.\n",
    "\n",
    "```python\n",
    "fig = px.box(data, x = 'species', y = 'petal_length',\n",
    "            title='Länge Petalum (Kronblatt)',\n",
    "            labels={'petal_length': 'Länge in cm', 'species': 'Irisart'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Bei der Länge der Kronblätter gibt es einen deutlichen Unterschied zwischen Iris\n",
    "Setosa (Median 1.5 cm) und den beiden anderen Irisarten: Iris Versicolor (Median\n",
    "4.35 cm) und Iris Virginica (Median 5.55 cm).\n",
    "\n",
    "```python\n",
    "fig = px.box(data, x = 'species', y = 'petal_width',\n",
    "            title='Breite Petalum (Kronblatt)',\n",
    "            labels={'petal_width': 'Breite in cm', 'species': 'Irisart'})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Der Unterschied bei der Länge der Kronblätter ist auch bei der Breite\n",
    "wiederzufinden. Iris Setosa hat im Median 0.2 cm deutlich dünnere Kronblätter\n",
    "als Iris Versicolor (Median 1.3 cm) und Iris Virginica (2 cm).\n",
    "\n",
    "```python\n",
    "fig = px.scatter_matrix(data, color='species')\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Die Irisart Iris Setosa lässt sich von den anderen beiden Arten trennen. Dazu\n",
    "können wir entweder die Länge oder die Breite der Kronblätter nehmen. Ist ein\n",
    "Kronblatt kürzer als beispielsweise 2.5 cm, so wird es eine Iris Setosa sein.\n",
    "Das gleiche gilt, wenn ein Kronblatt dünner als 0.8 cm ist.\n",
    "\n",
    "Wir trainieren ein Perzeptron für die Trennung in Iris Setosa und keine Iris\n",
    "Setosa.\n",
    "\n",
    "```python\n",
    "# Encoding \n",
    "data_classification_setosa = data.copy()\n",
    "data_classification_setosa.replace('Iris-setosa', 1, inplace=True)\n",
    "data_classification_setosa.replace('Iris-versicolor', 0, inplace=True)\n",
    "data_classification_setosa.replace('Iris-virginica', 0, inplace=True)\n",
    "\n",
    "# Model selection\n",
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron()\n",
    "\n",
    "# Adaption of data\n",
    "X = data_classification_setosa.loc[:, 'sepal_width':'petal_length']\n",
    "y = data_classification_setosa['species']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation\n",
    "score_train = model.score(X_train, y_train)\n",
    "score_test = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten: {score_train}')\n",
    "print(f'Score Testdaten: {score_test}')\n",
    "```\n",
    "\n",
    "Zuletzt trainieren wir ein Perzeptron und ein logistisches Regressionsmodell für\n",
    "die Irisart Iris Virginica und vergleiche beide miteinander.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Encoding\n",
    "classification_virginica = data.copy()\n",
    "\n",
    "classification_virginica.replace('Iris-virginica', 1, inplace=True)\n",
    "classification_virginica.replace('Iris-setosa', 0, inplace=True)\n",
    "classification_virginica.replace('Iris-versicolor', 0, inplace=True)\n",
    "\n",
    "# Adaption of data\n",
    "X = classification_virginica.loc[:, 'sepal_length' : 'petal_width']\n",
    "y = classification_virginica['species']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)\n",
    "\n",
    "# Model selection\n",
    "model_perceptron = Perceptron()\n",
    "model_logistic_regression = LogisticRegression()\n",
    "\n",
    "# Training\n",
    "model_perceptron.fit(X_train, y_train)\n",
    "model_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Validation\n",
    "score_perceptron_train = model_perceptron.score(X_train, y_train)\n",
    "score_perceptron_test = model_perceptron.score(X_test, y_test)\n",
    "score_logistic_regression_train = model_logistic_regression.score(X_train, y_train)\n",
    "score_logistic_regression_test = model_logistic_regression.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten Perzeptron: {score_perceptron_train:.2f}')\n",
    "print(f'Score Testdaten Perzeptron: {score_perceptron_test:.2f}')\n",
    "print(f'Score Trainingsdaten logistische Regression: {score_logistic_regression_train:.2f}')\n",
    "print(f'Score Testdaten logistische Regression: {score_logistic_regression_test:.2f}')\n",
    "```\n",
    "````\n",
    "\n",
    "```{admonition} Aufgabe 2\n",
    ":class: tip\n",
    "\n",
    "Der Datensatz 'diabetes.csv' ist eine Sammlung von medizinischen Daten, die vom\n",
    "National Institute of Diabetes and Digestive and Kidney Diseases, erhoben\n",
    "wurden, siehe\n",
    "https://www.kaggle.com/datasets/whenamancodes/predict-diabities?resource=download\n",
    ". Bei Frauen des Pima-Stammes wurden folgende medizinische Daten erhoben:\n",
    "\n",
    "* Pregnancies: Anzahl der Schwangerschaften\t\n",
    "* Glucose: Glukose-Level im Blut\n",
    "* BloodPressure: Messung des Blutdrucks\t\n",
    "* SkinThickness: Dicke der Haut\t\n",
    "* Insulin: Messung des Insulinspiegels im Blut\n",
    "* BMI: Body-Maß-Index (Gewicht geteilt durch Körpergröße ins Quadrat)\t\n",
    "* DiabetesPedigreeFunction: Wahrscheinlichkeit von Diabetes aufgrund der Familienhistorie\t\n",
    "* Age: Alter\t\n",
    "\n",
    "Enthalten ist auch, ob bei der Person Diabetes festgestellt wurde oder nicht.\n",
    "* Outcome: Diabetes = 1, kein Diabetes = 0\t\n",
    "\n",
    "Im letzten Kapitel haben wir bereits ein Perzeptron zur Prognose Diabetes\n",
    "ja/nein trainiert. Vergleichen Sie nun das Perzeptron mit der logistischen\n",
    "Regression. \n",
    "```\n",
    "\n",
    "````{admonition} Lösung\n",
    ":class: tip, toggle\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data.info()\n",
    "```\n",
    "\n",
    "Der Datensatz enthält 768 Einträge. Alle Einträge sind vorhanden und numerisch.\n",
    "Die beiden Eigenschaften BMI und DiabetesPedigreeFunction enthalten Floats, die\n",
    "anderen Eigenschaften werden durch Integers repräsentiert. \n",
    "\n",
    "Als nächstes ermitteln wir die statistischen Kennzahlen.\n",
    "\n",
    "```python\n",
    "data.describe()\n",
    "```\n",
    "\n",
    "Einige Eigenschaften haben 0 als Minimum. Wie in Aufgabe 8.1 analysiert, wurde\n",
    "die 0 wahrscheinlich als NaN missbraucht. Wir korrigieren daher den Datensatz.\n",
    "\n",
    "```python\n",
    "eigenschaften_mit_na = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "for eigenschaft in eigenschaften_mit_na: \n",
    "    zeilen_zum_loeschen = data[ data[eigenschaft] == 0.0 ].index\n",
    "    data = data.drop(zeilen_zum_loeschen)\n",
    "data.info()\n",
    "```\n",
    "\n",
    "Als nächstes trainieren wir das Perzeptron.\n",
    "\n",
    "```python\n",
    "# Auswahl des ML-Modells\n",
    "from sklearn.linear_model import Perceptron\n",
    "model_perceptron = Perceptron()\n",
    "\n",
    "# Adaption der Daten\n",
    "from sklearn.model_selection import train_test_split \n",
    "data_train, data_test = train_test_split(data)\n",
    "\n",
    "X_train = data_train.loc[:, 'Pregnancies' : 'Age']\n",
    "X_test = data_test.loc[:, 'Pregnancies' : 'Age']\n",
    "y_train = data_train['Outcome']\n",
    "y_test = data_test['Outcome']\n",
    "\n",
    "# Training\n",
    "model_perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Validierung\n",
    "score_train = model_perceptron.score(X_train, y_train)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "score_test = model_perceptron.score(X_test, y_test)\n",
    "print(f'Score für Testdaten: {score_test:.2f}')\n",
    "```\n",
    "\n",
    "Nun trainieren wir das logistische Regressionsmodell.\n",
    "\n",
    "```python\n",
    "# Auswahl des ML-Modells\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log_regression = LogisticRegression() \n",
    "\n",
    "# Training\n",
    "model_log_regression.fit(X_train, y_train)\n",
    "\n",
    "# Validierung\n",
    "score_train = model_log_regression.score(X_train, y_train)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "score_test = model_log_regression.score(X_test, y_test)\n",
    "print(f'Score für Testdaten: {score_test:.2f}')\n",
    "```\n",
    "\n",
    "Das logistische Regressionsmodell hat einen besseren Score. Für die\n",
    "Trainingsdaten verbessert sich der Score (für diesen Split der Trainings- und\n",
    "Testdaten) von 0.58 auf 0.75. Für die Testdaten steigt der Score von 0.62 auf\n",
    "0.77.\n",
    "\n",
    "Bemerkung: Es erscheint eine Warnung und die Empfehlung, entweder die Anzahl der\n",
    "Iterationen zu erhöhen oder die Daten zu skalieren. Falls man der Empfehlung\n",
    "folgen wollte, könnte man folgendermaßen die Daten skalieren:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = data['Outcome']\n",
    "X = data.drop('Outcome', axis=1)\n",
    "\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "# Training\n",
    "model_log_regression.fit(X_train, y_train)\n",
    "\n",
    "# Validierung\n",
    "score_train = model_log_regression.score(X_train, y_train)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "score_test = model_log_regression.score(X_test, y_test)\n",
    "print(f'Score für Testdaten: {score_test:.2f}')\n",
    "```\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "source_map": [
   13
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}