<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>9.1 Grundideen der Ensemble-Methoden - Maschinelles Lernen für Ingenieurwissenschaften</title><meta property="og:title" content="9.1 Grundideen der Ensemble-Methoden - Maschinelles Lernen für Ingenieurwissenschaften"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg"/><meta property="og:image" content="/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg"/><link rel="stylesheet" href="/book_ml4ing/build/_assets/app-AIT5GAEP.css"/><link rel="stylesheet" href="/book_ml4ing/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/book_ml4ing/favicon.ico"/><link rel="stylesheet" href="/book_ml4ing/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100vw;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/book_ml4ing/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="Maschinelles Lernen für Ingenieurwissenschaften" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/book_ml4ing/">Maschinelles Lernen für Ingenieurwissenschaften</a><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="1. Grundbegriffe des maschinellen Lernens" class="block break-words rounded py-2 grow cursor-pointer">1. Grundbegriffe des maschinellen Lernens</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2. Crashkurs Python" class="block break-words rounded py-2 grow cursor-pointer">2. Crashkurs Python</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rupsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rupsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="3. Pandas und Plotly anstatt Excel" class="block break-words rounded py-2 grow cursor-pointer">3. Pandas und Plotly anstatt Excel</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="4. Tabellarische Daten" class="block break-words rounded py-2 grow cursor-pointer">4. Tabellarische Daten</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="5. Kategoriale Daten" class="block break-words rounded py-2 grow cursor-pointer">5. Kategoriale Daten</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="6. Entscheidungsbäume (Decision Trees)" class="block break-words rounded py-2 grow cursor-pointer">6. Entscheidungsbäume (Decision Trees)</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1upsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1upsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="7. Lineare Regression" class="block break-words rounded py-2 grow cursor-pointer">7. Lineare Regression</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="8. ML-Workflow Datenvorverarbeitung" class="block break-words rounded py-2 grow cursor-pointer">8. ML-Workflow Datenvorverarbeitung</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="9. Ensemble-Methoden (Random Forests und XGBoost)" class="block break-words rounded py-2 grow cursor-pointer">9. Ensemble-Methoden (Random Forests und XGBoost)</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="10. Support Vector Machines" class="block break-words rounded py-2 grow cursor-pointer">10. Support Vector Machines</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2upsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2upsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="11. ML-Workflow Modellbewertung und Auswahl" class="block break-words rounded py-2 grow cursor-pointer">11. ML-Workflow Modellbewertung und Auswahl</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R36psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="12. Neuronale Netze" class="block break-words rounded py-2 grow cursor-pointer">12. Neuronale Netze</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="myst-made-with-myst flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer" class="myst-fm-license-cc-badge opacity-50 hover:opacity-100 text-inherit hover:text-inherit myst-fm-license-content" aria-label="Content License: Creative Commons Attribution Non Commercial Share Alike 4.0 International (CC-BY-NC-SA-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-main inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial Share Alike 4.0 International (CC-BY-NC-SA-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-by inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-nc inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-sa inline-block mr-1"><title>Adaptations must be shared under the same terms</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm-4.3 6.6c.2-1.2.7-2.1 1.4-2.8.8-.7 1.7-1 2.8-1 1.5 0 2.8.5 3.7 1.5.9 1 1.4 2.3 1.4 3.8s-.5 2.7-1.4 3.7c-.9 1-2.2 1.5-3.7 1.5-1.1 0-2.1-.3-2.9-1-.8-.7-1.3-1.6-1.4-2.8h2.5c.1 1.2.8 1.8 2.1 1.8.7 0 1.2-.3 1.7-.9.4-.6.6-1.4.6-2.4s-.2-1.8-.6-2.4c-.4-.5-.9-.8-1.7-.8-1.3 0-2 .6-2.2 1.7h.7l-1.9 1.9-1.9-1.9.8.1z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="myst-fm-open-access-badge text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-block-open-access-icon mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/gramschs/book_ml4ing" title="GitHub Repository: gramschs/book_ml4ing" target="_blank" rel="noopener noreferrer" class="myst-fm-github-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-github-icon inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div><a href="https://github.com/gramschs/book_ml4ing/edit/main/chapter09/chapter09_sec01.md" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="myst-fm-edit-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-edit-icon inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">9.1 Grundideen der Ensemble-Methoden</h1><header class="myst-fm-authors-affiliations mt-4 not-prose"><div class="myst-fm-authors-list"><span class="myst-fm-author font-semibold text-sm myst-fm-author-item inline-block"><button class="myst-fm-author-popover focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R78ucp:" data-state="closed"><span class="myst-fm-author-name">Simone Gramsch</span></button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><p>Eins, zwei, viele ... im Bereich des maschinellen Lernens sind Ensemble-Methoden
leistungsstarke Techniken zur Verbesserung der Modellgenauigkeit und Robustheit.
Diese Methoden kombinieren mehrere Modelle, um die Gesamtleistung zu steigern,
indem sie die individuellen Stärken der Modelle nutzen und deren Schwächen
ausgleichen. In diesem Kapitel werden wir die grundlegenden Konzepte und
Unterschiede zwischen diesen Methoden erläutern, um ein besseres
Verständnis ihrer Funktionsweise und Anwendungen zu vermitteln.</p><h2 id="lernziele" class="relative group"><span class="heading-text">Lernziele</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lernziele" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><aside class="myst-admonition myst-admonition-attention my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-amber-600 attention"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-amber-600 bg-amber-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-amber-600"><path stroke-linecap="round" stroke-linejoin="round" d="M10.34 15.84c-.688-.06-1.386-.09-2.09-.09H7.5a4.5 4.5 0 1 1 0-9h.75c.704 0 1.402-.03 2.09-.09m0 9.18c.253.962.584 1.892.985 2.783.247.55.06 1.21-.463 1.511l-.657.38c-.551.318-1.26.117-1.527-.461a20.845 20.845 0 0 1-1.44-4.282m3.102.069a18.03 18.03 0 0 1-.59-4.59c0-1.586.205-3.124.59-4.59m0 9.18a23.848 23.848 0 0 1 8.835 2.535M10.34 6.66a23.847 23.847 0 0 0 8.835-2.535m0 0A23.74 23.74 0 0 0 18.795 3m.38 1.125a23.91 23.91 0 0 1 1.014 5.395m-1.014 8.855c-.118.38-.245.754-.38 1.125m.38-1.125a23.91 23.91 0 0 0 1.014-5.395m0-3.46c.495.413.811 1.035.811 1.73 0 .695-.316 1.317-.811 1.73m0-3.46a24.347 24.347 0 0 1 0 3.46"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Lernziele</div></div><div class="myst-admonition-body px-4 py-1"><ul><li><p>Sie können in eigenen Worten erklären, was <strong>Ensemble-Methoden</strong> sind.</p></li><li><p>Sie kennen die Grundideen der Ensemble-Methoden</p><ul><li><p><strong>Voting</strong>,</p></li><li><p><strong>Averaging</strong>,</p></li><li><p><strong>Stacking</strong>,</p></li><li><p><strong>Bagging</strong> und</p></li><li><p><strong>Boosting</strong>.</p></li></ul></li></ul></div></aside><h2 id="ensemble-methoden" class="relative group"><span class="heading-text">Ensemble-Methoden</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#ensemble-methoden" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Der Begriff »Ensemble« wird im Allgemeinen eher mit Musik und Kunst in
Verbindung gebracht als mit Informatik. In der Musik bezeichnet ein Ensemble
eine kleine Gruppe von Musikern, die entweder das gleiche Instrument spielen
oder verschiedene Instrumente kombinieren. Im Theater bezeichnet man eine Gruppe
von Schauspielern ebenfalls als Ensemble, und in der Architektur beschreibt der
Begriff eine Gruppe von Gebäuden, die in einem besonderen Zusammenhang
zueinander stehen.</p><p>Auch im Bereich des maschinellen Lernens hat sich der Begriff Ensemble
etabliert. Mit <strong>Ensemble-Methoden</strong> (Ensemble Learning) wird eine Gruppe von
maschinellen Modellen bezeichnet, die zusammen eine Prognose treffen sollen.
Ähnlich wie bei Musik-Ensembles können bei den Ensemble-Methoden entweder
identische Modelle oder verschiedene Modelle kombiniert werden. Diese Modelle
können entweder gleichzeitig eine Prognose treffen, die dann kombiniert wird,
oder nacheinander verwendet werden, wobei ein nachfolgendes Modell die Fehler
des vorherigen korrigiert. Je nach Vorgehensweise unterscheidet man im
maschinellen Lernen zwischen <strong>Voting</strong>, <strong>Averaging</strong>, <strong>Stacking</strong>,
<strong>Bagging</strong> und <strong>Boosting</strong>.</p><p>In dieser Vorlesung konzentrieren wir uns auf Bagging und Boosting mit ihren
bekanntesten Vertretern, den Random Forests und XGBoost. Die Konzepte Voting und
Averaging sowie Stacking werden hier nur kurz ohne weitere Details vorgestellt.
Eine allgemeine Einführung in Ensemble-Methoden mit Scikit-Learn findet sich in
der <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html" class="">Dokumentation Scikit-Learn →
Ensemble</a>.</p><h2 id="voting-averaging-und-stacking" class="relative group"><span class="heading-text">Voting, Averaging und Stacking</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#voting-averaging-und-stacking" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><figure id="nA6bOnypyJ" class="fig-figure"><img id="sePQORfqD9" style="width:100%;margin-left:auto;margin-right:auto" src="/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg" alt="Die Prognosen von mehreren unterschiedlichen ML-Modellen werden zu einer
finalen Prognose kombiniert. Die Kombination kann beispielsweise durch
Mehrheitsentscheidung (Voting), aber auch Mittelwertbildung (Averaging)
erfolgen." data-canonical-url="pics/concept_voting.svg" class=""/><figcaption class="group"><p>Die Prognosen von mehreren <em>unterschiedlichen</em> ML-Modellen werden zu einer
finalen Prognose kombiniert. Die Kombination kann beispielsweise durch
Mehrheitsentscheidung (Voting), aber auch Mittelwertbildung (Averaging)
erfolgen.</p></figcaption></figure><p>In einem ersten Schritt werden mehrere ML-Modelle unabhängig voneinander auf den
Trainingsdaten trainiert. Jedes dieser Modelle liefert eine Prognose, die dann
auf verschiedene Arten miteinander kombiniert werden können. Bei
Klassifikationsaufgaben ist <strong>Voting</strong>, also die Wahl durch
Mehrheitsentscheidung, eine beliebte Methode, um die Einzelprognosen zu
kombinieren. Wurden beispielsweise drei ML-Modelle gewählt, die jeweils ja oder
nein prognostizieren, dann wird für die finale Prognose das Ergebnis genommen,
das die Mehrheit der einzelnen Modelle vorausgesagt hat. Scikit-Learn bietet
dafür einen Voting Classifier an, siehe <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier" class="">Dokumentation Scikit-Learn → Voting
Classifier</a>.</p><p>Bei Regressionsaufgaben werden die einzelnen Prognosen häufig gemittelt. Beim
<strong>Averaging</strong> kann entweder der übliche arithmetische Mittelwert verwendet
werden oder ein gewichteter Mittelwert, was als Weighted Averaging bezeichnet
wird. Dennoch wird die Mittelwertbildung bei Regressionsaufgaben von
Scikit-Learn ebenfalls als Voting bezeichnet, siehe <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor" class="">Dokumentation Scikit-Learn
→ Voting
Regressor</a>.</p><p>Eine alternative Kombinationsmethode ist die Verwendung eines weiteren
ML-Modells. In diesem Fall werden die Modelle, die die einzelnen Prognosen
liefern, als Basismodelle bezeichnet. Die Basismodelle liefern Features für ein
weiteres ML-Modell, das als Meta-Modell bezeichnet wird. Diese Ensemble-Methode
wird <strong>Stacking</strong> genannt. Weitere Informationen liefert die <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization" class="">Scikit-Learn
Dokumentation → Stacked
Generalization</a>.</p><p>Stacking bietet viele Vorteile. Der wichtigste Vorteil ist, dass die
Prognosefähigkeit des Gesamtmodells in der Regel deutlich besser ist als die der
einzelnen Basismodelle. Die Stärken der Basismodelle werden kombiniert und die
Schwächen ausgeglichen. Allerdings erfordert Stacking sehr viel Feinarbeit. Auch
steigt die Trainingszeit für das Gesamtmodell, selbst wenn die Basismodelle bei
genügend Rechenleistung parallel trainiert werden können. Aus diesem Grund
werden wir in dieser Vorlesung kein Stacking verwenden.</p><h2 id="bagging" class="relative group"><span class="heading-text">Bagging</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#bagging" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><figure id="rCwMIVN1km" class="fig-figure"><img id="J6hwyy8Ade" style="width:100%;margin-left:auto;margin-right:auto" src="/book_ml4ing/build/concept_bagging-8c7a36edab4307c19a7ab398b2233cea.svg" alt="Beim Bagging wird das gleiche ML-Modell auf unterschiedlichen Stichproben der
Trainingsdaten trainiert (Bootstrapping). Die Einzelprognosen der Modelle werden
dann zu einer finalen Prognose kombiniert (Aggregating)." data-canonical-url="pics/concept_bagging.svg" class=""/><figcaption class="group"><p>Beim Bagging wird das gleiche ML-Modell auf <em>unterschiedlichen</em> Stichproben der
Trainingsdaten trainiert (Bootstrapping). Die Einzelprognosen der Modelle werden
dann zu einer finalen Prognose kombiniert (Aggregating).</p></figcaption></figure><p>Bagging ist eine Ensemble-Methode, bei der stets dasselbe Modell für die
Einzelprognosen verwendet wird. Die Unterschiede in den Einzelprognosen
entstehen dadurch, dass für das Training der einzelnen Modelle unterschiedliche
Daten verwendet werden.</p><p>Im ersten Schritt werden zufällige Datenpunkte aus den Trainingsdaten ausgewählt
und in einen neuen Datensatz, „Stichprobe 1“, aufgenommen. Nachdem ein
Datenpunkt ausgewählt wurde, kehrt er in die ursprüngliche Menge der
Trainingsdaten zurück und kann erneut ausgewählt werden. Dieser Prozess wird in
der Mathematik als <strong>Ziehen mit Zurücklegen</strong> bezeichnet, auf Englisch
<strong>Bootstrapping</strong>. Durch Bootstrapping werden dann noch weitere Stichproben
gebildet, wobei jede Stichprobe üblicherweise die gleiche Anzahl an Datenpunkten
wie der ursprüngliche Datensatz enthält.</p><p>Im zweiten Schritt wird ein ML-Modell gewählt und für jede Bootstrap-Stichprobe
trainiert. Da die Stichproben unterschiedliche Trainingsdaten enthalten,
entstehen unterschiedlich trainierte Modelle, die für neue Daten verschiedene
Einzelprognosen liefern. Diese Einzelprognosen werden kombiniert bzw. nach
festgelegten Regeln zu einer finalen Prognose zusammengefasst. In der Statistik
wird die Zusammenfassung von Daten als Aggregation bezeichnet. Auf Englisch
heißt der Vorgang des Zusammenfassens <strong>Aggregating</strong>.</p><p>Die beiden wesentlichen Schritte der Bagging-Methode sind also <strong>B</strong>ootstrapping
und <strong>Agg</strong>regat<strong>ing</strong>, woraus sich die Abkürzung »Bagging« ableitet.
Scikit-Learn bietet sowohl für Klassifikations- als auch für Regressionsaufgaben
eine allgemeine Implementierung der Bagging-Methode an (siehe <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator" class="">Dokumentation
Scikit-Learn →
Bagging</a>).
Die bekannteste Bagging-Methode ist <strong>Random Forests</strong>, bei dem
Entscheidungsbäume (Decision Trees) auf unterschiedlichen Stichproben trainiert
und aggregiert werden. Random Forests werden wir im nächsten Kapitel
detaillierter betrachten. Vorab beschäftigen wir uns noch mit dem Konzept der
Boosting-Methoden.</p><h2 id="boosting" class="relative group"><span class="heading-text">Boosting</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#boosting" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><figure id="UX60avz9RL" class="fig-figure"><img id="Mg0kiU1lOb" style="width:100%;margin-left:auto;margin-right:auto" src="/book_ml4ing/build/concept_boosting-59fef25a9e2e127bf3da4114bd879f12.svg" alt="Der Fehler in der Prognose wird benutzt, um das nächste Modell zu trainieren.
Beim hier gezeigten Adaboost-Verfahren werden die Daten neu gewichtet, beim
(Stochastic) Gradient Boosting werden Modelle zur Fehlerkorrektur trainiert." data-canonical-url="pics/concept_boosting.svg" class=""/><figcaption class="group"><p>Der Fehler in der Prognose wird benutzt, um das nächste Modell zu trainieren.
Beim hier gezeigten Adaboost-Verfahren werden die Daten neu gewichtet, beim
(Stochastic) Gradient Boosting werden Modelle zur Fehlerkorrektur trainiert.</p></figcaption></figure><p>Das englische Verb „to boost sth.“ hat viele Bedeutungen. Insbesondere wird es
im Deutschen mit „etwas verstärken“ übersetzt. Im Kontext des maschinellen
Lernens bezeichnet <strong>Boosting</strong> eine Ensemble-Methode, bei der mehrere ML-Modelle
hintereinander geschaltet werden, um die Genauigkeit der Prognose zu verstärken.
Die Idee des Boosting besteht darin, dass jedes Modell die Fehler des
Vorgängermodells reduziert. Es gibt mehrere Varianten zur Fehlerreduktion, aus
denen sich unterschiedliche Boosting-Methoden ableiten. Die wichtigsten
Varianten sind:</p><ul><li><p>Adaboost,</p></li><li><p>Gradient Boosting und</p></li><li><p>Stochastic Gradient Boosting.</p></li></ul><p>Beim <strong>Adaboost</strong>-Verfahren wird im ersten Schritt ein Modell (z.B. ein
Entscheidungsbaum) auf den Trainingsdaten trainiert. Anschließend werden die
Prognosen dieses Modells mit den tatsächlichen Werten verglichen. Im zweiten
Schritt wird ein neuer Datensatz erstellt, wobei die falsch prognostizierten
Datenpunkte ein größeres Gewicht erhalten. Nun wird erneut ein Modell trainiert;
und dessen Prognosen werden wieder mit den echten Werten verglichen. Dieser
Vorgang wird mehrfach wiederholt. Das Training der Modelle erfolgt sequentiell,
da jedes Vorgängermodell die neue Gewichtung der Trainingsdaten liefert. Am Ende
werden alle Einzelprognosen gewichtet zu einer finalen Prognose kombiniert.
Weitere Details finden sich in der <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost" class="">Dokumentation Scikit-Learn →
Adaboost</a>.</p><p>Beim <strong>Gradient Boosting</strong> wird ebenfalls ein sequentieller Ansatz verfolgt,
aber der Fokus liegt auf der Minimierung der Fehler. Im ersten Schritt wird ein
ML-Modell (häufig ein Entscheidungsbaum) trainiert. Danach wird für jeden
Datenpunkt der Fehler des Modells, das sogenannte <strong>Residuum</strong>, berechnet, indem
die Differenzen zwischen dem tatsächlichen Wert und den Prognosen bestimmt wird.
Im nächsten Schritt wird ein neues Modell trainiert, das darauf abzielt, diese
Residuen vorherzusagen. Dieses neue Modell wird dann zu dem vorherigen Modell
hinzugefügt, um die Gesamtprognose zu verbessern. Dieser Prozess wird
wiederholt, wobei in jeder Iteration ein neues Modell trainiert wird, das die
Fehler der bisherigen Modelle reduziert (mit Hilfe einer Verlustfunktion und
eines Gradientenverfahrens). Am Ende ergibt sich eine starke Vorhersage, indem
alle Modelle kombiniert werden. Da häufig Entscheidungsbäume als Modell gewählt
werden, bietet Scikit-Learn eine Implementierung der sogenannten
<strong>Gradient-Boosted Decision Trees</strong> an, siehe <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosted-trees" class="">Dokumentation Scikit-Learn →
Gradient-boosted
trees</a>.</p><p><strong>Stochastic Gradient Boosting</strong> ist eine Erweiterung des Gradient Boosting, bei
der zusätzlich Stochastik eingeführt wird. Hierbei wird in jedem Schritt nur
eine zufällige Stichprobe der Trainingsdaten verwendet, um ein Modell zu
trainieren. Der Trainingsprozess ähnelt dem von Gradient Boosting, wobei in
jeder Runde ein neues Modell trainiert wird, das die Fehler der vorherigen
Modelle korrigiert. Durch die zufällige Auswahl der Trainingsdaten in jeder
Iteration wird eine höhere Robustheit gegenüber Overfitting (Überanpassung)
erreicht. Stochastic Gradient Boosting wird von Scikit-Learn nicht direkt
unterstützt. Eine sehr bekannte Implementierung davon ist XGBoost (siehe
<a target="_blank" rel="noreferrer" href="https://xgboost.readthedocs.io/en/stable/" class="">https://<wbr/>xgboost<wbr/>.readthedocs<wbr/>.io/</a>),
die wir in einem der nächsten Kapitel noch näher betrachten werden.</p><h2 id="zusammenfassung-und-ausblick" class="relative group"><span class="heading-text">Zusammenfassung und Ausblick</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#zusammenfassung-und-ausblick" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In diesem Kapitel haben Sie die Konzepte Voting, Averaging, Stacking, Bagging
und Boosting kennengelernt. Alle Methoden sind Ensemble-Methoden, bei denen
mehrere ML-Modelle parallel oder sequentiell kombiniert werden. Obwohl diese
Ensemble-Methoden allgemein für verschiedene ML-Modelle eingesetzt werden
können, haben sich vor allem Random Forests (Bagging für Entscheidungsbäume) und
Stochastic Gradient Boosting als besonders effektiv erwiesen. Letztere sind
nicht in Scikit-Learn implementiert, sondern werden durch eine eigene Bibliothek
namens XGBoost bereitgestellt. In den nächsten beiden Kapiteln werden wir beide
auch mit praktischen Beispielen vertiefen.</p><div class="myst-backmatter-parts"></div><div class="myst-footer-links flex pt-10 mb-10 space-x-4"><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-prev" href="/book_ml4ing/chapter08-sec04"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">8. ML-Workflow Datenvorverarbeitung</div>Übungen</div></div></a><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-next" href="/book_ml4ing/chapter09-sec02"><div class="flex h-full align-middle"><div class="flex-grow"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">9. Ensemble-Methoden (Random Forests und XGBoost)</div>9.2 Random Forests</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/book_ml4ing/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-OYMW4E3D.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/book_ml4ing/build/root-CXYA7X5D.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-DATP5P2X.js"/><link rel="modulepreload" href="/book_ml4ing/build/routes/$-JRBPULBO.js"/><script>window.__remixContext = {"url":"/chapter09-sec01","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.7.1","options":{"style":"/book_ml4ing/build/myadmonitions-2678b80ebf14ff136f40b5cf268e40ac.css"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"title":"Maschinelles Lernen für Ingenieurwissenschaften","authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"github":"https://github.com/gramschs/book_ml4ing","id":"8312bbb5-c2ab-495b-accc-a6773ec93d28","toc":[{"file":"intro.md"},{"children":[{"file":"chapter01/chapter01_sec01.md"},{"file":"chapter01/chapter01_sec02.md"},{"file":"chapter01/chapter01_sec03.md"}],"title":"1. Grundbegriffe des maschinellen Lernens"},{"children":[{"file":"chapter02/chapter02_sec01.md"},{"file":"chapter02/chapter02_sec02.md"},{"file":"chapter02/chapter02_sec03.md"},{"file":"chapter02/chapter02_sec04.md"}],"title":"2. Crashkurs Python"},{"children":[{"file":"chapter03/chapter03_sec01.md"},{"file":"chapter03/chapter03_sec02.md"},{"file":"chapter03/chapter03_sec03.md"},{"file":"chapter03/chapter03_sec04.md"}],"title":"3. Pandas und Plotly anstatt Excel"},{"children":[{"file":"chapter04/chapter04_sec01.md"},{"file":"chapter04/chapter04_sec02.md"},{"file":"chapter04/chapter04_sec03.md"},{"file":"chapter04/chapter04_sec04.md"}],"title":"4. Tabellarische Daten"},{"children":[{"file":"chapter05/chapter05_sec01.md"},{"file":"chapter05/chapter05_sec02.md"},{"file":"chapter05/chapter05_sec03.md"},{"file":"chapter05/chapter05_sec04.md"}],"title":"5. Kategoriale Daten"},{"children":[{"file":"chapter06/chapter06_sec01.md"},{"file":"chapter06/chapter06_sec02.md"},{"file":"chapter06/chapter06_sec03.md"},{"file":"chapter06/chapter06_sec04.md"}],"title":"6. Entscheidungsbäume (Decision Trees)"},{"children":[{"file":"chapter07/chapter07_sec01.md"},{"file":"chapter07/chapter07_sec02.md"},{"file":"chapter07/chapter07_sec03.md"},{"file":"chapter07/chapter07_sec04.md"}],"title":"7. Lineare Regression"},{"children":[{"file":"chapter08/chapter08_sec01.md"},{"file":"chapter08/chapter08_sec02.md"},{"file":"chapter08/chapter08_sec03.md"},{"file":"chapter08/chapter08_sec04.md"}],"title":"8. ML-Workflow Datenvorverarbeitung"},{"children":[{"file":"chapter09/chapter09_sec01.md"},{"file":"chapter09/chapter09_sec02.md"},{"file":"chapter09/chapter09_sec03.md"},{"file":"chapter09/chapter09_sec04.md"}],"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"children":[{"file":"chapter10/chapter10_sec01.md"},{"file":"chapter10/chapter10_sec02.md"},{"file":"chapter10/chapter10_sec03.md"},{"file":"chapter10/chapter10_sec04.md"}],"title":"10. Support Vector Machines"},{"children":[{"file":"chapter11/chapter11_sec01.md"},{"file":"chapter11/chapter11_sec02.md"},{"file":"chapter11/chapter11_sec04.md"}],"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"children":[{"file":"chapter12/chapter12_sec01.md"},{"file":"chapter12/chapter12_sec02.md"},{"file":"chapter12/chapter12_sec03.md"}],"title":"12. Neuronale Netze"}],"exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"1. Grundbegriffe des maschinellen Lernens"},{"slug":"chapter01-sec01","title":"1.1 Was ist maschinelles Lernen?","description":"","date":"","thumbnail":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.png","thumbnailOptimized":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec02","title":"1.2 Überwachtes, unüberwachtes und verstärkendes Lernen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec03","title":"1.3 Technische Voraussetzungen","description":"","date":"","thumbnail":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.png","thumbnailOptimized":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"2. Crashkurs Python"},{"slug":"chapter02-sec01","title":"2.1 Datentypen, Variablen und print()","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec02","title":"2.2 Listen und for-Schleifen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec03","title":"2.3 Dictionaries, Funktionen und Methoden","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"3. Pandas und Plotly anstatt Excel"},{"slug":"chapter03-sec01","title":"3.1 Pandas Series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec02","title":"3.2 Statistik mit Pandas","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec03","title":"3.3 Boxplots mit Plotly","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"4. Tabellarische Daten"},{"slug":"chapter04-sec01","title":"4.1 Datenstruktur DataFrame","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec02","title":"4.2 Arbeiten mit Tabellendaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec03","title":"4.3 Scatterplots und Scattermatrix","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"5. Kategoriale Daten"},{"slug":"chapter05-sec01","title":"5.1 Was sind kategoriale Daten?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec02","title":"5.2 Barplots und Histogramme","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec03","title":"5.3 Daten filtern und gruppieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"6. Entscheidungsbäume (Decision Trees)"},{"slug":"chapter06-sec01","title":"6.1 Was ist ein Entscheidungsbaum?","description":"","date":"","thumbnail":"/book_ml4ing/build/combined_decisiontre-828d24d00dcf41e5ebd76c64a833686d.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec02","title":"6.2 Entscheidungsbäume visualisieren und trainieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec03","title":"6.3 Entscheidungsbäume in der Praxis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"7. Lineare Regression"},{"slug":"chapter07-sec01","title":"7.1 Einfache lineare Regression","description":"","date":"","thumbnail":"/book_ml4ing/build/Linear_regression-b0a448b4378e9c4ed49a7896796e35b1.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec02","title":"7.2 Multiple lineare Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec03","title":"7.3 Polynomiale Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"8. ML-Workflow Datenvorverarbeitung"},{"slug":"chapter08-sec01","title":"8.1 Fehlende Daten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec02","title":"8.2 Trainings- und Testdaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec03","title":"8.3 Kodierung und Skalierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"slug":"chapter09-sec01","title":"9.1 Grundideen der Ensemble-Methoden","description":"","date":"","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec02","title":"9.2 Random Forests","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec03","title":"9.3 XGBoost","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"10. Support Vector Machines"},{"slug":"chapter10-sec01","title":"10.1 Maximiere den Rand, aber soft","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.pdf","thumbnailOptimized":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec02","title":"10.2 Training SVM mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec03","title":"10.3 Nichtlineare SVM","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.png","thumbnailOptimized":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"slug":"chapter11-sec01","title":"11.1 Kreuzvalidierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec02","title":"11.2 Gittersuche","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"12. Neuronale Netze"},{"slug":"chapter12-sec01","title":"12.1 Perzeptron = Grundbaustein neuronaler Netze","description":"","date":"","thumbnail":"/book_ml4ing/build/neuron_wikipedia-3eb6913313ac8930bf9e8f1c3c3de9b5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec02","title":"12.2 Mehrschichtiges Perzeptron","description":"","date":"","thumbnail":"/book_ml4ing/build/perceptron-b623483f7ef788fc968924c61cb9287b.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec03","title":"12.3 Neuronale Netze mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/book_ml4ing"},"routes/$":{"config":{"version":3,"myst":"1.7.1","options":{"style":"/book_ml4ing/build/myadmonitions-2678b80ebf14ff136f40b5cf268e40ac.css"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"title":"Maschinelles Lernen für Ingenieurwissenschaften","authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"github":"https://github.com/gramschs/book_ml4ing","id":"8312bbb5-c2ab-495b-accc-a6773ec93d28","toc":[{"file":"intro.md"},{"children":[{"file":"chapter01/chapter01_sec01.md"},{"file":"chapter01/chapter01_sec02.md"},{"file":"chapter01/chapter01_sec03.md"}],"title":"1. Grundbegriffe des maschinellen Lernens"},{"children":[{"file":"chapter02/chapter02_sec01.md"},{"file":"chapter02/chapter02_sec02.md"},{"file":"chapter02/chapter02_sec03.md"},{"file":"chapter02/chapter02_sec04.md"}],"title":"2. Crashkurs Python"},{"children":[{"file":"chapter03/chapter03_sec01.md"},{"file":"chapter03/chapter03_sec02.md"},{"file":"chapter03/chapter03_sec03.md"},{"file":"chapter03/chapter03_sec04.md"}],"title":"3. Pandas und Plotly anstatt Excel"},{"children":[{"file":"chapter04/chapter04_sec01.md"},{"file":"chapter04/chapter04_sec02.md"},{"file":"chapter04/chapter04_sec03.md"},{"file":"chapter04/chapter04_sec04.md"}],"title":"4. Tabellarische Daten"},{"children":[{"file":"chapter05/chapter05_sec01.md"},{"file":"chapter05/chapter05_sec02.md"},{"file":"chapter05/chapter05_sec03.md"},{"file":"chapter05/chapter05_sec04.md"}],"title":"5. Kategoriale Daten"},{"children":[{"file":"chapter06/chapter06_sec01.md"},{"file":"chapter06/chapter06_sec02.md"},{"file":"chapter06/chapter06_sec03.md"},{"file":"chapter06/chapter06_sec04.md"}],"title":"6. Entscheidungsbäume (Decision Trees)"},{"children":[{"file":"chapter07/chapter07_sec01.md"},{"file":"chapter07/chapter07_sec02.md"},{"file":"chapter07/chapter07_sec03.md"},{"file":"chapter07/chapter07_sec04.md"}],"title":"7. Lineare Regression"},{"children":[{"file":"chapter08/chapter08_sec01.md"},{"file":"chapter08/chapter08_sec02.md"},{"file":"chapter08/chapter08_sec03.md"},{"file":"chapter08/chapter08_sec04.md"}],"title":"8. ML-Workflow Datenvorverarbeitung"},{"children":[{"file":"chapter09/chapter09_sec01.md"},{"file":"chapter09/chapter09_sec02.md"},{"file":"chapter09/chapter09_sec03.md"},{"file":"chapter09/chapter09_sec04.md"}],"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"children":[{"file":"chapter10/chapter10_sec01.md"},{"file":"chapter10/chapter10_sec02.md"},{"file":"chapter10/chapter10_sec03.md"},{"file":"chapter10/chapter10_sec04.md"}],"title":"10. Support Vector Machines"},{"children":[{"file":"chapter11/chapter11_sec01.md"},{"file":"chapter11/chapter11_sec02.md"},{"file":"chapter11/chapter11_sec04.md"}],"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"children":[{"file":"chapter12/chapter12_sec01.md"},{"file":"chapter12/chapter12_sec02.md"},{"file":"chapter12/chapter12_sec03.md"}],"title":"12. Neuronale Netze"}],"exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"1. Grundbegriffe des maschinellen Lernens"},{"slug":"chapter01-sec01","title":"1.1 Was ist maschinelles Lernen?","description":"","date":"","thumbnail":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.png","thumbnailOptimized":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec02","title":"1.2 Überwachtes, unüberwachtes und verstärkendes Lernen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec03","title":"1.3 Technische Voraussetzungen","description":"","date":"","thumbnail":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.png","thumbnailOptimized":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"2. Crashkurs Python"},{"slug":"chapter02-sec01","title":"2.1 Datentypen, Variablen und print()","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec02","title":"2.2 Listen und for-Schleifen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec03","title":"2.3 Dictionaries, Funktionen und Methoden","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"3. Pandas und Plotly anstatt Excel"},{"slug":"chapter03-sec01","title":"3.1 Pandas Series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec02","title":"3.2 Statistik mit Pandas","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec03","title":"3.3 Boxplots mit Plotly","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"4. Tabellarische Daten"},{"slug":"chapter04-sec01","title":"4.1 Datenstruktur DataFrame","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec02","title":"4.2 Arbeiten mit Tabellendaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec03","title":"4.3 Scatterplots und Scattermatrix","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"5. Kategoriale Daten"},{"slug":"chapter05-sec01","title":"5.1 Was sind kategoriale Daten?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec02","title":"5.2 Barplots und Histogramme","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec03","title":"5.3 Daten filtern und gruppieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"6. Entscheidungsbäume (Decision Trees)"},{"slug":"chapter06-sec01","title":"6.1 Was ist ein Entscheidungsbaum?","description":"","date":"","thumbnail":"/book_ml4ing/build/combined_decisiontre-828d24d00dcf41e5ebd76c64a833686d.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec02","title":"6.2 Entscheidungsbäume visualisieren und trainieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec03","title":"6.3 Entscheidungsbäume in der Praxis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"7. Lineare Regression"},{"slug":"chapter07-sec01","title":"7.1 Einfache lineare Regression","description":"","date":"","thumbnail":"/book_ml4ing/build/Linear_regression-b0a448b4378e9c4ed49a7896796e35b1.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec02","title":"7.2 Multiple lineare Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec03","title":"7.3 Polynomiale Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"8. ML-Workflow Datenvorverarbeitung"},{"slug":"chapter08-sec01","title":"8.1 Fehlende Daten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec02","title":"8.2 Trainings- und Testdaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec03","title":"8.3 Kodierung und Skalierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"slug":"chapter09-sec01","title":"9.1 Grundideen der Ensemble-Methoden","description":"","date":"","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec02","title":"9.2 Random Forests","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec03","title":"9.3 XGBoost","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"10. Support Vector Machines"},{"slug":"chapter10-sec01","title":"10.1 Maximiere den Rand, aber soft","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.pdf","thumbnailOptimized":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec02","title":"10.2 Training SVM mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec03","title":"10.3 Nichtlineare SVM","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.png","thumbnailOptimized":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"slug":"chapter11-sec01","title":"11.1 Kreuzvalidierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec02","title":"11.2 Gittersuche","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"12. Neuronale Netze"},{"slug":"chapter12-sec01","title":"12.1 Perzeptron = Grundbaustein neuronaler Netze","description":"","date":"","thumbnail":"/book_ml4ing/build/neuron_wikipedia-3eb6913313ac8930bf9e8f1c3c3de9b5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec02","title":"12.2 Mehrschichtiges Perzeptron","description":"","date":"","thumbnail":"/book_ml4ing/build/perceptron-b623483f7ef788fc968924c61cb9287b.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec03","title":"12.3 Neuronale Netze mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":3,"kind":"Notebook","sha256":"2b0e0aa5484119987cca28432285812cedeb1f9b4245fe0ec41c5b1292404388","slug":"chapter09-sec01","location":"/chapter09/chapter09_sec01.md","dependencies":[],"frontmatter":{"title":"9.1 Grundideen der Ensemble-Methoden","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"jupytext":{"formats":"ipynb,md:myst","text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.15.2"}},"content_includes_title":false,"authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"github":"https://github.com/gramschs/book_ml4ing","numbering":{"title":{"offset":1}},"source_url":"https://github.com/gramschs/book_ml4ing/blob/main/chapter09/chapter09_sec01.md","edit_url":"https://github.com/gramschs/book_ml4ing/edit/main/chapter09/chapter09_sec01.md","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","exports":[{"format":"md","filename":"chapter09_sec01.md","url":"/book_ml4ing/build/chapter09_sec01-740bede0a38be1d4175324c30cc0cb6b.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Eins, zwei, viele ... im Bereich des maschinellen Lernens sind Ensemble-Methoden\nleistungsstarke Techniken zur Verbesserung der Modellgenauigkeit und Robustheit.\nDiese Methoden kombinieren mehrere Modelle, um die Gesamtleistung zu steigern,\nindem sie die individuellen Stärken der Modelle nutzen und deren Schwächen\nausgleichen. In diesem Kapitel werden wir die grundlegenden Konzepte und\nUnterschiede zwischen diesen Methoden erläutern, um ein besseres\nVerständnis ihrer Funktionsweise und Anwendungen zu vermitteln.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"oiMYQd1ov5"}],"key":"SVPEygQBJG"},{"type":"heading","depth":2,"position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Lernziele","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"PbsyU4v2dS"}],"identifier":"lernziele","label":"Lernziele","html_id":"lernziele","implicit":true,"key":"jtq2AudYE8"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Lernziele","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"p1XoYNlJxe"}],"key":"DXPtFFX8sJ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":29,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie können in eigenen Worten erklären, was ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"ZksF3xTlZq"},{"type":"strong","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Ensemble-Methoden","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"U4L70F0QJE"}],"key":"W75B5jrJUX"},{"type":"text","value":" sind.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"UiBEK7BUam"}],"key":"m6G3Vh2Y4R"}],"key":"VpFsOHKdhj"},{"type":"listItem","spread":true,"position":{"start":{"line":30,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie kennen die Grundideen der Ensemble-Methoden","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"RvT81oG9wp"}],"key":"OXd0bT0jnc"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":31,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Voting","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"V509DywQNq"}],"key":"aKD6WzmJR9"},{"type":"text","value":",","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"OfYkacIt2e"}],"key":"O2OSHz2DMX"}],"key":"twUZGFLEZb"},{"type":"listItem","spread":true,"position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Averaging","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"UYhGt4lrgd"}],"key":"ehLMo5aMpu"},{"type":"text","value":",","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"qqPWi2GXo2"}],"key":"EYaomhf4LS"}],"key":"sTIAdOESLx"},{"type":"listItem","spread":true,"position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Stacking","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"gae7qFWDf7"}],"key":"zZlEncrpz0"},{"type":"text","value":",","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"kreCdqv5q1"}],"key":"YBPNds9MmW"}],"key":"y1njudhSXc"},{"type":"listItem","spread":true,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Bagging","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"FSycciIrHD"}],"key":"qdP4wNemGU"},{"type":"text","value":" und","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"ZK4z0hiYLp"}],"key":"WI0UIjNmch"}],"key":"RIlJcj7zMu"},{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Boosting","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"M4h3afXE5s"}],"key":"RxzTxOQPoY"},{"type":"text","value":".","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"AB5whMb7DL"}],"key":"cKimyYfKNp"}],"key":"vlzq9WQcL5"}],"key":"jhC3wiX3sr"}],"key":"OIdmGRDtum"}],"key":"hThkCZ7Qgw"}],"class":"attention","key":"LLBLzsL8dB"},{"type":"heading","depth":2,"position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Ensemble-Methoden","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"OTAir39N1K"}],"identifier":"ensemble-methoden","label":"Ensemble-Methoden","html_id":"ensemble-methoden","implicit":true,"key":"wMQsX5p2x8"},{"type":"paragraph","position":{"start":{"line":40,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Der Begriff »Ensemble« wird im Allgemeinen eher mit Musik und Kunst in\nVerbindung gebracht als mit Informatik. In der Musik bezeichnet ein Ensemble\neine kleine Gruppe von Musikern, die entweder das gleiche Instrument spielen\noder verschiedene Instrumente kombinieren. Im Theater bezeichnet man eine Gruppe\nvon Schauspielern ebenfalls als Ensemble, und in der Architektur beschreibt der\nBegriff eine Gruppe von Gebäuden, die in einem besonderen Zusammenhang\nzueinander stehen.","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"ZF8Z3JKmaE"}],"key":"My2PvKV7V8"},{"type":"paragraph","position":{"start":{"line":48,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"Auch im Bereich des maschinellen Lernens hat sich der Begriff Ensemble\netabliert. Mit ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"X2UzJy7a15"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Ensemble-Methoden","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"RIBe4mIio5"}],"key":"X2ZxgGZhx1"},{"type":"text","value":" (Ensemble Learning) wird eine Gruppe von\nmaschinellen Modellen bezeichnet, die zusammen eine Prognose treffen sollen.\nÄhnlich wie bei Musik-Ensembles können bei den Ensemble-Methoden entweder\nidentische Modelle oder verschiedene Modelle kombiniert werden. Diese Modelle\nkönnen entweder gleichzeitig eine Prognose treffen, die dann kombiniert wird,\noder nacheinander verwendet werden, wobei ein nachfolgendes Modell die Fehler\ndes vorherigen korrigiert. Je nach Vorgehensweise unterscheidet man im\nmaschinellen Lernen zwischen ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"YDxCmRVZrr"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Voting","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"W37SWF5iAQ"}],"key":"uGF0y0yuur"},{"type":"text","value":", ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"b5ewtMp2uJ"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Averaging","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"AP5tpYV7Ax"}],"key":"mhLwI1b0nP"},{"type":"text","value":", ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"H0qoe65OHZ"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Stacking","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"XBrryb2bFt"}],"key":"ovrzRK6DMl"},{"type":"text","value":",\n","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"U1OBbLqptl"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Bagging","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"K3aLCmAmso"}],"key":"Cyaxkeox2o"},{"type":"text","value":" und ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"AOGe8eot2b"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Boosting","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"PIIkxjvrvr"}],"key":"TsFGQxq1t3"},{"type":"text","value":".","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"ymUtmP81pG"}],"key":"rZeOYPEitN"},{"type":"paragraph","position":{"start":{"line":59,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"In dieser Vorlesung konzentrieren wir uns auf Bagging und Boosting mit ihren\nbekanntesten Vertretern, den Random Forests und XGBoost. Die Konzepte Voting und\nAveraging sowie Stacking werden hier nur kurz ohne weitere Details vorgestellt.\nEine allgemeine Einführung in Ensemble-Methoden mit Scikit-Learn findet sich in\nder ","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"w46AsfY6UP"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"Dokumentation Scikit-Learn →\nEnsemble","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"hhoSO700BZ"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html","key":"eO2wLOKCUR"},{"type":"text","value":".","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"Ej4KTVrGnI"}],"key":"Lz24SlRrIt"},{"type":"heading","depth":2,"position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Voting, Averaging und Stacking","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"wQ3b2uriAw"}],"identifier":"voting-averaging-und-stacking","label":"Voting, Averaging und Stacking","html_id":"voting-averaging-und-stacking","implicit":true,"key":"v4GWP253O8"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","alt":"Die Prognosen von mehreren unterschiedlichen ML-Modellen werden zu einer\nfinalen Prognose kombiniert. Die Kombination kann beispielsweise durch\nMehrheitsentscheidung (Voting), aber auch Mittelwertbildung (Averaging)\nerfolgen.","width":"100%","data":{"altTextIsAutoGenerated":true},"key":"sePQORfqD9","urlSource":"pics/concept_voting.svg"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":72,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"text","value":"Die Prognosen von mehreren ","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"Vth6CZiNnp"},{"type":"emphasis","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"children":[{"type":"text","value":"unterschiedlichen","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"F79YEoUTDT"}],"key":"dOqHDkrgWP"},{"type":"text","value":" ML-Modellen werden zu einer\nfinalen Prognose kombiniert. Die Kombination kann beispielsweise durch\nMehrheitsentscheidung (Voting), aber auch Mittelwertbildung (Averaging)\nerfolgen.","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"VA5LiTrtwJ"}],"key":"VwefHnG0Vn"}],"key":"KE8gU4ZlPn"}],"enumerator":"1","key":"nA6bOnypyJ"},{"type":"paragraph","position":{"start":{"line":78,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"text","value":"In einem ersten Schritt werden mehrere ML-Modelle unabhängig voneinander auf den\nTrainingsdaten trainiert. Jedes dieser Modelle liefert eine Prognose, die dann\nauf verschiedene Arten miteinander kombiniert werden können. Bei\nKlassifikationsaufgaben ist ","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"qQKI0sz4kw"},{"type":"strong","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"text","value":"Voting","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"X5cRb59ddn"}],"key":"F6cYvXZymC"},{"type":"text","value":", also die Wahl durch\nMehrheitsentscheidung, eine beliebte Methode, um die Einzelprognosen zu\nkombinieren. Wurden beispielsweise drei ML-Modelle gewählt, die jeweils ja oder\nnein prognostizieren, dann wird für die finale Prognose das Ergebnis genommen,\ndas die Mehrheit der einzelnen Modelle vorausgesagt hat. Scikit-Learn bietet\ndafür einen Voting Classifier an, siehe ","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"buzhNQygvn"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"text","value":"Dokumentation Scikit-Learn → Voting\nClassifier","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"tfGRG23S4t"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier","key":"tlEB3gYD56"},{"type":"text","value":".","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"dHFjriOcEb"}],"key":"uCz394HK8s"},{"type":"paragraph","position":{"start":{"line":89,"column":1},"end":{"line":95,"column":1}},"children":[{"type":"text","value":"Bei Regressionsaufgaben werden die einzelnen Prognosen häufig gemittelt. Beim\n","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"IpgziUg8Zq"},{"type":"strong","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"text","value":"Averaging","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"akdavEAzFK"}],"key":"G6cTIeiiYa"},{"type":"text","value":" kann entweder der übliche arithmetische Mittelwert verwendet\nwerden oder ein gewichteter Mittelwert, was als Weighted Averaging bezeichnet\nwird. Dennoch wird die Mittelwertbildung bei Regressionsaufgaben von\nScikit-Learn ebenfalls als Voting bezeichnet, siehe ","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"eUfiCiRRx6"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"text","value":"Dokumentation Scikit-Learn\n→ Voting\nRegressor","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"UjLkMm1mn9"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor","key":"IHOG6R8PMN"},{"type":"text","value":".","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"GzsrIYxglA"}],"key":"AIswWDjMLh"},{"type":"paragraph","position":{"start":{"line":97,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Eine alternative Kombinationsmethode ist die Verwendung eines weiteren\nML-Modells. In diesem Fall werden die Modelle, die die einzelnen Prognosen\nliefern, als Basismodelle bezeichnet. Die Basismodelle liefern Features für ein\nweiteres ML-Modell, das als Meta-Modell bezeichnet wird. Diese Ensemble-Methode\nwird ","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"Gu2TZas7Dv"},{"type":"strong","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"children":[{"type":"text","value":"Stacking","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"miXD2Ks659"}],"key":"kiUVq47dmY"},{"type":"text","value":" genannt. Weitere Informationen liefert die ","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"O29sVzCwab"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"children":[{"type":"text","value":"Scikit-Learn\nDokumentation → Stacked\nGeneralization","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"csRYdnQtcg"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization","key":"i77ktRhxxN"},{"type":"text","value":".","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"NYWDUFwVJR"}],"key":"leSgaMFVkJ"},{"type":"paragraph","position":{"start":{"line":105,"column":1},"end":{"line":111,"column":1}},"children":[{"type":"text","value":"Stacking bietet viele Vorteile. Der wichtigste Vorteil ist, dass die\nPrognosefähigkeit des Gesamtmodells in der Regel deutlich besser ist als die der\neinzelnen Basismodelle. Die Stärken der Basismodelle werden kombiniert und die\nSchwächen ausgeglichen. Allerdings erfordert Stacking sehr viel Feinarbeit. Auch\nsteigt die Trainingszeit für das Gesamtmodell, selbst wenn die Basismodelle bei\ngenügend Rechenleistung parallel trainiert werden können. Aus diesem Grund\nwerden wir in dieser Vorlesung kein Stacking verwenden.","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"key":"tmxvJACuTY"}],"key":"W2OCYbnUWY"},{"type":"heading","depth":2,"position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"children":[{"type":"text","value":"Bagging","position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"key":"Eqn2DzJEjo"}],"identifier":"bagging","label":"Bagging","html_id":"bagging","implicit":true,"key":"NIseGQLjlH"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/book_ml4ing/build/concept_bagging-8c7a36edab4307c19a7ab398b2233cea.svg","alt":"Beim Bagging wird das gleiche ML-Modell auf unterschiedlichen Stichproben der\nTrainingsdaten trainiert (Bootstrapping). Die Einzelprognosen der Modelle werden\ndann zu einer finalen Prognose kombiniert (Aggregating).","width":"100%","data":{"altTextIsAutoGenerated":true},"key":"J6hwyy8Ade","urlSource":"pics/concept_bagging.svg"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":119,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"text","value":"Beim Bagging wird das gleiche ML-Modell auf ","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"qg3sOvXiaq"},{"type":"emphasis","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"children":[{"type":"text","value":"unterschiedlichen","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"octsJH2I9i"}],"key":"W17Ag0mMGx"},{"type":"text","value":" Stichproben der\nTrainingsdaten trainiert (Bootstrapping). Die Einzelprognosen der Modelle werden\ndann zu einer finalen Prognose kombiniert (Aggregating).","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"HZRgzV3o1y"}],"key":"iY2pyv0pQ1"}],"key":"eir5fcdBXQ"}],"enumerator":"2","key":"rCwMIVN1km"},{"type":"paragraph","position":{"start":{"line":124,"column":1},"end":{"line":127,"column":1}},"children":[{"type":"text","value":"Bagging ist eine Ensemble-Methode, bei der stets dasselbe Modell für die\nEinzelprognosen verwendet wird. Die Unterschiede in den Einzelprognosen\nentstehen dadurch, dass für das Training der einzelnen Modelle unterschiedliche\nDaten verwendet werden.","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"WL3Ea4oLyF"}],"key":"lP6TWNZ0PE"},{"type":"paragraph","position":{"start":{"line":129,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"Im ersten Schritt werden zufällige Datenpunkte aus den Trainingsdaten ausgewählt\nund in einen neuen Datensatz, „Stichprobe 1“, aufgenommen. Nachdem ein\nDatenpunkt ausgewählt wurde, kehrt er in die ursprüngliche Menge der\nTrainingsdaten zurück und kann erneut ausgewählt werden. Dieser Prozess wird in\nder Mathematik als ","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"LmtYXFczpN"},{"type":"strong","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"children":[{"type":"text","value":"Ziehen mit Zurücklegen","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"V36oKfMiFm"}],"key":"kaBPYYdRFa"},{"type":"text","value":" bezeichnet, auf Englisch\n","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"weZaqPtVbF"},{"type":"strong","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"children":[{"type":"text","value":"Bootstrapping","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"Q1tn5ITJrJ"}],"key":"yqbDO370Xk"},{"type":"text","value":". Durch Bootstrapping werden dann noch weitere Stichproben\ngebildet, wobei jede Stichprobe üblicherweise die gleiche Anzahl an Datenpunkten\nwie der ursprüngliche Datensatz enthält.","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"XZSkysXi9g"}],"key":"uZIlPuwyXr"},{"type":"paragraph","position":{"start":{"line":138,"column":1},"end":{"line":144,"column":1}},"children":[{"type":"text","value":"Im zweiten Schritt wird ein ML-Modell gewählt und für jede Bootstrap-Stichprobe\ntrainiert. Da die Stichproben unterschiedliche Trainingsdaten enthalten,\nentstehen unterschiedlich trainierte Modelle, die für neue Daten verschiedene\nEinzelprognosen liefern. Diese Einzelprognosen werden kombiniert bzw. nach\nfestgelegten Regeln zu einer finalen Prognose zusammengefasst. In der Statistik\nwird die Zusammenfassung von Daten als Aggregation bezeichnet. Auf Englisch\nheißt der Vorgang des Zusammenfassens ","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"lcwqTlvBRH"},{"type":"strong","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"children":[{"type":"text","value":"Aggregating","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"NbqPdGygQW"}],"key":"ihqGRQmfth"},{"type":"text","value":".","position":{"start":{"line":138,"column":1},"end":{"line":138,"column":1}},"key":"Jya8hIMqk0"}],"key":"Kr03gcsNfF"},{"type":"paragraph","position":{"start":{"line":146,"column":1},"end":{"line":156,"column":1}},"children":[{"type":"text","value":"Die beiden wesentlichen Schritte der Bagging-Methode sind also ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"hrByClDD1T"},{"type":"strong","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"B","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"aNJn1lkMLq"}],"key":"OrfubCejVK"},{"type":"text","value":"ootstrapping\nund ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"nnzlP18fWw"},{"type":"strong","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"Agg","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"myiEWfykdT"}],"key":"LZyOix7Dru"},{"type":"text","value":"regat","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"wMGENHroZF"},{"type":"strong","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"ing","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"sY81OgFxcW"}],"key":"wq3c32FBDM"},{"type":"text","value":", woraus sich die Abkürzung »Bagging« ableitet.\nScikit-Learn bietet sowohl für Klassifikations- als auch für Regressionsaufgaben\neine allgemeine Implementierung der Bagging-Methode an (siehe ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"ARY50vzcL7"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"Dokumentation\nScikit-Learn →\nBagging","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"z7dmqKISF6"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator","key":"A8cxBZuW1Y"},{"type":"text","value":").\nDie bekannteste Bagging-Methode ist ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"XvSm2PT41w"},{"type":"strong","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"Random Forests","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"KPmJoGu7Ph"}],"key":"UZyKg5JOER"},{"type":"text","value":", bei dem\nEntscheidungsbäume (Decision Trees) auf unterschiedlichen Stichproben trainiert\nund aggregiert werden. Random Forests werden wir im nächsten Kapitel\ndetaillierter betrachten. Vorab beschäftigen wir uns noch mit dem Konzept der\nBoosting-Methoden.","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"uxvq4i6A7G"}],"key":"as817J8N85"},{"type":"heading","depth":2,"position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"children":[{"type":"text","value":"Boosting","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"VewwK7aHfb"}],"identifier":"boosting","label":"Boosting","html_id":"boosting","implicit":true,"key":"WVv3svXlGx"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/book_ml4ing/build/concept_boosting-59fef25a9e2e127bf3da4114bd879f12.svg","alt":"Der Fehler in der Prognose wird benutzt, um das nächste Modell zu trainieren.\nBeim hier gezeigten Adaboost-Verfahren werden die Daten neu gewichtet, beim\n(Stochastic) Gradient Boosting werden Modelle zur Fehlerkorrektur trainiert.","width":"100%","data":{"altTextIsAutoGenerated":true},"key":"Mg0kiU1lOb","urlSource":"pics/concept_boosting.svg"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":164,"column":1},"end":{"line":166,"column":1}},"children":[{"type":"text","value":"Der Fehler in der Prognose wird benutzt, um das nächste Modell zu trainieren.\nBeim hier gezeigten Adaboost-Verfahren werden die Daten neu gewichtet, beim\n(Stochastic) Gradient Boosting werden Modelle zur Fehlerkorrektur trainiert.","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"key":"vr2KmGaH8X"}],"key":"TOKC7FsxjD"}],"key":"vPRsroSrlL"}],"enumerator":"3","key":"UX60avz9RL"},{"type":"paragraph","position":{"start":{"line":169,"column":1},"end":{"line":176,"column":1}},"children":[{"type":"text","value":"Das englische Verb „to boost sth.“ hat viele Bedeutungen. Insbesondere wird es\nim Deutschen mit „etwas verstärken“ übersetzt. Im Kontext des maschinellen\nLernens bezeichnet ","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"SaT57M4aiI"},{"type":"strong","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"children":[{"type":"text","value":"Boosting","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"yvevtdHo4l"}],"key":"Hm9VC2FG95"},{"type":"text","value":" eine Ensemble-Methode, bei der mehrere ML-Modelle\nhintereinander geschaltet werden, um die Genauigkeit der Prognose zu verstärken.\nDie Idee des Boosting besteht darin, dass jedes Modell die Fehler des\nVorgängermodells reduziert. Es gibt mehrere Varianten zur Fehlerreduktion, aus\ndenen sich unterschiedliche Boosting-Methoden ableiten. Die wichtigsten\nVarianten sind:","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"GKWyjRPAcM"}],"key":"lfWcsr1qpk"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":178,"column":1},"end":{"line":181,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":178,"column":1},"end":{"line":178,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Adaboost,","position":{"start":{"line":178,"column":1},"end":{"line":178,"column":1}},"key":"qxU6jV8U2G"}],"key":"E7w9SNyu8r"}],"key":"hGFZNwnSLv"},{"type":"listItem","spread":true,"position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Gradient Boosting und","position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"key":"w8nxOyE6kx"}],"key":"tvuqdxnZGa"}],"key":"eTi4HySwRV"},{"type":"listItem","spread":true,"position":{"start":{"line":180,"column":1},"end":{"line":181,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Stochastic Gradient Boosting.","position":{"start":{"line":180,"column":1},"end":{"line":180,"column":1}},"key":"E3nv2ouFrm"}],"key":"lJTuxCAX3Z"}],"key":"IwCvy1XpmA"}],"key":"Y2P8n6Bumo"},{"type":"paragraph","position":{"start":{"line":182,"column":1},"end":{"line":192,"column":1}},"children":[{"type":"text","value":"Beim ","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"M1Nm2qnXeW"},{"type":"strong","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"children":[{"type":"text","value":"Adaboost","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"kyn9zmIE4D"}],"key":"B824qi1eC8"},{"type":"text","value":"-Verfahren wird im ersten Schritt ein Modell (z.B. ein\nEntscheidungsbaum) auf den Trainingsdaten trainiert. Anschließend werden die\nPrognosen dieses Modells mit den tatsächlichen Werten verglichen. Im zweiten\nSchritt wird ein neuer Datensatz erstellt, wobei die falsch prognostizierten\nDatenpunkte ein größeres Gewicht erhalten. Nun wird erneut ein Modell trainiert;\nund dessen Prognosen werden wieder mit den echten Werten verglichen. Dieser\nVorgang wird mehrfach wiederholt. Das Training der Modelle erfolgt sequentiell,\nda jedes Vorgängermodell die neue Gewichtung der Trainingsdaten liefert. Am Ende\nwerden alle Einzelprognosen gewichtet zu einer finalen Prognose kombiniert.\nWeitere Details finden sich in der ","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"jJHy4QUO9T"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html#adaboost","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"children":[{"type":"text","value":"Dokumentation Scikit-Learn →\nAdaboost","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"N9VTpZhxtd"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html#adaboost","key":"RihGJApUx2"},{"type":"text","value":".","position":{"start":{"line":182,"column":1},"end":{"line":182,"column":1}},"key":"hIslIYVgFm"}],"key":"lDBOkEFQoI"},{"type":"paragraph","position":{"start":{"line":194,"column":1},"end":{"line":209,"column":1}},"children":[{"type":"text","value":"Beim ","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"ltstGNcEVr"},{"type":"strong","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"children":[{"type":"text","value":"Gradient Boosting","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"aQJCoCKjdF"}],"key":"Y8xFtKUIis"},{"type":"text","value":" wird ebenfalls ein sequentieller Ansatz verfolgt,\naber der Fokus liegt auf der Minimierung der Fehler. Im ersten Schritt wird ein\nML-Modell (häufig ein Entscheidungsbaum) trainiert. Danach wird für jeden\nDatenpunkt der Fehler des Modells, das sogenannte ","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"IVe99jd6In"},{"type":"strong","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"children":[{"type":"text","value":"Residuum","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"oFwvvmvCeS"}],"key":"wISd1F9oWI"},{"type":"text","value":", berechnet, indem\ndie Differenzen zwischen dem tatsächlichen Wert und den Prognosen bestimmt wird.\nIm nächsten Schritt wird ein neues Modell trainiert, das darauf abzielt, diese\nResiduen vorherzusagen. Dieses neue Modell wird dann zu dem vorherigen Modell\nhinzugefügt, um die Gesamtprognose zu verbessern. Dieser Prozess wird\nwiederholt, wobei in jeder Iteration ein neues Modell trainiert wird, das die\nFehler der bisherigen Modelle reduziert (mit Hilfe einer Verlustfunktion und\neines Gradientenverfahrens). Am Ende ergibt sich eine starke Vorhersage, indem\nalle Modelle kombiniert werden. Da häufig Entscheidungsbäume als Modell gewählt\nwerden, bietet Scikit-Learn eine Implementierung der sogenannten\n","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"EUj2HKqJlB"},{"type":"strong","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"children":[{"type":"text","value":"Gradient-Boosted Decision Trees","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"Mdjjt18cuP"}],"key":"IHheipJZ6O"},{"type":"text","value":" an, siehe ","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"ycDf98oDkk"},{"type":"link","url":"https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosted-trees","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"children":[{"type":"text","value":"Dokumentation Scikit-Learn →\nGradient-boosted\ntrees","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"bEVlmwXi8O"}],"urlSource":"https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosted-trees","key":"JojPOFiTfW"},{"type":"text","value":".","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"DfFbQavOyx"}],"key":"xYoX7ZJsEB"},{"type":"paragraph","position":{"start":{"line":211,"column":1},"end":{"line":221,"column":1}},"children":[{"type":"strong","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"text","value":"Stochastic Gradient Boosting","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"AL7Z1plus3"}],"key":"Wnt7o8z24R"},{"type":"text","value":" ist eine Erweiterung des Gradient Boosting, bei\nder zusätzlich Stochastik eingeführt wird. Hierbei wird in jedem Schritt nur\neine zufällige Stichprobe der Trainingsdaten verwendet, um ein Modell zu\ntrainieren. Der Trainingsprozess ähnelt dem von Gradient Boosting, wobei in\njeder Runde ein neues Modell trainiert wird, das die Fehler der vorherigen\nModelle korrigiert. Durch die zufällige Auswahl der Trainingsdaten in jeder\nIteration wird eine höhere Robustheit gegenüber Overfitting (Überanpassung)\nerreicht. Stochastic Gradient Boosting wird von Scikit-Learn nicht direkt\nunterstützt. Eine sehr bekannte Implementierung davon ist XGBoost (siehe\n","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"mEuDjGUYOx"},{"type":"link","url":"https://xgboost.readthedocs.io/en/stable/","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"text","value":"https://​xgboost​.readthedocs​.io/","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"J2tkwHbEwt"}],"urlSource":"https://xgboost.readthedocs.io/en/stable/","key":"IskX2RIFji"},{"type":"text","value":"),\ndie wir in einem der nächsten Kapitel noch näher betrachten werden.","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"YnUMzuVQJB"}],"key":"TQ56YzTiEM"},{"type":"heading","depth":2,"position":{"start":{"line":223,"column":1},"end":{"line":223,"column":1}},"children":[{"type":"text","value":"Zusammenfassung und Ausblick","position":{"start":{"line":223,"column":1},"end":{"line":223,"column":1}},"key":"o3xL9zFhuH"}],"identifier":"zusammenfassung-und-ausblick","label":"Zusammenfassung und Ausblick","html_id":"zusammenfassung-und-ausblick","implicit":true,"key":"dBoo9DytYL"},{"type":"paragraph","position":{"start":{"line":225,"column":1},"end":{"line":233,"column":1}},"children":[{"type":"text","value":"In diesem Kapitel haben Sie die Konzepte Voting, Averaging, Stacking, Bagging\nund Boosting kennengelernt. Alle Methoden sind Ensemble-Methoden, bei denen\nmehrere ML-Modelle parallel oder sequentiell kombiniert werden. Obwohl diese\nEnsemble-Methoden allgemein für verschiedene ML-Modelle eingesetzt werden\nkönnen, haben sich vor allem Random Forests (Bagging für Entscheidungsbäume) und\nStochastic Gradient Boosting als besonders effektiv erwiesen. Letztere sind\nnicht in Scikit-Learn implementiert, sondern werden durch eine eigene Bibliothek\nnamens XGBoost bereitgestellt. In den nächsten beiden Kapiteln werden wir beide\nauch mit praktischen Beispielen vertiefen.","position":{"start":{"line":225,"column":1},"end":{"line":225,"column":1}},"key":"rb4XbKk1CC"}],"key":"nXrPIMAcAZ"}],"key":"SpVga862nB"}],"key":"s1DUcxem8v"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Übungen","url":"/chapter08-sec04","group":"8. ML-Workflow Datenvorverarbeitung"},"next":{"title":"9.2 Random Forests","url":"/chapter09-sec02","group":"9. Ensemble-Methoden (Random Forests und XGBoost)"}}},"domain":"http://localhost:3004"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"title":"Maschinelles Lernen für Ingenieurwissenschaften","authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"github":"https://github.com/gramschs/book_ml4ing","id":"8312bbb5-c2ab-495b-accc-a6773ec93d28","toc":[{"file":"intro.md"},{"children":[{"file":"chapter01/chapter01_sec01.md"},{"file":"chapter01/chapter01_sec02.md"},{"file":"chapter01/chapter01_sec03.md"}],"title":"1. Grundbegriffe des maschinellen Lernens"},{"children":[{"file":"chapter02/chapter02_sec01.md"},{"file":"chapter02/chapter02_sec02.md"},{"file":"chapter02/chapter02_sec03.md"},{"file":"chapter02/chapter02_sec04.md"}],"title":"2. Crashkurs Python"},{"children":[{"file":"chapter03/chapter03_sec01.md"},{"file":"chapter03/chapter03_sec02.md"},{"file":"chapter03/chapter03_sec03.md"},{"file":"chapter03/chapter03_sec04.md"}],"title":"3. Pandas und Plotly anstatt Excel"},{"children":[{"file":"chapter04/chapter04_sec01.md"},{"file":"chapter04/chapter04_sec02.md"},{"file":"chapter04/chapter04_sec03.md"},{"file":"chapter04/chapter04_sec04.md"}],"title":"4. Tabellarische Daten"},{"children":[{"file":"chapter05/chapter05_sec01.md"},{"file":"chapter05/chapter05_sec02.md"},{"file":"chapter05/chapter05_sec03.md"},{"file":"chapter05/chapter05_sec04.md"}],"title":"5. Kategoriale Daten"},{"children":[{"file":"chapter06/chapter06_sec01.md"},{"file":"chapter06/chapter06_sec02.md"},{"file":"chapter06/chapter06_sec03.md"},{"file":"chapter06/chapter06_sec04.md"}],"title":"6. Entscheidungsbäume (Decision Trees)"},{"children":[{"file":"chapter07/chapter07_sec01.md"},{"file":"chapter07/chapter07_sec02.md"},{"file":"chapter07/chapter07_sec03.md"},{"file":"chapter07/chapter07_sec04.md"}],"title":"7. Lineare Regression"},{"children":[{"file":"chapter08/chapter08_sec01.md"},{"file":"chapter08/chapter08_sec02.md"},{"file":"chapter08/chapter08_sec03.md"},{"file":"chapter08/chapter08_sec04.md"}],"title":"8. ML-Workflow Datenvorverarbeitung"},{"children":[{"file":"chapter09/chapter09_sec01.md"},{"file":"chapter09/chapter09_sec02.md"},{"file":"chapter09/chapter09_sec03.md"},{"file":"chapter09/chapter09_sec04.md"}],"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"children":[{"file":"chapter10/chapter10_sec01.md"},{"file":"chapter10/chapter10_sec02.md"},{"file":"chapter10/chapter10_sec03.md"},{"file":"chapter10/chapter10_sec04.md"}],"title":"10. Support Vector Machines"},{"children":[{"file":"chapter11/chapter11_sec01.md"},{"file":"chapter11/chapter11_sec02.md"},{"file":"chapter11/chapter11_sec04.md"}],"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"children":[{"file":"chapter12/chapter12_sec01.md"},{"file":"chapter12/chapter12_sec02.md"},{"file":"chapter12/chapter12_sec03.md"}],"title":"12. Neuronale Netze"}],"exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"1. Grundbegriffe des maschinellen Lernens"},{"slug":"chapter01-sec01","title":"1.1 Was ist maschinelles Lernen?","description":"","date":"","thumbnail":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.png","thumbnailOptimized":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec02","title":"1.2 Überwachtes, unüberwachtes und verstärkendes Lernen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec03","title":"1.3 Technische Voraussetzungen","description":"","date":"","thumbnail":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.png","thumbnailOptimized":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"2. Crashkurs Python"},{"slug":"chapter02-sec01","title":"2.1 Datentypen, Variablen und print()","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec02","title":"2.2 Listen und for-Schleifen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec03","title":"2.3 Dictionaries, Funktionen und Methoden","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"3. Pandas und Plotly anstatt Excel"},{"slug":"chapter03-sec01","title":"3.1 Pandas Series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec02","title":"3.2 Statistik mit Pandas","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec03","title":"3.3 Boxplots mit Plotly","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"4. Tabellarische Daten"},{"slug":"chapter04-sec01","title":"4.1 Datenstruktur DataFrame","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec02","title":"4.2 Arbeiten mit Tabellendaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec03","title":"4.3 Scatterplots und Scattermatrix","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"5. Kategoriale Daten"},{"slug":"chapter05-sec01","title":"5.1 Was sind kategoriale Daten?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec02","title":"5.2 Barplots und Histogramme","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec03","title":"5.3 Daten filtern und gruppieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"6. Entscheidungsbäume (Decision Trees)"},{"slug":"chapter06-sec01","title":"6.1 Was ist ein Entscheidungsbaum?","description":"","date":"","thumbnail":"/book_ml4ing/build/combined_decisiontre-828d24d00dcf41e5ebd76c64a833686d.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec02","title":"6.2 Entscheidungsbäume visualisieren und trainieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec03","title":"6.3 Entscheidungsbäume in der Praxis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"7. Lineare Regression"},{"slug":"chapter07-sec01","title":"7.1 Einfache lineare Regression","description":"","date":"","thumbnail":"/book_ml4ing/build/Linear_regression-b0a448b4378e9c4ed49a7896796e35b1.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec02","title":"7.2 Multiple lineare Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec03","title":"7.3 Polynomiale Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"8. ML-Workflow Datenvorverarbeitung"},{"slug":"chapter08-sec01","title":"8.1 Fehlende Daten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec02","title":"8.2 Trainings- und Testdaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec03","title":"8.3 Kodierung und Skalierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"slug":"chapter09-sec01","title":"9.1 Grundideen der Ensemble-Methoden","description":"","date":"","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec02","title":"9.2 Random Forests","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec03","title":"9.3 XGBoost","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"10. Support Vector Machines"},{"slug":"chapter10-sec01","title":"10.1 Maximiere den Rand, aber soft","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.pdf","thumbnailOptimized":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec02","title":"10.2 Training SVM mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec03","title":"10.3 Nichtlineare SVM","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.png","thumbnailOptimized":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"slug":"chapter11-sec01","title":"11.1 Kreuzvalidierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec02","title":"11.2 Gittersuche","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"12. Neuronale Netze"},{"slug":"chapter12-sec01","title":"12.1 Perzeptron = Grundbaustein neuronaler Netze","description":"","date":"","thumbnail":"/book_ml4ing/build/neuron_wikipedia-3eb6913313ac8930bf9e8f1c3c3de9b5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec02","title":"12.2 Mehrschichtiges Perzeptron","description":"","date":"","thumbnail":"/book_ml4ing/build/perceptron-b623483f7ef788fc968924c61cb9287b.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec03","title":"12.3 Neuronale Netze mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/book_ml4ing/build/manifest-86A905A4.js";
import * as route0 from "/book_ml4ing/build/root-CXYA7X5D.js";
import * as route1 from "/book_ml4ing/build/routes/$-JRBPULBO.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/book_ml4ing/build/entry.client-PCJPW7TK.js");</script></body></html>