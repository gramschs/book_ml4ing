<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>6.3 Entscheidungsbäume in der Praxis - Maschinelles Lernen für Ingenieurwissenschaften</title><meta property="og:title" content="6.3 Entscheidungsbäume in der Praxis - Maschinelles Lernen für Ingenieurwissenschaften"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/book_ml4ing/build/_assets/app-AIT5GAEP.css"/><link rel="stylesheet" href="/book_ml4ing/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/book_ml4ing/favicon.ico"/><link rel="stylesheet" href="/book_ml4ing/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100vw;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/book_ml4ing/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="Maschinelles Lernen für Ingenieurwissenschaften" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/book_ml4ing/">Maschinelles Lernen für Ingenieurwissenschaften</a><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="1. Grundbegriffe des maschinellen Lernens" class="block break-words rounded py-2 grow cursor-pointer">1. Grundbegriffe des maschinellen Lernens</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2. Crashkurs Python" class="block break-words rounded py-2 grow cursor-pointer">2. Crashkurs Python</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rupsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rupsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="3. Pandas und Plotly anstatt Excel" class="block break-words rounded py-2 grow cursor-pointer">3. Pandas und Plotly anstatt Excel</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="4. Tabellarische Daten" class="block break-words rounded py-2 grow cursor-pointer">4. Tabellarische Daten</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="5. Kategoriale Daten" class="block break-words rounded py-2 grow cursor-pointer">5. Kategoriale Daten</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="6. Entscheidungsbäume (Decision Trees)" class="block break-words rounded py-2 grow cursor-pointer">6. Entscheidungsbäume (Decision Trees)</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1upsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1upsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="7. Lineare Regression" class="block break-words rounded py-2 grow cursor-pointer">7. Lineare Regression</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="8. ML-Workflow Datenvorverarbeitung" class="block break-words rounded py-2 grow cursor-pointer">8. ML-Workflow Datenvorverarbeitung</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="9. Ensemble-Methoden (Random Forests und XGBoost)" class="block break-words rounded py-2 grow cursor-pointer">9. Ensemble-Methoden (Random Forests und XGBoost)</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="10. Support Vector Machines" class="block break-words rounded py-2 grow cursor-pointer">10. Support Vector Machines</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2upsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2upsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="11. ML-Workflow Modellbewertung und Auswahl" class="block break-words rounded py-2 grow cursor-pointer">11. ML-Workflow Modellbewertung und Auswahl</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R36psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="12. Neuronale Netze" class="block break-words rounded py-2 grow cursor-pointer">12. Neuronale Netze</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="myst-made-with-myst flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer" class="myst-fm-license-cc-badge opacity-50 hover:opacity-100 text-inherit hover:text-inherit myst-fm-license-content" aria-label="Content License: Creative Commons Attribution Non Commercial Share Alike 4.0 International (CC-BY-NC-SA-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-main inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial Share Alike 4.0 International (CC-BY-NC-SA-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-by inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-nc inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-license-cc-icon myst-fm-license-cc-icon-sa inline-block mr-1"><title>Adaptations must be shared under the same terms</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm-4.3 6.6c.2-1.2.7-2.1 1.4-2.8.8-.7 1.7-1 2.8-1 1.5 0 2.8.5 3.7 1.5.9 1 1.4 2.3 1.4 3.8s-.5 2.7-1.4 3.7c-.9 1-2.2 1.5-3.7 1.5-1.1 0-2.1-.3-2.9-1-.8-.7-1.3-1.6-1.4-2.8h2.5c.1 1.2.8 1.8 2.1 1.8.7 0 1.2-.3 1.7-.9.4-.6.6-1.4.6-2.4s-.2-1.8-.6-2.4c-.4-.5-.9-.8-1.7-.8-1.3 0-2 .6-2.2 1.7h.7l-1.9 1.9-1.9-1.9.8.1z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="myst-fm-open-access-badge text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-block-open-access-icon mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/gramschs/book_ml4ing" title="GitHub Repository: gramschs/book_ml4ing" target="_blank" rel="noopener noreferrer" class="myst-fm-github-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-github-icon inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div><a href="https://github.com/gramschs/book_ml4ing/edit/main/chapter06/chapter06_sec03.md" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="myst-fm-edit-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-edit-icon inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">6.3 Entscheidungsbäume in der Praxis</h1><header class="myst-fm-authors-affiliations mt-4 not-prose"><div class="myst-fm-authors-list"><span class="myst-fm-author font-semibold text-sm myst-fm-author-item inline-block"><button class="myst-fm-author-popover focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R78ucp:" data-state="closed"><span class="myst-fm-author-name">Simone Gramsch</span></button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><p>Entscheidungsbäume bieten viele Vorteile, haben aber auch Nachteile, die wir in
diesem Kapitel diskutieren werden. Darüber hinaus lernen wir Methoden kennen,
um bei Entscheidungsbäumen diese Nachteile zu reduzieren.</p><h2 id="lernziele" class="relative group"><span class="heading-text">Lernziele</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lernziele" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><aside class="myst-admonition myst-admonition-attention my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-amber-600 attention"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-amber-600 bg-amber-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-amber-600"><path stroke-linecap="round" stroke-linejoin="round" d="M10.34 15.84c-.688-.06-1.386-.09-2.09-.09H7.5a4.5 4.5 0 1 1 0-9h.75c.704 0 1.402-.03 2.09-.09m0 9.18c.253.962.584 1.892.985 2.783.247.55.06 1.21-.463 1.511l-.657.38c-.551.318-1.26.117-1.527-.461a20.845 20.845 0 0 1-1.44-4.282m3.102.069a18.03 18.03 0 0 1-.59-4.59c0-1.586.205-3.124.59-4.59m0 9.18a23.848 23.848 0 0 1 8.835 2.535M10.34 6.66a23.847 23.847 0 0 0 8.835-2.535m0 0A23.74 23.74 0 0 0 18.795 3m.38 1.125a23.91 23.91 0 0 1 1.014 5.395m-1.014 8.855c-.118.38-.245.754-.38 1.125m.38-1.125a23.91 23.91 0 0 0 1.014-5.395m0-3.46c.495.413.811 1.035.811 1.73 0 .695-.316 1.317-.811 1.73m0-3.46a24.347 24.347 0 0 1 0 3.46"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Lernziele</div></div><div class="myst-admonition-body px-4 py-1"><ul><li><p>Sie können in eigenen Worten erklären, was <strong>Overfitting</strong> (deutsch:
<strong>Überanpassung</strong>) ist.</p></li><li><p>Sie wissen, was <strong>Underfitting</strong> bedeutet.</p></li><li><p>Sie wissen, dass Entscheidungsbäume eine Tendenz zu Overfitting haben und
Maßnahmen zur Reduzierung von Overfitting ergriffen werden müssen.</p></li><li><p>Sie wissen, was <strong>Hyperparameter</strong> sind.</p></li><li><p>Sie kennen Hyperparameter der Entscheidungsbäume wie beispielsweise</p><ul><li><p>maximale Baumtiefe,</p></li><li><p>minimale Anzahl an Datenpunkten in Knoten oder</p></li><li><p>minimale Anzahl an Datenpunkten in Blättern.</p></li></ul></li><li><p>Sie können die Hyperparameter zum <strong>Prä-Pruning</strong> (deutsch: vorab
Zurechtschneiden) geeignet wählen.</p></li></ul></div></aside><h2 id="die-tendenz-von-entscheidungsb-umen-zum-overfitting" class="relative group"><span class="heading-text">Die Tendenz von Entscheidungsbäumen zum Overfitting</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#die-tendenz-von-entscheidungsb-umen-zum-overfitting" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Entscheidungsbaummodelle bieten zahlreiche Vorteile. Ein wesentlicher Vorzug ist
die Möglichkeit, den trainierten Entscheidungsbaum zu visualisieren, wodurch es
leicht nachvollziehbar wird, welche Merkmale einen signifikanten Einfluss haben.
Ein weiterer Vorteil ist ihre Effizienz bei heterogenen Daten; sowohl numerische
als auch kategoriale Eigenschaften können problemlos verarbeitet werden.
Entscheidungsbäume sind selbst bei unterschiedlichen Datenskalen robust und
erfordern nur wenig Vorverarbeitung.</p><p>Trotz dieser Stärken besitzen Entscheidungsbäume eine Neigung zum
<strong>Overfitting</strong>. Overfitting, auch als Überanpassung bekannt, beschreibt ein
Problem im maschinellen Lernen, bei dem ein Modell die Trainingsdaten zu genau
lernt. Das klingt zunächst gut, aber das Modell kann dadurch seine Fähigkeit
verlieren, Vorhersagen für neue, unbekannte Daten zu treffen. Im Gegensatz dazu
steht das <strong>Underfitting</strong>, das eine zu geringe Anpassung an die Daten bedeutet
und ebenfalls unerwünscht ist.</p><p>Um uns das Problem des Overfittings zu veranschaulichen, betrachten wir erneut
das Autohaus-Beispiel, aber diesmal mit mehr Autos. Wir lassen die Autos diesmal
mit einer in Scikit-Learn eingebauten Funktion zur Generierung von künstlichen
Daten erzeugen, der sogenannten <code>make_moons</code>-Funktion (siehe <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html" class="">Dokumentation
Scikit-Learn →
make_moons</a>)
aus dem Module <code>sklearn.datasets</code>.</p><div id="NSsm2kqiPL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.datasets import make_moons 

X_array, y_array = make_moons(noise = 0.5, n_samples=50, random_state=3)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="lhnekaPC5oYRZw73l9aDM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p>Damit die künstlichen Daten besser zu dem Autohaus-Beispiel passen,
transformieren wir sie und nutzen die Pandas-Datenstrukturen, um sie effizient
zu verwalten.</p><div id="l5Hqk1kiNE" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import numpy as np
import pandas as pd

# Transformation der Merkmalswerte in einen positiven Bereich und 
# Umwandlung in eine Integer-Matrix
X_array = X_array + 1.2 * np.abs(np.min(X_array))
X_array[:,0] = np.ceil(X_array[:,0] * 30000)
X_array[:,1] = np.ceil(X_array[:,1] * 10000)
X = pd.DataFrame(X_array, columns=[&#x27;Kilometerstand [km]&#x27;, &#x27;Preis [EUR]&#x27;], dtype=(int, int))

# Zuweisung von True/False basierend auf den Kategorien 1 bzw. 0
y_array = (y_array - 1.0) * (-1)
y = pd.Series(y_array, name=&#x27;verkauft&#x27;, dtype=&#x27;bool&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="m9d3-uKrp9uOegKS3L_xL" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p>Nach der Datenvorbereitung visualisieren wir diese:</p><div id="QhvPzSIVe1" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import plotly.express as px

fig = px.scatter(x = X[&#x27;Kilometerstand [km]&#x27;], y = X[&#x27;Preis [EUR]&#x27;], color=y,
    title=&#x27;Künstliche Daten Autohaus&#x27;,
    labels={&#x27;x&#x27;: &#x27;Kilometerstand [km]&#x27;, &#x27;y&#x27;: &#x27;Preis [EUR]&#x27;, &#x27;color&#x27;: &#x27;verkauft&#x27;})
fig.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="jQErFiwTwg_X4QHWJiTz1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><p>Das Training des Entscheidungsbaumes und dessen Visualisierung erledigt der
folgende Code.</p><div id="W3nrzWOAiB" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.tree import DecisionTreeClassifier, plot_tree

modell = DecisionTreeClassifier(random_state=0)
modell.fit(X,y)

plot_tree(modell,
    feature_names=[&#x27;Kilometerstand [km]&#x27;, &#x27;Preis [EUR]&#x27;],
    class_names=[&#x27;nicht verkauft&#x27;, &#x27;verkauft&#x27;]);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="umrwpvZi0Lm0KvXTmUvlp" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/book_ml4ing/build/f04143ecb736809ebdae7e09fc4c8f79.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Die Visualisierung offenbart zahlreiche Verzweigungen und eine schwer lesbare
Beschriftung. Die Entscheidungsgrenzen, die im Folgenden mit
<code>DecisionBoundaryDisplay</code> visualisiert werden, zeigen eine zu starke Anpassung
an die Trainingsdaten.</p><div id="sfIFfaoLNX" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.colors import ListedColormap
from sklearn.inspection import DecisionBoundaryDisplay

fig = DecisionBoundaryDisplay.from_estimator(modell, X, cmap=ListedColormap([&#x27;#EF553B33&#x27;, &#x27;#636EFA33&#x27;]), grid_resolution=1000)
fig.ax_.scatter(X[&#x27;Kilometerstand [km]&#x27;], X[&#x27;Preis [EUR]&#x27;], c=y, cmap=ListedColormap([&#x27;#EF553B&#x27;, &#x27;#636EFA&#x27;]))
fig.ax_.set_title(&#x27;Entscheidungsgrenzen&#x27;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="PaGoHNP_gIb3HLUAVkcrh" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/book_ml4ing/build/5357933f05d4c7f64eb2daeebe329dbc.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Es ist fraglich, ob dieser Entscheidungsbaum nicht zu genau an die
Trainingsdaten angepasst wurde. Der dünne blaue vertikale Streifen bei ungefähr
97000 km ist wahrscheinlich keine sinnvolle Entscheidung, sondern eher einem
Ausreißer geschuldet (dem Auto mit einem Kilometerstand von 97098 km und einem
Preis von 28229 EUR). Der Entscheidungsbaum hat sich zu stark an die Daten
angepasst. Es ist wahrscheinlich, dass dieser Entscheidungsbaum für Autos mit
einem Kilometerstand von ungefähr 97000 km falsche Prognosen treffen wird. Wenn
wir mit den gleichen Daten erneut einen Entscheidungsbaum trainieren lassen und
den Zufallszahlengenerator mit dem Zustand <code>random_state=1</code> initialisieren,
erhalten wir ein völlig anderes Ergebnis.</p><div id="FS4LMr92AK" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">modell_alternative = DecisionTreeClassifier(random_state=1)
modell_alternative.fit(X,y)

fig = DecisionBoundaryDisplay.from_estimator(modell_alternative, X, cmap=ListedColormap([&#x27;#EF553B33&#x27;, &#x27;#636EFA33&#x27;]), grid_resolution=1000)
fig.ax_.scatter(X[&#x27;Kilometerstand [km]&#x27;], X[&#x27;Preis [EUR]&#x27;], c=y, cmap=ListedColormap([&#x27;#EF553B&#x27;, &#x27;#636EFA&#x27;]))
fig.ax_.set_title(&#x27;Entscheidungsgrenzen des alternativen Modells&#x27;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YsY2cFuM-B6O8V0OzJzLp" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/book_ml4ing/build/95b161ea226c5b2ce6ac47becd21bce9.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Eine Möglichkeit, das Overfitting (Überanpassung) an die Daten zu bekämpfen, ist
das Zurechtschneiden (Pruning) der Entscheidungsbäume. Eine andere ist, aus
mehreren Entscheidungbäumen einen »durchschnittlichen« Entscheidungsbaum zu
bilden. Dieses Verfahren heißt Zufallswald (Random Forest) und wird ausführlich
in einem eigenen Kapitel behandelt werden. In diesem Kapitel betrachten wir nur
das Zurechtschneiden der Entscheidungsbäume.</p><h2 id="zurechtschneiden-von-entscheidungsb-umen" class="relative group"><span class="heading-text">Zurechtschneiden von Entscheidungsbäumen</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#zurechtschneiden-von-entscheidungsb-umen" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Eine effektive Strategie zur Bekämpfung des Overfittings bei Entscheidungsbäumen
ist das sogenannte <strong>Pruning</strong>, also das Beschneiden des Baumes. Pruning hilft,
die Komplexität des Modells zu reduzieren, indem weniger relevante
Entscheidungszweige nach bestimmten Kriterien entfernt werden. Im Kontext
unseres Autohaus-Beispiels würde dies bedeuten, dass Entscheidungszweige, die
beispielsweise aufgrund von Ausreißern entstanden sind, abgeschnitten werden.
Dies könnte beispielsweise den zuvor erwähnten dünnen blauen Streifen bei einem
Kilometerstand von ungefähr 97000 km betreffen, der wahrscheinlich durch einen
Ausreißer entstanden ist. Durch das Entfernen solcher spezifischen Anpassungen
kann der Entscheidungsbaum besser verallgemeinern und wird robuster gegenüber
neuen, unbekannten Daten. Das Ergebnis ist ein Modell, das eine bessere Balance
zwischen Anpassung an die Trainingsdaten und Generalisierungsfähigkeit aufweist.</p><p>Für Entscheidungsbäume gibt es prinzipiell zwei Methoden des Prunings:
<strong>Prä-Pruning</strong> und <strong>Post-Pruning</strong>. Das Prä-Pruning findet <em>vor</em> dem Training
des Entscheidungsbaumes statt, das Post-Pruning <em>nach</em> dem Training. Die beiden
wichtigsten Prä-Pruning-Maßnahmen sind</p><ul><li><p>die Begrenzung der maximalen Tiefe des Baumes und</p></li><li><p>die Forderung nach einer Mindestanzahl von Datenpunkten (entweder pro Knoten
oder pro Blatt).</p></li></ul><p>Beim Post-Pruning werden im Nachhinein Knoten mit wenig Informationen aus dem
Entscheidungsbaum entfernt oder es werden Knoten zusammengelegt. Scikit-Learn
hat nur Prä-Pruning implementiert, so dass wir hier nicht weiter auf
Post-Pruning eingehen.</p><h3 id="pr-pruning-baumtiefe" class="relative group"><span class="heading-text">Prä-Pruning: Baumtiefe</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#pr-pruning-baumtiefe" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Wir schauen uns zunächst an, wie bei Scikit-Learn-Entscheidungsbäumen die
maximale Tiefe festgelegt wird. Bisher haben wir das Modell ohne weitere
Parameter initialisiert (einzige Ausnahme: wir haben ggf. den
Zufallszahlengenerator aus didaktischen Gründen fixiert, damit die Ergebnisse
vergleichbar sind). Nun verwenden wir bei der Initialisierung des
DecisionTreeClassifiers das optionale Argument <code>max_depth=</code> und setzen es auf
<code>1</code>.</p><div id="EYh69MoGtv" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">modell_tiefe1 = DecisionTreeClassifier(random_state=0, max_depth=1)
modell_tiefe1.fit(X,y)

plot_tree(modell_tiefe1,
    feature_names=[&#x27;Kilometerstand [km]&#x27;, &#x27;Preis [EUR]&#x27;],
    class_names=[&#x27;nicht verkauft&#x27;, &#x27;verkauft&#x27;]);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="_b0EHHkog1IIcvg_76Po0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/book_ml4ing/build/cb8aba09652b28c8f6545fcb0ba207d5.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Eine Tiefe von 1 bedeutet, dass nur noch eine einzige Entscheidungsfrage
gestellt wird. Das reicht nicht mehr, um die Autos in reine Blätter zu
sortieren. Im linken Blatt sind 13 nicht verkaufte Autos und 24 verkaufte Autos,
weshalb diesem Blatt die Kategorie »verkauft« zugeordnet wird. Im rechten Blatt
sind 12 nicht verkaufte Autos und ein verkauftes Auto, so dass dieses Blatt
insgesamt als »nicht verkauft« gilt. Die Visualisierung der Entscheidungsgrenzen
zeigt, um welche Autos es sich handelt.</p><div id="u64RfgZf7M" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig = DecisionBoundaryDisplay.from_estimator(modell_tiefe1, X, cmap=ListedColormap([&#x27;#EF553B33&#x27;, &#x27;#636EFA33&#x27;]), grid_resolution=1000)
fig.ax_.scatter(X[&#x27;Kilometerstand [km]&#x27;], X[&#x27;Preis [EUR]&#x27;], c=y, cmap=ListedColormap([&#x27;#EF553B&#x27;, &#x27;#636EFA&#x27;]))
fig.ax_.set_title(&#x27;Entscheidungsgrenzen&#x27;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="A4PbGDGyDL8GvyGWidw9v" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/book_ml4ing/build/f7a778082f9a47b45e4a1b80340c2c50.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Insbesondere die Visualisierung der Entscheidungsgrenzen zeigt aber auch, dass
dieser Entscheidungsbaum nicht besonders gut die Daten erklärt. Der Score ist
mit</p><div id="FvTbrIF4so" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(f&#x27;Score des Entscheidungsbaumes mit Tiefe 1: {modell_tiefe1.score(X,y)}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="LRlF5Vne9fdEI9r-kvTuV" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Score des Entscheidungsbaumes mit Tiefe 1: 0.72
</span></code></pre></div></div></div></div><p>auch nicht so gut. Daher verwenden wir nun als maximale Tiefe des Entscheidungsbaumes einen Wert von 2.</p><div id="YUZ7cBIDZE" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">modell_tiefe2 = DecisionTreeClassifier(random_state=0, max_depth=2)
modell_tiefe2.fit(X,y)

plot_tree(modell_tiefe2,
    feature_names=[&#x27;Kilometerstand [km]&#x27;, &#x27;Preis [EUR]&#x27;],
    class_names=[&#x27;nicht verkauft&#x27;, &#x27;verkauft&#x27;]);

print(f&#x27;Score des Entscheidungsbaumes mit Tiefe 2: {modell_tiefe2.score(X,y)}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="ZUpdywuUuVj52rdD-VTtP" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Score des Entscheidungsbaumes mit Tiefe 2: 0.78
</span></code></pre></div></div><div data-name="safe-output-image"><img src="/book_ml4ing/build/b3447c976699eee489d72a071f3a5660.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Mit einem Score von 0.78 ist der Entscheidungsbaum mit einer maximalen Tiefe von
2 zwar besser als der Baum mit einer maximalen Tiefe von 1, aber deutlich
entfernt von dem Score 1.0 bei einer Baumtiefe von 7. Die Entscheidungsgrenzen
sehen folgendermaßen aus:</p><div id="fE2C8vRwrV" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig = DecisionBoundaryDisplay.from_estimator(modell_tiefe2, X, cmap=ListedColormap([&#x27;#EF553B33&#x27;, &#x27;#636EFA33&#x27;]), grid_resolution=1000)
fig.ax_.scatter(X[&#x27;Kilometerstand [km]&#x27;], X[&#x27;Preis [EUR]&#x27;], c=y, cmap=ListedColormap([&#x27;#EF553B&#x27;, &#x27;#636EFA&#x27;]))
fig.ax_.set_title(&#x27;Entscheidungsgrenzen&#x27;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="kv6gjt2T4qbyGmK0_CYt0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/book_ml4ing/build/16d4867c980f97c0d539a8d28c00a66d.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Was ist jetzt besser, eine maximale Tiefe von 1 oder 2? Oder doch 3 vielleicht?
Die Einführung der maximalen Tiefe bietet den Vorteil, das Overfitting zu
bekämpfen. Der Nachteil davon ist, dass wir jetzt einen neuen Parameter haben,
der das Training und die Prognose des Modells bestimmt. Und für diesen Parameter
muss ein passender Wert eingestellt werden. Solche Parameter nennt man
<strong>Hyperparameter</strong>.</p><aside class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500 note"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Was ist ... ein Hyperparameter?</div></div><div class="myst-admonition-body px-4 py-1"><p>Ein Hyperparameter ist ein Parameter, der vor dem Training eines Modells
festgelegt wird und nicht aus den Daten während des Trainings gelernt wird. Die
Hyperparameter steuern den gesamten Lernprozess und haben einen wesentlichen
Einfluss auf die Leistung des Modells.</p></div></aside><p>Ein Score von 1.0 auf den Trainingsdaten deutet auf Overfitting hin, d.h. das
Modell hat die Daten auswendig gelernt. Ein sehr niedriger Score (z.B. 0.72)
deutet auf Underfitting hin, d.h. das Modell ist zu einfach. Das Ziel ist ein
Gleichgewicht: ein Score, der hoch genug ist, um die Daten gut zu beschreiben,
aber nicht 1.0, um Generalisierung zu ermöglichen. Werte zwischen 0.8 und 0.95
sind oft ein guter Kompromiss, aber dies muss mit separaten Testdaten validiert
werden.</p><p>Kommen wir nun zu einem anderen Hyperparameter der Entscheidungsbäume, der
Mindestanzahl von Datenpunkten.</p><h3 id="pr-pruning-mindestanzahl-datenpunkte" class="relative group"><span class="heading-text">Prä-Pruning: Mindestanzahl Datenpunkte</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#pr-pruning-mindestanzahl-datenpunkte" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Genau wie der Hyperparameter zur Begrenzung der Baumtiefe wird die Mindestanzahl
der Datenpunkte vorab bei der Initialisierung des Entscheidungsbaumes
festgelegt. Scikit-Learn bietet wiederum zwei Möglichkeiten, über die minimale
Anzahl von Datenpunkten den Entscheidungsbaum zurechtzuschneiden. Zum einen kann
für die <em>Knoten</em> eine minimal erforderliche Anzahl von Datenpunkten festgelegt
werden, ab der es erlaubt ist, durch Entscheidungsfragen weiter zu verzweigen.
Zum anderen kann eine minimale Anzahl an Datenpunkten für jedes <em>Blatt</em>
festgelegt werden, das am Ende der Verzweigungen erreicht werden muss.</p><p>Wir probieren beide Möglichkeiten aus und vergleichen die Ergebnisse
miteinander. Die Option zur Einstellung der Mindestanzahl pro Knoten heißt
<code>min_samples_split</code> und die Option zur Einstellung des Mindestanzahl Datenpunkte
pro Blatt heißt <code>min_samples_leaf</code>. Beiden optionalen Argumenten kann entweder
ein Integer übergeben werden oder ein Float. Wird ein Integer übergeben, so ist
damit die tatsächliche minimale Anzahl an Datenpunkten gemeint. Ein Float wird
als Bruch interpretiert und meint die relative Anzahl der Datenpunkte. Der Bruch
wird mit der Gesamtzahl der Datenpunkte multipliziert und dann wird auf die
nächste ganze Zahl aufgerundet.</p><p>Schauen wir uns beide Varianten an. Zunächst begrenzen wir die Knoten und
fordern, dass sich in jedem Entscheidungsknoten mindestens sechs Datenpunkte
befinden müssen.</p><div id="ibKXTcl7sc" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">modell_knotenbegrenzung = DecisionTreeClassifier(random_state=0, min_samples_split=6)
modell_knotenbegrenzung.fit(X,y)

plot_tree(modell_knotenbegrenzung,
    feature_names=[&#x27;Kilometerstand [km]&#x27;, &#x27;Preis [EUR]&#x27;],
    class_names=[&#x27;nicht verkauft&#x27;, &#x27;verkauft&#x27;]);

print(f&#x27;Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Knoten: {modell_knotenbegrenzung.score(X,y)}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="AV97-Jw2_jkwX4K5irXZv" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Knoten: 0.92
</span></code></pre></div></div><div data-name="safe-output-image"><img src="/book_ml4ing/build/60faffff720b19e19d64011f6321509d.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>Der Score ist 0.92. Nun fordern wir, dass in jedem Blatt mindestens sechs
Datenpunkte verbleiben müssen.</p><div id="gXR0sZ5zsD" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">modell_blattbegrenzung = DecisionTreeClassifier(random_state=0, min_samples_leaf=6)
modell_blattbegrenzung.fit(X,y)

plot_tree(modell_blattbegrenzung,
    feature_names=[&#x27;Kilometerstand [km]&#x27;, &#x27;Preis [EUR]&#x27;],
    class_names=[&#x27;nicht verkauft&#x27;, &#x27;verkauft&#x27;]);

print(f&#x27;Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Blatt: {modell_blattbegrenzung.score(X,y)}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="ChudZsqqg2hn-e368RZLI" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Blatt: 0.82
</span></code></pre></div></div><div data-name="safe-output-image"><img src="/book_ml4ing/build/d12f1b09a02342fe04b539d5bcee6e6a.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><p>In diesem Fall erhalten wir einen Entscheidungsbaum mit einem Score von 0.82.
Was jetzt die bessere Wahl ist -- Begrenzung der Baumtiefe oder Festlegung einer
Mindestanzahl von Datenpunkten Knoten/Blatt -- und vor allem welchen Wert der
Hyperparameter haben soll, ist eine zentrale Herausforderung im maschinellen
Lernen. In späteren Kapiteln werden wir systematische Methoden wie Grid Search
und Cross-Validation kennenlernen, um die besten Hyperparameter-Werte zu finden.</p><aside class="myst-admonition myst-admonition-tip my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-green-600 tip"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-green-600 bg-green-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-green-600"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Mini-Übung</div></div><div class="myst-admonition-body px-4 py-1"><p>Welcher Entscheidungsbaum zeigt vermutlich die stärkste Tendenz zum Overfitting?
Stellen Sie eine Vermuting an und überprüfen Sie Ihre Vermutung durch Ausprobieren.</p><p>A) <code>DecisionTreeClassifier(max_depth=2)</code><br/>B) <code>DecisionTreeClassifier(max_depth=10)</code><br/>C) <code>DecisionTreeClassifier(min_samples_leaf=20)</code></p></div></aside><div id="wXOUjdCcoF" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hier Ihr Code</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="6-85nGqX1CSzBwc1rn6Hi" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><details class="myst-admonition myst-admonition-tip my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-green-600 tip dropdown, dropdown"><summary class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-green-600 bg-green-50 dark:bg-slate-900 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03]"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-green-600"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Lösung</div><div class="self-center flex-none text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none transition-transform details-toggle"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></div></summary><div class="myst-admonition-body px-4 py-1 details-body"><p>Antwort B, denn eine große maximale Tiefe erlaubt sehr komplexe Bäume.</p><p>Überprüfung durch Code:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Die drei Modelle trainieren und Scores vergleichen
modell_a = DecisionTreeClassifier(max_depth=2, random_state=0)
modell_a.fit(X, y)
print(f&#x27;Score A (max_depth=2): {modell_a.score(X, y):.3f}&#x27;)

modell_b = DecisionTreeClassifier(max_depth=10, random_state=0)
modell_b.fit(X, y)
print(f&#x27;Score B (max_depth=10): {modell_b.score(X, y):.3f}&#x27;)

modell_c = DecisionTreeClassifier(min_samples_leaf=20, random_state=0)
modell_c.fit(X, y)
print(f&#x27;Score C (min_samples_leaf=20): {modell_c.score(X, y):.3f}&#x27;)

# Modell B hat vermutlich den höchsten Score (nahe 1.0) → Overfitting!</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Video “How to Implement Decision Trees in Python / Scikit-Learn” von Misra Turp</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/wxS5P7yDHRA?si=rawkRWRmUi0ZZAub" title="YouTube video player" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div></div></details><h2 id="zusammenfassung-und-ausblick" class="relative group"><span class="heading-text">Zusammenfassung und Ausblick</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#zusammenfassung-und-ausblick" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In diesem Kapitel haben wir die Tendenz der Entscheidungsbäume zum Overfitting
diskutiert. Um dem Problem des Overfittings zu begegnen, bietet Scikit-Learn die
Möglichkeit des Prä-Prunings. Durch die Begrenzung der maximalen Baumtiefe oder
die Festlegung einer Mindestanzahl von Datenpunkten in Knoten oder Blättern kann
Overfitting reduziert werden. Diese zusätzlichen Parameter des
Entscheidungsbaums werden Hyperparameter genannt und müssen angepasst werden.
Eine weitere Alternative, das Overfitting von Entscheidungsbäumen zu minimieren,
bieten die Random Forests, die wir in einem späteren Kapitel kennenlernen
werden.</p><div class="myst-backmatter-parts"></div><div class="myst-footer-links flex pt-10 mb-10 space-x-4"><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-prev" href="/book_ml4ing/chapter06-sec02"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">6. Entscheidungsbäume (Decision Trees)</div>6.2 Entscheidungsbäume visualisieren und trainieren</div></div></a><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-next" href="/book_ml4ing/chapter06-sec04"><div class="flex h-full align-middle"><div class="flex-grow"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">6. Entscheidungsbäume (Decision Trees)</div>Übung</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/book_ml4ing/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-OYMW4E3D.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/book_ml4ing/build/root-CXYA7X5D.js"/><link rel="modulepreload" href="/book_ml4ing/build/_shared/chunk-DATP5P2X.js"/><link rel="modulepreload" href="/book_ml4ing/build/routes/$-JRBPULBO.js"/><script>window.__remixContext = {"url":"/chapter06-sec03","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.7.1","options":{"style":"/book_ml4ing/build/myadmonitions-2678b80ebf14ff136f40b5cf268e40ac.css"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"title":"Maschinelles Lernen für Ingenieurwissenschaften","authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"github":"https://github.com/gramschs/book_ml4ing","id":"8312bbb5-c2ab-495b-accc-a6773ec93d28","toc":[{"file":"intro.md"},{"children":[{"file":"chapter01/chapter01_sec01.md"},{"file":"chapter01/chapter01_sec02.md"},{"file":"chapter01/chapter01_sec03.md"}],"title":"1. Grundbegriffe des maschinellen Lernens"},{"children":[{"file":"chapter02/chapter02_sec01.md"},{"file":"chapter02/chapter02_sec02.md"},{"file":"chapter02/chapter02_sec03.md"},{"file":"chapter02/chapter02_sec04.md"}],"title":"2. Crashkurs Python"},{"children":[{"file":"chapter03/chapter03_sec01.md"},{"file":"chapter03/chapter03_sec02.md"},{"file":"chapter03/chapter03_sec03.md"},{"file":"chapter03/chapter03_sec04.md"}],"title":"3. Pandas und Plotly anstatt Excel"},{"children":[{"file":"chapter04/chapter04_sec01.md"},{"file":"chapter04/chapter04_sec02.md"},{"file":"chapter04/chapter04_sec03.md"},{"file":"chapter04/chapter04_sec04.md"}],"title":"4. Tabellarische Daten"},{"children":[{"file":"chapter05/chapter05_sec01.md"},{"file":"chapter05/chapter05_sec02.md"},{"file":"chapter05/chapter05_sec03.md"},{"file":"chapter05/chapter05_sec04.md"}],"title":"5. Kategoriale Daten"},{"children":[{"file":"chapter06/chapter06_sec01.md"},{"file":"chapter06/chapter06_sec02.md"},{"file":"chapter06/chapter06_sec03.md"},{"file":"chapter06/chapter06_sec04.md"}],"title":"6. Entscheidungsbäume (Decision Trees)"},{"children":[{"file":"chapter07/chapter07_sec01.md"},{"file":"chapter07/chapter07_sec02.md"},{"file":"chapter07/chapter07_sec03.md"},{"file":"chapter07/chapter07_sec04.md"}],"title":"7. Lineare Regression"},{"children":[{"file":"chapter08/chapter08_sec01.md"},{"file":"chapter08/chapter08_sec02.md"},{"file":"chapter08/chapter08_sec03.md"},{"file":"chapter08/chapter08_sec04.md"}],"title":"8. ML-Workflow Datenvorverarbeitung"},{"children":[{"file":"chapter09/chapter09_sec01.md"},{"file":"chapter09/chapter09_sec02.md"},{"file":"chapter09/chapter09_sec03.md"},{"file":"chapter09/chapter09_sec04.md"}],"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"children":[{"file":"chapter10/chapter10_sec01.md"},{"file":"chapter10/chapter10_sec02.md"},{"file":"chapter10/chapter10_sec03.md"},{"file":"chapter10/chapter10_sec04.md"}],"title":"10. Support Vector Machines"},{"children":[{"file":"chapter11/chapter11_sec01.md"},{"file":"chapter11/chapter11_sec02.md"},{"file":"chapter11/chapter11_sec04.md"}],"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"children":[{"file":"chapter12/chapter12_sec01.md"},{"file":"chapter12/chapter12_sec02.md"},{"file":"chapter12/chapter12_sec03.md"}],"title":"12. Neuronale Netze"}],"exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"1. Grundbegriffe des maschinellen Lernens"},{"slug":"chapter01-sec01","title":"1.1 Was ist maschinelles Lernen?","description":"","date":"","thumbnail":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.png","thumbnailOptimized":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec02","title":"1.2 Überwachtes, unüberwachtes und verstärkendes Lernen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec03","title":"1.3 Technische Voraussetzungen","description":"","date":"","thumbnail":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.png","thumbnailOptimized":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"2. Crashkurs Python"},{"slug":"chapter02-sec01","title":"2.1 Datentypen, Variablen und print()","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec02","title":"2.2 Listen und for-Schleifen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec03","title":"2.3 Dictionaries, Funktionen und Methoden","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"3. Pandas und Plotly anstatt Excel"},{"slug":"chapter03-sec01","title":"3.1 Pandas Series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec02","title":"3.2 Statistik mit Pandas","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec03","title":"3.3 Boxplots mit Plotly","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"4. Tabellarische Daten"},{"slug":"chapter04-sec01","title":"4.1 Datenstruktur DataFrame","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec02","title":"4.2 Arbeiten mit Tabellendaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec03","title":"4.3 Scatterplots und Scattermatrix","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"5. Kategoriale Daten"},{"slug":"chapter05-sec01","title":"5.1 Was sind kategoriale Daten?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec02","title":"5.2 Barplots und Histogramme","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec03","title":"5.3 Daten filtern und gruppieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"6. Entscheidungsbäume (Decision Trees)"},{"slug":"chapter06-sec01","title":"6.1 Was ist ein Entscheidungsbaum?","description":"","date":"","thumbnail":"/book_ml4ing/build/combined_decisiontre-828d24d00dcf41e5ebd76c64a833686d.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec02","title":"6.2 Entscheidungsbäume visualisieren und trainieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec03","title":"6.3 Entscheidungsbäume in der Praxis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"7. Lineare Regression"},{"slug":"chapter07-sec01","title":"7.1 Einfache lineare Regression","description":"","date":"","thumbnail":"/book_ml4ing/build/Linear_regression-b0a448b4378e9c4ed49a7896796e35b1.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec02","title":"7.2 Multiple lineare Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec03","title":"7.3 Polynomiale Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"8. ML-Workflow Datenvorverarbeitung"},{"slug":"chapter08-sec01","title":"8.1 Fehlende Daten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec02","title":"8.2 Trainings- und Testdaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec03","title":"8.3 Kodierung und Skalierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"slug":"chapter09-sec01","title":"9.1 Grundideen der Ensemble-Methoden","description":"","date":"","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec02","title":"9.2 Random Forests","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec03","title":"9.3 XGBoost","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"10. Support Vector Machines"},{"slug":"chapter10-sec01","title":"10.1 Maximiere den Rand, aber soft","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.pdf","thumbnailOptimized":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec02","title":"10.2 Training SVM mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec03","title":"10.3 Nichtlineare SVM","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.png","thumbnailOptimized":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"slug":"chapter11-sec01","title":"11.1 Kreuzvalidierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec02","title":"11.2 Gittersuche","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"12. Neuronale Netze"},{"slug":"chapter12-sec01","title":"12.1 Perzeptron = Grundbaustein neuronaler Netze","description":"","date":"","thumbnail":"/book_ml4ing/build/neuron_wikipedia-3eb6913313ac8930bf9e8f1c3c3de9b5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec02","title":"12.2 Mehrschichtiges Perzeptron","description":"","date":"","thumbnail":"/book_ml4ing/build/perceptron-b623483f7ef788fc968924c61cb9287b.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec03","title":"12.3 Neuronale Netze mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/book_ml4ing"},"routes/$":{"config":{"version":3,"myst":"1.7.1","options":{"style":"/book_ml4ing/build/myadmonitions-2678b80ebf14ff136f40b5cf268e40ac.css"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"title":"Maschinelles Lernen für Ingenieurwissenschaften","authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"github":"https://github.com/gramschs/book_ml4ing","id":"8312bbb5-c2ab-495b-accc-a6773ec93d28","toc":[{"file":"intro.md"},{"children":[{"file":"chapter01/chapter01_sec01.md"},{"file":"chapter01/chapter01_sec02.md"},{"file":"chapter01/chapter01_sec03.md"}],"title":"1. Grundbegriffe des maschinellen Lernens"},{"children":[{"file":"chapter02/chapter02_sec01.md"},{"file":"chapter02/chapter02_sec02.md"},{"file":"chapter02/chapter02_sec03.md"},{"file":"chapter02/chapter02_sec04.md"}],"title":"2. Crashkurs Python"},{"children":[{"file":"chapter03/chapter03_sec01.md"},{"file":"chapter03/chapter03_sec02.md"},{"file":"chapter03/chapter03_sec03.md"},{"file":"chapter03/chapter03_sec04.md"}],"title":"3. Pandas und Plotly anstatt Excel"},{"children":[{"file":"chapter04/chapter04_sec01.md"},{"file":"chapter04/chapter04_sec02.md"},{"file":"chapter04/chapter04_sec03.md"},{"file":"chapter04/chapter04_sec04.md"}],"title":"4. Tabellarische Daten"},{"children":[{"file":"chapter05/chapter05_sec01.md"},{"file":"chapter05/chapter05_sec02.md"},{"file":"chapter05/chapter05_sec03.md"},{"file":"chapter05/chapter05_sec04.md"}],"title":"5. Kategoriale Daten"},{"children":[{"file":"chapter06/chapter06_sec01.md"},{"file":"chapter06/chapter06_sec02.md"},{"file":"chapter06/chapter06_sec03.md"},{"file":"chapter06/chapter06_sec04.md"}],"title":"6. Entscheidungsbäume (Decision Trees)"},{"children":[{"file":"chapter07/chapter07_sec01.md"},{"file":"chapter07/chapter07_sec02.md"},{"file":"chapter07/chapter07_sec03.md"},{"file":"chapter07/chapter07_sec04.md"}],"title":"7. Lineare Regression"},{"children":[{"file":"chapter08/chapter08_sec01.md"},{"file":"chapter08/chapter08_sec02.md"},{"file":"chapter08/chapter08_sec03.md"},{"file":"chapter08/chapter08_sec04.md"}],"title":"8. ML-Workflow Datenvorverarbeitung"},{"children":[{"file":"chapter09/chapter09_sec01.md"},{"file":"chapter09/chapter09_sec02.md"},{"file":"chapter09/chapter09_sec03.md"},{"file":"chapter09/chapter09_sec04.md"}],"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"children":[{"file":"chapter10/chapter10_sec01.md"},{"file":"chapter10/chapter10_sec02.md"},{"file":"chapter10/chapter10_sec03.md"},{"file":"chapter10/chapter10_sec04.md"}],"title":"10. Support Vector Machines"},{"children":[{"file":"chapter11/chapter11_sec01.md"},{"file":"chapter11/chapter11_sec02.md"},{"file":"chapter11/chapter11_sec04.md"}],"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"children":[{"file":"chapter12/chapter12_sec01.md"},{"file":"chapter12/chapter12_sec02.md"},{"file":"chapter12/chapter12_sec03.md"}],"title":"12. Neuronale Netze"}],"exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"1. Grundbegriffe des maschinellen Lernens"},{"slug":"chapter01-sec01","title":"1.1 Was ist maschinelles Lernen?","description":"","date":"","thumbnail":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.png","thumbnailOptimized":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec02","title":"1.2 Überwachtes, unüberwachtes und verstärkendes Lernen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec03","title":"1.3 Technische Voraussetzungen","description":"","date":"","thumbnail":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.png","thumbnailOptimized":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"2. Crashkurs Python"},{"slug":"chapter02-sec01","title":"2.1 Datentypen, Variablen und print()","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec02","title":"2.2 Listen und for-Schleifen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec03","title":"2.3 Dictionaries, Funktionen und Methoden","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"3. Pandas und Plotly anstatt Excel"},{"slug":"chapter03-sec01","title":"3.1 Pandas Series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec02","title":"3.2 Statistik mit Pandas","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec03","title":"3.3 Boxplots mit Plotly","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"4. Tabellarische Daten"},{"slug":"chapter04-sec01","title":"4.1 Datenstruktur DataFrame","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec02","title":"4.2 Arbeiten mit Tabellendaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec03","title":"4.3 Scatterplots und Scattermatrix","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"5. Kategoriale Daten"},{"slug":"chapter05-sec01","title":"5.1 Was sind kategoriale Daten?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec02","title":"5.2 Barplots und Histogramme","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec03","title":"5.3 Daten filtern und gruppieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"6. Entscheidungsbäume (Decision Trees)"},{"slug":"chapter06-sec01","title":"6.1 Was ist ein Entscheidungsbaum?","description":"","date":"","thumbnail":"/book_ml4ing/build/combined_decisiontre-828d24d00dcf41e5ebd76c64a833686d.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec02","title":"6.2 Entscheidungsbäume visualisieren und trainieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec03","title":"6.3 Entscheidungsbäume in der Praxis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"7. Lineare Regression"},{"slug":"chapter07-sec01","title":"7.1 Einfache lineare Regression","description":"","date":"","thumbnail":"/book_ml4ing/build/Linear_regression-b0a448b4378e9c4ed49a7896796e35b1.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec02","title":"7.2 Multiple lineare Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec03","title":"7.3 Polynomiale Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"8. ML-Workflow Datenvorverarbeitung"},{"slug":"chapter08-sec01","title":"8.1 Fehlende Daten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec02","title":"8.2 Trainings- und Testdaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec03","title":"8.3 Kodierung und Skalierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"slug":"chapter09-sec01","title":"9.1 Grundideen der Ensemble-Methoden","description":"","date":"","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec02","title":"9.2 Random Forests","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec03","title":"9.3 XGBoost","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"10. Support Vector Machines"},{"slug":"chapter10-sec01","title":"10.1 Maximiere den Rand, aber soft","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.pdf","thumbnailOptimized":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec02","title":"10.2 Training SVM mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec03","title":"10.3 Nichtlineare SVM","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.png","thumbnailOptimized":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"slug":"chapter11-sec01","title":"11.1 Kreuzvalidierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec02","title":"11.2 Gittersuche","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"12. Neuronale Netze"},{"slug":"chapter12-sec01","title":"12.1 Perzeptron = Grundbaustein neuronaler Netze","description":"","date":"","thumbnail":"/book_ml4ing/build/neuron_wikipedia-3eb6913313ac8930bf9e8f1c3c3de9b5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec02","title":"12.2 Mehrschichtiges Perzeptron","description":"","date":"","thumbnail":"/book_ml4ing/build/perceptron-b623483f7ef788fc968924c61cb9287b.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec03","title":"12.3 Neuronale Netze mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":3,"kind":"Notebook","sha256":"9fa20d9a38d8fe041278a0f7ab7719226db120d7874ef9affc516396454020a5","slug":"chapter06-sec03","location":"/chapter06/chapter06_sec03.md","dependencies":[],"frontmatter":{"title":"6.3 Entscheidungsbäume in der Praxis","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"jupytext":{"formats":"ipynb,md:myst","text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.15.2"}},"content_includes_title":false,"authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"github":"https://github.com/gramschs/book_ml4ing","numbering":{"title":{"offset":1}},"source_url":"https://github.com/gramschs/book_ml4ing/blob/main/chapter06/chapter06_sec03.md","edit_url":"https://github.com/gramschs/book_ml4ing/edit/main/chapter06/chapter06_sec03.md","exports":[{"format":"md","filename":"chapter06_sec03.md","url":"/book_ml4ing/build/chapter06_sec03-449ff3cbda3d9e0395993f9d8dfefd54.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Entscheidungsbäume bieten viele Vorteile, haben aber auch Nachteile, die wir in\ndiesem Kapitel diskutieren werden. Darüber hinaus lernen wir Methoden kennen,\num bei Entscheidungsbäumen diese Nachteile zu reduzieren.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"X2xURGjWkI"}],"key":"TzBb1HK4us"},{"type":"heading","depth":2,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Lernziele","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"sU2YnwlBOy"}],"identifier":"lernziele","label":"Lernziele","html_id":"lernziele","implicit":true,"key":"BXsCyaQbeE"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Lernziele","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"ce7QMAtnbV"}],"key":"sG4VstuwG8"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":25,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie können in eigenen Worten erklären, was ","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"gHEk7lyvtH"},{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Overfitting","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"lF2GYyo5Dq"}],"key":"H8duvDxAHR"},{"type":"text","value":" (deutsch:\n","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"FUczgokWCu"},{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Überanpassung","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"AFL8iNyziv"}],"key":"SNoaSfhnhd"},{"type":"text","value":") ist.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"EyqP6pFZkz"}],"key":"CxxFRPzES5"}],"key":"ZCvN2UkziS"},{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie wissen, was ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"bPMpPvgslj"},{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Underfitting","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"b9y8Zhj3nC"}],"key":"s8otdmKA9b"},{"type":"text","value":" bedeutet.","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"FuwLWVAwSW"}],"key":"F6CNvg3GfR"}],"key":"tHbnbac3RI"},{"type":"listItem","spread":true,"position":{"start":{"line":28,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie wissen, dass Entscheidungsbäume eine Tendenz zu Overfitting haben und\nMaßnahmen zur Reduzierung von Overfitting ergriffen werden müssen.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"OTFpv0NtGf"}],"key":"rSrfSm3DI2"}],"key":"bc4BcPW7mw"},{"type":"listItem","spread":true,"position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie wissen, was ","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"JA0K07A55C"},{"type":"strong","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Hyperparameter","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"WKJGsol2BF"}],"key":"uEfEcQJb2b"},{"type":"text","value":" sind.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"MtgIUAG5BU"}],"key":"n8xmqU9IYD"}],"key":"p4dPALqm4a"},{"type":"listItem","spread":true,"position":{"start":{"line":31,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie kennen Hyperparameter der Entscheidungsbäume wie beispielsweise","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"ZNlIgxfJ5j"}],"key":"DkzQgobXRd"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":32,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"maximale Baumtiefe,","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"dBMKYOMhoP"}],"key":"UKtuTXVk3n"}],"key":"ffS40dE1r2"},{"type":"listItem","spread":true,"position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"minimale Anzahl an Datenpunkten in Knoten oder","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"Hwx5XnJcNB"}],"key":"YdRJAqNafb"}],"key":"vBUV7dlbpL"},{"type":"listItem","spread":true,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"minimale Anzahl an Datenpunkten in Blättern.","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"RIMFu96IdZ"}],"key":"ZiTBZ94Zwb"}],"key":"OXo69aUdFf"}],"key":"XaVVeVVcts"}],"key":"jHJBlodaan"},{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Sie können die Hyperparameter zum ","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"osniNT25a8"},{"type":"strong","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Prä-Pruning","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"qphtwaRcqZ"}],"key":"nIksjKZ3tH"},{"type":"text","value":" (deutsch: vorab\nZurechtschneiden) geeignet wählen.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"LbYrmHpbJE"}],"key":"na7EWhOSJR"}],"key":"GYXD6BSWD8"}],"key":"Yc4VGrTHEm"}],"class":"attention","key":"LQ2dL9U6P8"},{"type":"heading","depth":2,"position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Die Tendenz von Entscheidungsbäumen zum Overfitting","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"qwOlhBlXNw"}],"identifier":"die-tendenz-von-entscheidungsb-umen-zum-overfitting","label":"Die Tendenz von Entscheidungsbäumen zum Overfitting","html_id":"die-tendenz-von-entscheidungsb-umen-zum-overfitting","implicit":true,"key":"VfszcPtWf9"},{"type":"paragraph","position":{"start":{"line":41,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Entscheidungsbaummodelle bieten zahlreiche Vorteile. Ein wesentlicher Vorzug ist\ndie Möglichkeit, den trainierten Entscheidungsbaum zu visualisieren, wodurch es\nleicht nachvollziehbar wird, welche Merkmale einen signifikanten Einfluss haben.\nEin weiterer Vorteil ist ihre Effizienz bei heterogenen Daten; sowohl numerische\nals auch kategoriale Eigenschaften können problemlos verarbeitet werden.\nEntscheidungsbäume sind selbst bei unterschiedlichen Datenskalen robust und\nerfordern nur wenig Vorverarbeitung.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"hDXNyuOTzg"}],"key":"E3Fh4nqPbP"},{"type":"paragraph","position":{"start":{"line":49,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"Trotz dieser Stärken besitzen Entscheidungsbäume eine Neigung zum\n","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"D2Ba9ryyPP"},{"type":"strong","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Overfitting","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"MXeOp8aTZY"}],"key":"F6wFvy3YgS"},{"type":"text","value":". Overfitting, auch als Überanpassung bekannt, beschreibt ein\nProblem im maschinellen Lernen, bei dem ein Modell die Trainingsdaten zu genau\nlernt. Das klingt zunächst gut, aber das Modell kann dadurch seine Fähigkeit\nverlieren, Vorhersagen für neue, unbekannte Daten zu treffen. Im Gegensatz dazu\nsteht das ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"KuCE0cO60u"},{"type":"strong","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Underfitting","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"WamtGmCWqE"}],"key":"qWT1KKhEoh"},{"type":"text","value":", das eine zu geringe Anpassung an die Daten bedeutet\nund ebenfalls unerwünscht ist.","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"U0PA4S13bP"}],"key":"PJJV5TN7aj"},{"type":"paragraph","position":{"start":{"line":57,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"Um uns das Problem des Overfittings zu veranschaulichen, betrachten wir erneut\ndas Autohaus-Beispiel, aber diesmal mit mehr Autos. Wir lassen die Autos diesmal\nmit einer in Scikit-Learn eingebauten Funktion zur Generierung von künstlichen\nDaten erzeugen, der sogenannten ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"AsdYnDEdlv"},{"type":"inlineCode","value":"make_moons","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"DvdptiS9Hh"},{"type":"text","value":"-Funktion (siehe ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"IKE4b1Cl8i"},{"type":"link","url":"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"Dokumentation\nScikit-Learn →\nmake_moons","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"Z1qB3M1Dvo"}],"urlSource":"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html","key":"WFuC8gc85M"},{"type":"text","value":")\naus dem Module ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"xDnt2ReyMx"},{"type":"inlineCode","value":"sklearn.datasets","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"WYjN5XHkR8"},{"type":"text","value":".","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"dwWtHgHWrF"}],"key":"hyoTfcnE9q"}],"key":"GwJPaLssZZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from sklearn.datasets import make_moons \n\nX_array, y_array = make_moons(noise = 0.5, n_samples=50, random_state=3)","key":"JzvugaCgqh"},{"type":"outputs","id":"lhnekaPC5oYRZw73l9aDM","children":[],"key":"VgIm8Sy4E4"}],"key":"NSsm2kqiPL"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":71,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"Damit die künstlichen Daten besser zu dem Autohaus-Beispiel passen,\ntransformieren wir sie und nutzen die Pandas-Datenstrukturen, um sie effizient\nzu verwalten.","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"LJEL8738aW"}],"key":"o83fiB9SGG"}],"key":"tACTjBT47s"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport pandas as pd\n\n# Transformation der Merkmalswerte in einen positiven Bereich und \n# Umwandlung in eine Integer-Matrix\nX_array = X_array + 1.2 * np.abs(np.min(X_array))\nX_array[:,0] = np.ceil(X_array[:,0] * 30000)\nX_array[:,1] = np.ceil(X_array[:,1] * 10000)\nX = pd.DataFrame(X_array, columns=['Kilometerstand [km]', 'Preis [EUR]'], dtype=(int, int))\n\n# Zuweisung von True/False basierend auf den Kategorien 1 bzw. 0\ny_array = (y_array - 1.0) * (-1)\ny = pd.Series(y_array, name='verkauft', dtype='bool')","key":"pPVSpe0ONZ"},{"type":"outputs","id":"m9d3-uKrp9uOegKS3L_xL","children":[],"key":"H3UdeFFLxS"}],"key":"l5Hqk1kiNE"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"text","value":"Nach der Datenvorbereitung visualisieren wir diese:","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"key":"v3m4IFoMJ6"}],"key":"Teo0ebcMUq"}],"key":"r9VExiSR5H"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import plotly.express as px\n\nfig = px.scatter(x = X['Kilometerstand [km]'], y = X['Preis [EUR]'], color=y,\n    title='Künstliche Daten Autohaus',\n    labels={'x': 'Kilometerstand [km]', 'y': 'Preis [EUR]', 'color': 'verkauft'})\nfig.show()","key":"rx2KZH6BUQ"},{"type":"outputs","id":"jQErFiwTwg_X4QHWJiTz1","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content":"{\"data\":[{\"hovertemplate\":\"verkauft=True\u003cbr\u003eKilometerstand [km]=%{x}\u003cbr\u003ePreis [EUR]=%{y}\u003cextra\u003e\u003c/extra\u003e\",\"legendgroup\":\"True\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"True\",\"orientation\":\"v\",\"showlegend\":true,\"x\":{\"dtype\":\"i4\",\"bdata\":\"8RUBAI4XAQDnuQAAdGgBABkEAQBOWQAAkwgBAGiLAAD9jQAAf4wAAH0lAQDU+QAAjhsBAP9GAQALNQAAIiEBADF0AACQUgAAWPkAAKxaAABqiAAAfS8BAEp7AQDOZAEAgb8AAA==\"},\"xaxis\":\"x\",\"y\":{\"dtype\":\"i4\",\"bdata\":\"62AAAOyBAAC2ZgAA1VkAABo3AAAlTgAACmkAALNaAADlbAAAGoAAAKw1AACgawAAcFMAAPwKAAD4OgAAVWMAABdVAAC8WQAAHG4AAH5PAAAeUwAAkTEAAEVuAABoRwAASkEAAA==\"},\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"verkauft=False\u003cbr\u003eKilometerstand [km]=%{x}\u003cbr\u003ePreis [EUR]=%{y}\u003cextra\u003e\u003c/extra\u003e\",\"legendgroup\":\"False\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"False\",\"orientation\":\"v\",\"showlegend\":true,\"x\":{\"dtype\":\"i4\",\"bdata\":\"6X0BAEnOAQA5GQEA37IAALuQAQDFrwEAJV8BAOs/AQDLxAAAsBwBAKSxAQDEAwEABe0AAAS6AQDRlAEA0PQAAK4gAQArCAEAl+4AANDUAACobAEAtpEBAIN2AQCAswEA874BAA==\"},\"xaxis\":\"x\",\"y\":{\"dtype\":\"i2\",\"bdata\":\"xwtKNf9AVV1RdPMVgyXHR1xNo02JK/BOX0fOSq1NADskLfUwpjxlcbckzyVLbvpDyVM=\"},\"yaxis\":\"y\",\"type\":\"scatter\"}],\"layout\":{\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]],\"sequentialminus\":[[0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0,1],\"title\":{\"text\":\"Kilometerstand [km]\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0,1],\"title\":{\"text\":\"Preis [EUR]\"}},\"legend\":{\"title\":{\"text\":\"verkauft\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Künstliche Daten Autohaus\"}},\"config\":{\"plotlyServerURL\":\"https://plot.ly\"}}","content_type":"application/vnd.plotly.v1+json"}}},"key":"nqKluM1pz4"}],"key":"Q3GY6mz6ov"}],"key":"QhvPzSIVe1"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":102,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Das Training des Entscheidungsbaumes und dessen Visualisierung erledigt der\nfolgende Code.","position":{"start":{"line":102,"column":1},"end":{"line":102,"column":1}},"key":"lu2Tg9RCAN"}],"key":"RINXp4tzSb"}],"key":"E0HpsxwRP6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from sklearn.tree import DecisionTreeClassifier, plot_tree\n\nmodell = DecisionTreeClassifier(random_state=0)\nmodell.fit(X,y)\n\nplot_tree(modell,\n    feature_names=['Kilometerstand [km]', 'Preis [EUR]'],\n    class_names=['nicht verkauft', 'verkauft']);","key":"jwrDnlRnT7"},{"type":"outputs","id":"umrwpvZi0Lm0KvXTmUvlp","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"f04143ecb736809ebdae7e09fc4c8f79","path":"/book_ml4ing/build/f04143ecb736809ebdae7e09fc4c8f79.png"}}},"key":"kHCVV8Nppa"}],"key":"Pg4TAehWJw"}],"key":"W3nrzWOAiB"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":116,"column":1},"end":{"line":119,"column":1}},"children":[{"type":"text","value":"Die Visualisierung offenbart zahlreiche Verzweigungen und eine schwer lesbare\nBeschriftung. Die Entscheidungsgrenzen, die im Folgenden mit\n","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"uBKXVDg8dg"},{"type":"inlineCode","value":"DecisionBoundaryDisplay","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"g5YwnMIp0Y"},{"type":"text","value":" visualisiert werden, zeigen eine zu starke Anpassung\nan die Trainingsdaten.","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"VuvfXK8LrV"}],"key":"TTBtygRdMW"}],"key":"du7kLamgHi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.inspection import DecisionBoundaryDisplay\n\nfig = DecisionBoundaryDisplay.from_estimator(modell, X, cmap=ListedColormap(['#EF553B33', '#636EFA33']), grid_resolution=1000)\nfig.ax_.scatter(X['Kilometerstand [km]'], X['Preis [EUR]'], c=y, cmap=ListedColormap(['#EF553B', '#636EFA']))\nfig.ax_.set_title('Entscheidungsgrenzen');","key":"JfGwyXUAG5"},{"type":"outputs","id":"PaGoHNP_gIb3HLUAVkcrh","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"5357933f05d4c7f64eb2daeebe329dbc","path":"/book_ml4ing/build/5357933f05d4c7f64eb2daeebe329dbc.png"}}},"key":"ljyOMiHThs"}],"key":"hu8gfj89wo"}],"key":"sfIFfaoLNX"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":132,"column":1},"end":{"line":141,"column":1}},"children":[{"type":"text","value":"Es ist fraglich, ob dieser Entscheidungsbaum nicht zu genau an die\nTrainingsdaten angepasst wurde. Der dünne blaue vertikale Streifen bei ungefähr\n97000 km ist wahrscheinlich keine sinnvolle Entscheidung, sondern eher einem\nAusreißer geschuldet (dem Auto mit einem Kilometerstand von 97098 km und einem\nPreis von 28229 EUR). Der Entscheidungsbaum hat sich zu stark an die Daten\nangepasst. Es ist wahrscheinlich, dass dieser Entscheidungsbaum für Autos mit\neinem Kilometerstand von ungefähr 97000 km falsche Prognosen treffen wird. Wenn\nwir mit den gleichen Daten erneut einen Entscheidungsbaum trainieren lassen und\nden Zufallszahlengenerator mit dem Zustand ","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"u0GYIhhs8R"},{"type":"inlineCode","value":"random_state=1","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"OKXEuCwzoE"},{"type":"text","value":" initialisieren,\nerhalten wir ein völlig anderes Ergebnis.","position":{"start":{"line":132,"column":1},"end":{"line":132,"column":1}},"key":"TKmF9GqBxZ"}],"key":"NfOVtiuLXU"}],"key":"ivlkksDv3T"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"modell_alternative = DecisionTreeClassifier(random_state=1)\nmodell_alternative.fit(X,y)\n\nfig = DecisionBoundaryDisplay.from_estimator(modell_alternative, X, cmap=ListedColormap(['#EF553B33', '#636EFA33']), grid_resolution=1000)\nfig.ax_.scatter(X['Kilometerstand [km]'], X['Preis [EUR]'], c=y, cmap=ListedColormap(['#EF553B', '#636EFA']))\nfig.ax_.set_title('Entscheidungsgrenzen des alternativen Modells');","key":"uZ8gXXBTfr"},{"type":"outputs","id":"YsY2cFuM-B6O8V0OzJzLp","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"95b161ea226c5b2ce6ac47becd21bce9","path":"/book_ml4ing/build/95b161ea226c5b2ce6ac47becd21bce9.png"}}},"key":"Ct0AUyTEGO"}],"key":"BUUtiz3l8f"}],"key":"FS4LMr92AK"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":152,"column":1},"end":{"line":157,"column":1}},"children":[{"type":"text","value":"Eine Möglichkeit, das Overfitting (Überanpassung) an die Daten zu bekämpfen, ist\ndas Zurechtschneiden (Pruning) der Entscheidungsbäume. Eine andere ist, aus\nmehreren Entscheidungbäumen einen »durchschnittlichen« Entscheidungsbaum zu\nbilden. Dieses Verfahren heißt Zufallswald (Random Forest) und wird ausführlich\nin einem eigenen Kapitel behandelt werden. In diesem Kapitel betrachten wir nur\ndas Zurechtschneiden der Entscheidungsbäume.","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"Ev7OahgA8C"}],"key":"I8HpYMJ15j"},{"type":"heading","depth":2,"position":{"start":{"line":159,"column":1},"end":{"line":159,"column":1}},"children":[{"type":"text","value":"Zurechtschneiden von Entscheidungsbäumen","position":{"start":{"line":159,"column":1},"end":{"line":159,"column":1}},"key":"mbeZKxvFje"}],"identifier":"zurechtschneiden-von-entscheidungsb-umen","label":"Zurechtschneiden von Entscheidungsbäumen","html_id":"zurechtschneiden-von-entscheidungsb-umen","implicit":true,"key":"UFdPGxRL4T"},{"type":"paragraph","position":{"start":{"line":161,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"Eine effektive Strategie zur Bekämpfung des Overfittings bei Entscheidungsbäumen\nist das sogenannte ","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"iSNHdE4s6l"},{"type":"strong","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"children":[{"type":"text","value":"Pruning","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"p2hT6Sg8aD"}],"key":"gBVKqRTTZ6"},{"type":"text","value":", also das Beschneiden des Baumes. Pruning hilft,\ndie Komplexität des Modells zu reduzieren, indem weniger relevante\nEntscheidungszweige nach bestimmten Kriterien entfernt werden. Im Kontext\nunseres Autohaus-Beispiels würde dies bedeuten, dass Entscheidungszweige, die\nbeispielsweise aufgrund von Ausreißern entstanden sind, abgeschnitten werden.\nDies könnte beispielsweise den zuvor erwähnten dünnen blauen Streifen bei einem\nKilometerstand von ungefähr 97000 km betreffen, der wahrscheinlich durch einen\nAusreißer entstanden ist. Durch das Entfernen solcher spezifischen Anpassungen\nkann der Entscheidungsbaum besser verallgemeinern und wird robuster gegenüber\nneuen, unbekannten Daten. Das Ergebnis ist ein Modell, das eine bessere Balance\nzwischen Anpassung an die Trainingsdaten und Generalisierungsfähigkeit aufweist.","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"iUwyJ9BTGj"}],"key":"AKbqIDLylC"},{"type":"paragraph","position":{"start":{"line":174,"column":1},"end":{"line":177,"column":1}},"children":[{"type":"text","value":"Für Entscheidungsbäume gibt es prinzipiell zwei Methoden des Prunings:\n","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"ujsDmsqSGz"},{"type":"strong","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"children":[{"type":"text","value":"Prä-Pruning","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"A67yN27x7V"}],"key":"phwy9TzzEe"},{"type":"text","value":" und ","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"G6p2ODaeT1"},{"type":"strong","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"children":[{"type":"text","value":"Post-Pruning","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"Eo5KVqRUf2"}],"key":"zwxNlhhpR1"},{"type":"text","value":". Das Prä-Pruning findet ","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"HlirehepRq"},{"type":"emphasis","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"children":[{"type":"text","value":"vor","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"KMljAQdsIY"}],"key":"gC2bwuVepx"},{"type":"text","value":" dem Training\ndes Entscheidungsbaumes statt, das Post-Pruning ","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"uTTGj7YBM0"},{"type":"emphasis","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"children":[{"type":"text","value":"nach","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"bXcyFjPXBt"}],"key":"yCl8CVyKPr"},{"type":"text","value":" dem Training. Die beiden\nwichtigsten Prä-Pruning-Maßnahmen sind","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"wme8jw2QEa"}],"key":"Hvy9pvqX5F"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":179,"column":1},"end":{"line":182,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"die Begrenzung der maximalen Tiefe des Baumes und","position":{"start":{"line":179,"column":1},"end":{"line":179,"column":1}},"key":"bqg4KvdEvS"}],"key":"QIke8V59SS"}],"key":"sypaAV26s2"},{"type":"listItem","spread":true,"position":{"start":{"line":180,"column":1},"end":{"line":182,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"die Forderung nach einer Mindestanzahl von Datenpunkten (entweder pro Knoten\noder pro Blatt).","position":{"start":{"line":180,"column":1},"end":{"line":180,"column":1}},"key":"li3femE4is"}],"key":"OCPXYTZ7ST"}],"key":"YVUA7DpYW4"}],"key":"yBeF5FOp7I"},{"type":"paragraph","position":{"start":{"line":183,"column":1},"end":{"line":186,"column":1}},"children":[{"type":"text","value":"Beim Post-Pruning werden im Nachhinein Knoten mit wenig Informationen aus dem\nEntscheidungsbaum entfernt oder es werden Knoten zusammengelegt. Scikit-Learn\nhat nur Prä-Pruning implementiert, so dass wir hier nicht weiter auf\nPost-Pruning eingehen.","position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"key":"buzPuavPsT"}],"key":"Nc6OFfXW7o"},{"type":"heading","depth":3,"position":{"start":{"line":188,"column":1},"end":{"line":188,"column":1}},"children":[{"type":"text","value":"Prä-Pruning: Baumtiefe","position":{"start":{"line":188,"column":1},"end":{"line":188,"column":1}},"key":"UFvodB4Y70"}],"identifier":"pr-pruning-baumtiefe","label":"Prä-Pruning: Baumtiefe","html_id":"pr-pruning-baumtiefe","implicit":true,"key":"n4g8Kz7l5v"},{"type":"paragraph","position":{"start":{"line":190,"column":1},"end":{"line":196,"column":1}},"children":[{"type":"text","value":"Wir schauen uns zunächst an, wie bei Scikit-Learn-Entscheidungsbäumen die\nmaximale Tiefe festgelegt wird. Bisher haben wir das Modell ohne weitere\nParameter initialisiert (einzige Ausnahme: wir haben ggf. den\nZufallszahlengenerator aus didaktischen Gründen fixiert, damit die Ergebnisse\nvergleichbar sind). Nun verwenden wir bei der Initialisierung des\nDecisionTreeClassifiers das optionale Argument ","position":{"start":{"line":190,"column":1},"end":{"line":190,"column":1}},"key":"q7DqFqjSjF"},{"type":"inlineCode","value":"max_depth=","position":{"start":{"line":190,"column":1},"end":{"line":190,"column":1}},"key":"LfynpDwc8S"},{"type":"text","value":" und setzen es auf\n","position":{"start":{"line":190,"column":1},"end":{"line":190,"column":1}},"key":"jwqQkO0zXQ"},{"type":"inlineCode","value":"1","position":{"start":{"line":190,"column":1},"end":{"line":190,"column":1}},"key":"wevbUteb0i"},{"type":"text","value":".","position":{"start":{"line":190,"column":1},"end":{"line":190,"column":1}},"key":"ZaysJyb1t2"}],"key":"NO38eVPl1a"}],"key":"p81SVsTxFU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"modell_tiefe1 = DecisionTreeClassifier(random_state=0, max_depth=1)\nmodell_tiefe1.fit(X,y)\n\nplot_tree(modell_tiefe1,\n    feature_names=['Kilometerstand [km]', 'Preis [EUR]'],\n    class_names=['nicht verkauft', 'verkauft']);","key":"Pv6gSMxOdf"},{"type":"outputs","id":"_b0EHHkog1IIcvg_76Po0","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"cb8aba09652b28c8f6545fcb0ba207d5","path":"/book_ml4ing/build/cb8aba09652b28c8f6545fcb0ba207d5.png"}}},"key":"X97n0ZETA5"}],"key":"F4eYLMn01Q"}],"key":"EYh69MoGtv"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":207,"column":1},"end":{"line":213,"column":1}},"children":[{"type":"text","value":"Eine Tiefe von 1 bedeutet, dass nur noch eine einzige Entscheidungsfrage\ngestellt wird. Das reicht nicht mehr, um die Autos in reine Blätter zu\nsortieren. Im linken Blatt sind 13 nicht verkaufte Autos und 24 verkaufte Autos,\nweshalb diesem Blatt die Kategorie »verkauft« zugeordnet wird. Im rechten Blatt\nsind 12 nicht verkaufte Autos und ein verkauftes Auto, so dass dieses Blatt\ninsgesamt als »nicht verkauft« gilt. Die Visualisierung der Entscheidungsgrenzen\nzeigt, um welche Autos es sich handelt.","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"lpdUfkO18F"}],"key":"agyuqKY38b"}],"key":"FuChmTbv69"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig = DecisionBoundaryDisplay.from_estimator(modell_tiefe1, X, cmap=ListedColormap(['#EF553B33', '#636EFA33']), grid_resolution=1000)\nfig.ax_.scatter(X['Kilometerstand [km]'], X['Preis [EUR]'], c=y, cmap=ListedColormap(['#EF553B', '#636EFA']))\nfig.ax_.set_title('Entscheidungsgrenzen');","key":"omDNnDYHl9"},{"type":"outputs","id":"A4PbGDGyDL8GvyGWidw9v","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"f7a778082f9a47b45e4a1b80340c2c50","path":"/book_ml4ing/build/f7a778082f9a47b45e4a1b80340c2c50.png"}}},"key":"MYEaZyFaVX"}],"key":"LAVLQW2R4K"}],"key":"u64RfgZf7M"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":221,"column":1},"end":{"line":223,"column":1}},"children":[{"type":"text","value":"Insbesondere die Visualisierung der Entscheidungsgrenzen zeigt aber auch, dass\ndieser Entscheidungsbaum nicht besonders gut die Daten erklärt. Der Score ist\nmit","position":{"start":{"line":221,"column":1},"end":{"line":221,"column":1}},"key":"rN0ZTNlB3g"}],"key":"D4QAkDY058"}],"key":"vkNaGAGVM6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(f'Score des Entscheidungsbaumes mit Tiefe 1: {modell_tiefe1.score(X,y)}')","key":"UtmyqoMHUq"},{"type":"outputs","id":"LRlF5Vne9fdEI9r-kvTuV","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Score des Entscheidungsbaumes mit Tiefe 1: 0.72\n"},"key":"z9PhmFAxlb"}],"key":"vKaCkN2f84"}],"key":"FvTbrIF4so"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"children":[{"type":"text","value":"auch nicht so gut. Daher verwenden wir nun als maximale Tiefe des Entscheidungsbaumes einen Wert von 2.","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"QQtAtZI1vW"}],"key":"qdb61PJ9v1"}],"key":"ZN9AEnivmR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"modell_tiefe2 = DecisionTreeClassifier(random_state=0, max_depth=2)\nmodell_tiefe2.fit(X,y)\n\nplot_tree(modell_tiefe2,\n    feature_names=['Kilometerstand [km]', 'Preis [EUR]'],\n    class_names=['nicht verkauft', 'verkauft']);\n\nprint(f'Score des Entscheidungsbaumes mit Tiefe 2: {modell_tiefe2.score(X,y)}')","key":"Dxew37h9cN"},{"type":"outputs","id":"ZUpdywuUuVj52rdD-VTtP","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Score des Entscheidungsbaumes mit Tiefe 2: 0.78\n"},"key":"ZQkwUZFWZt"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"b3447c976699eee489d72a071f3a5660","path":"/book_ml4ing/build/b3447c976699eee489d72a071f3a5660.png"}}},"key":"Q5vp6Ua5rb"}],"key":"bHbVnLN8Gk"}],"key":"YUZ7cBIDZE"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":242,"column":1},"end":{"line":245,"column":1}},"children":[{"type":"text","value":"Mit einem Score von 0.78 ist der Entscheidungsbaum mit einer maximalen Tiefe von\n2 zwar besser als der Baum mit einer maximalen Tiefe von 1, aber deutlich\nentfernt von dem Score 1.0 bei einer Baumtiefe von 7. Die Entscheidungsgrenzen\nsehen folgendermaßen aus:","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"key":"hYZiCc8QbU"}],"key":"JOaNHvDCoq"}],"key":"dmp5CnvtrJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig = DecisionBoundaryDisplay.from_estimator(modell_tiefe2, X, cmap=ListedColormap(['#EF553B33', '#636EFA33']), grid_resolution=1000)\nfig.ax_.scatter(X['Kilometerstand [km]'], X['Preis [EUR]'], c=y, cmap=ListedColormap(['#EF553B', '#636EFA']))\nfig.ax_.set_title('Entscheidungsgrenzen');","key":"cpkHKzQ35p"},{"type":"outputs","id":"kv6gjt2T4qbyGmK0_CYt0","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"16d4867c980f97c0d539a8d28c00a66d","path":"/book_ml4ing/build/16d4867c980f97c0d539a8d28c00a66d.png"}}},"key":"KXyPRnENF1"}],"key":"XUnqIjTy19"}],"key":"fE2C8vRwrV"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":253,"column":1},"end":{"line":258,"column":1}},"children":[{"type":"text","value":"Was ist jetzt besser, eine maximale Tiefe von 1 oder 2? Oder doch 3 vielleicht?\nDie Einführung der maximalen Tiefe bietet den Vorteil, das Overfitting zu\nbekämpfen. Der Nachteil davon ist, dass wir jetzt einen neuen Parameter haben,\nder das Training und die Prognose des Modells bestimmt. Und für diesen Parameter\nmuss ein passender Wert eingestellt werden. Solche Parameter nennt man\n","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"key":"xDnWfsvc9l"},{"type":"strong","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"children":[{"type":"text","value":"Hyperparameter","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"key":"QKMjupZkxb"}],"key":"wEPsj7XQsx"},{"type":"text","value":".","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"key":"mWdMiI7Sxv"}],"key":"mkSw8E1a6H"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Was ist ... ein Hyperparameter?","position":{"start":{"line":260,"column":1},"end":{"line":260,"column":1}},"key":"dVGWdgnQ17"}],"key":"ua753Yzgy2"},{"type":"paragraph","position":{"start":{"line":262,"column":1},"end":{"line":265,"column":1}},"children":[{"type":"text","value":"Ein Hyperparameter ist ein Parameter, der vor dem Training eines Modells\nfestgelegt wird und nicht aus den Daten während des Trainings gelernt wird. Die\nHyperparameter steuern den gesamten Lernprozess und haben einen wesentlichen\nEinfluss auf die Leistung des Modells.","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"gmAt55Oorw"}],"key":"OVQ59t4EIU"}],"class":"note","key":"cqVYk7W4Tc"},{"type":"paragraph","position":{"start":{"line":268,"column":1},"end":{"line":274,"column":1}},"children":[{"type":"text","value":"Ein Score von 1.0 auf den Trainingsdaten deutet auf Overfitting hin, d.h. das\nModell hat die Daten auswendig gelernt. Ein sehr niedriger Score (z.B. 0.72)\ndeutet auf Underfitting hin, d.h. das Modell ist zu einfach. Das Ziel ist ein\nGleichgewicht: ein Score, der hoch genug ist, um die Daten gut zu beschreiben,\naber nicht 1.0, um Generalisierung zu ermöglichen. Werte zwischen 0.8 und 0.95\nsind oft ein guter Kompromiss, aber dies muss mit separaten Testdaten validiert\nwerden.","position":{"start":{"line":268,"column":1},"end":{"line":268,"column":1}},"key":"uv9lXI3DTO"}],"key":"rN2HZ3rFlR"},{"type":"paragraph","position":{"start":{"line":276,"column":1},"end":{"line":277,"column":1}},"children":[{"type":"text","value":"Kommen wir nun zu einem anderen Hyperparameter der Entscheidungsbäume, der\nMindestanzahl von Datenpunkten.","position":{"start":{"line":276,"column":1},"end":{"line":276,"column":1}},"key":"Fq7WpR0tsQ"}],"key":"wxZOn5fP3i"},{"type":"heading","depth":3,"position":{"start":{"line":279,"column":1},"end":{"line":279,"column":1}},"children":[{"type":"text","value":"Prä-Pruning: Mindestanzahl Datenpunkte","position":{"start":{"line":279,"column":1},"end":{"line":279,"column":1}},"key":"PYp5d5PtyI"}],"identifier":"pr-pruning-mindestanzahl-datenpunkte","label":"Prä-Pruning: Mindestanzahl Datenpunkte","html_id":"pr-pruning-mindestanzahl-datenpunkte","implicit":true,"key":"phuRSgZBT6"},{"type":"paragraph","position":{"start":{"line":281,"column":1},"end":{"line":288,"column":1}},"children":[{"type":"text","value":"Genau wie der Hyperparameter zur Begrenzung der Baumtiefe wird die Mindestanzahl\nder Datenpunkte vorab bei der Initialisierung des Entscheidungsbaumes\nfestgelegt. Scikit-Learn bietet wiederum zwei Möglichkeiten, über die minimale\nAnzahl von Datenpunkten den Entscheidungsbaum zurechtzuschneiden. Zum einen kann\nfür die ","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"key":"dzHSNRncpJ"},{"type":"emphasis","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"children":[{"type":"text","value":"Knoten","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"key":"cOnQfaxz8Y"}],"key":"p3RjKeem87"},{"type":"text","value":" eine minimal erforderliche Anzahl von Datenpunkten festgelegt\nwerden, ab der es erlaubt ist, durch Entscheidungsfragen weiter zu verzweigen.\nZum anderen kann eine minimale Anzahl an Datenpunkten für jedes ","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"key":"lsZunvNzjB"},{"type":"emphasis","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"children":[{"type":"text","value":"Blatt","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"key":"jQgOj2Vy1u"}],"key":"wKi2H6iY0v"},{"type":"text","value":"\nfestgelegt werden, das am Ende der Verzweigungen erreicht werden muss.","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"key":"V5jkuEI9JW"}],"key":"aWWtSY99Rz"},{"type":"paragraph","position":{"start":{"line":290,"column":1},"end":{"line":298,"column":1}},"children":[{"type":"text","value":"Wir probieren beide Möglichkeiten aus und vergleichen die Ergebnisse\nmiteinander. Die Option zur Einstellung der Mindestanzahl pro Knoten heißt\n","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"key":"lvGlCRuJMf"},{"type":"inlineCode","value":"min_samples_split","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"key":"jlEhAViFUo"},{"type":"text","value":" und die Option zur Einstellung des Mindestanzahl Datenpunkte\npro Blatt heißt ","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"key":"D8Qv2ejaX8"},{"type":"inlineCode","value":"min_samples_leaf","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"key":"qKmIqnvEh1"},{"type":"text","value":". Beiden optionalen Argumenten kann entweder\nein Integer übergeben werden oder ein Float. Wird ein Integer übergeben, so ist\ndamit die tatsächliche minimale Anzahl an Datenpunkten gemeint. Ein Float wird\nals Bruch interpretiert und meint die relative Anzahl der Datenpunkte. Der Bruch\nwird mit der Gesamtzahl der Datenpunkte multipliziert und dann wird auf die\nnächste ganze Zahl aufgerundet.","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"key":"uFw2Rg02ep"}],"key":"sk0NADCpN6"},{"type":"paragraph","position":{"start":{"line":300,"column":1},"end":{"line":302,"column":1}},"children":[{"type":"text","value":"Schauen wir uns beide Varianten an. Zunächst begrenzen wir die Knoten und\nfordern, dass sich in jedem Entscheidungsknoten mindestens sechs Datenpunkte\nbefinden müssen.","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"hynkFXvuuf"}],"key":"G9n98BSr5c"}],"key":"m9PoJ8Bdsj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"modell_knotenbegrenzung = DecisionTreeClassifier(random_state=0, min_samples_split=6)\nmodell_knotenbegrenzung.fit(X,y)\n\nplot_tree(modell_knotenbegrenzung,\n    feature_names=['Kilometerstand [km]', 'Preis [EUR]'],\n    class_names=['nicht verkauft', 'verkauft']);\n\nprint(f'Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Knoten: {modell_knotenbegrenzung.score(X,y)}')","key":"mIBXIklBGk"},{"type":"outputs","id":"AV97-Jw2_jkwX4K5irXZv","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Knoten: 0.92\n"},"key":"EUkAfJLc9w"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"60faffff720b19e19d64011f6321509d","path":"/book_ml4ing/build/60faffff720b19e19d64011f6321509d.png"}}},"key":"wohPoZYh8g"}],"key":"mehCq1G60P"}],"key":"ibKXTcl7sc"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":315,"column":1},"end":{"line":316,"column":1}},"children":[{"type":"text","value":"Der Score ist 0.92. Nun fordern wir, dass in jedem Blatt mindestens sechs\nDatenpunkte verbleiben müssen.","position":{"start":{"line":315,"column":1},"end":{"line":315,"column":1}},"key":"ekNWJ0dCJO"}],"key":"zukQtMSvVP"}],"key":"VYNwhoMo4E"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"modell_blattbegrenzung = DecisionTreeClassifier(random_state=0, min_samples_leaf=6)\nmodell_blattbegrenzung.fit(X,y)\n\nplot_tree(modell_blattbegrenzung,\n    feature_names=['Kilometerstand [km]', 'Preis [EUR]'],\n    class_names=['nicht verkauft', 'verkauft']);\n\nprint(f'Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Blatt: {modell_blattbegrenzung.score(X,y)}')","key":"uoeePgvPCX"},{"type":"outputs","id":"ChudZsqqg2hn-e368RZLI","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Score des Entscheidungsbaumes mit Prä-Pruning Mindestanzahl Datenpunkte pro Blatt: 0.82\n"},"key":"eQLr70OuiC"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"d12f1b09a02342fe04b539d5bcee6e6a","path":"/book_ml4ing/build/d12f1b09a02342fe04b539d5bcee6e6a.png"}}},"key":"veker1o5Bp"}],"key":"Dkx2OegP6P"}],"key":"gXR0sZ5zsD"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":329,"column":1},"end":{"line":334,"column":1}},"children":[{"type":"text","value":"In diesem Fall erhalten wir einen Entscheidungsbaum mit einem Score von 0.82.\nWas jetzt die bessere Wahl ist -- Begrenzung der Baumtiefe oder Festlegung einer\nMindestanzahl von Datenpunkten Knoten/Blatt -- und vor allem welchen Wert der\nHyperparameter haben soll, ist eine zentrale Herausforderung im maschinellen\nLernen. In späteren Kapiteln werden wir systematische Methoden wie Grid Search\nund Cross-Validation kennenlernen, um die besten Hyperparameter-Werte zu finden.","position":{"start":{"line":329,"column":1},"end":{"line":329,"column":1}},"key":"eHHSAwx5hJ"}],"key":"ZsokXqcQz2"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Mini-Übung","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"LdsGD9A1j8"}],"key":"VzCsBsp96w"},{"type":"paragraph","position":{"start":{"line":338,"column":1},"end":{"line":339,"column":1}},"children":[{"type":"text","value":"Welcher Entscheidungsbaum zeigt vermutlich die stärkste Tendenz zum Overfitting?\nStellen Sie eine Vermuting an und überprüfen Sie Ihre Vermutung durch Ausprobieren.","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"s93pZ2ufR6"}],"key":"C6fPqKF9Oe"},{"type":"paragraph","position":{"start":{"line":341,"column":1},"end":{"line":343,"column":1}},"children":[{"type":"text","value":"A) ","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"XuZECu6gru"},{"type":"inlineCode","value":"DecisionTreeClassifier(max_depth=2)","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"GeSKiD6ReD"},{"type":"break","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"RO3AB43naW"},{"type":"text","value":"B) ","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"yRC53tH9zM"},{"type":"inlineCode","value":"DecisionTreeClassifier(max_depth=10)","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"EfyzT3UfHT"},{"type":"break","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"Vddq9KV8vc"},{"type":"text","value":"C) ","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"nYzNSUIdKh"},{"type":"inlineCode","value":"DecisionTreeClassifier(min_samples_leaf=20)","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"yZeWvQOUTB"}],"key":"wr62sV3o8M"}],"class":"tip","key":"dnC08wMbhD"}],"key":"Jkw12sgRTu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hier Ihr Code","key":"XQbYUDIuH1"},{"type":"outputs","id":"6-85nGqX1CSzBwc1rn6Hi","children":[],"key":"oqagdciteU"}],"key":"wXOUjdCcoF"},{"type":"block","children":[{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Lösung","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"HoxfOJQpqy"}],"key":"BfUF9RjvYR"},{"type":"paragraph","position":{"start":{"line":353,"column":1},"end":{"line":353,"column":1}},"children":[{"type":"text","value":"Antwort B, denn eine große maximale Tiefe erlaubt sehr komplexe Bäume.","position":{"start":{"line":353,"column":1},"end":{"line":353,"column":1}},"key":"iocAe31uvq"}],"key":"iFiZXIUER6"},{"type":"paragraph","position":{"start":{"line":355,"column":1},"end":{"line":355,"column":1}},"children":[{"type":"text","value":"Überprüfung durch Code:","position":{"start":{"line":355,"column":1},"end":{"line":355,"column":1}},"key":"wnqttvJizc"}],"key":"e1gBqxTE6T"},{"type":"code","lang":"python","value":"# Die drei Modelle trainieren und Scores vergleichen\nmodell_a = DecisionTreeClassifier(max_depth=2, random_state=0)\nmodell_a.fit(X, y)\nprint(f'Score A (max_depth=2): {modell_a.score(X, y):.3f}')\n\nmodell_b = DecisionTreeClassifier(max_depth=10, random_state=0)\nmodell_b.fit(X, y)\nprint(f'Score B (max_depth=10): {modell_b.score(X, y):.3f}')\n\nmodell_c = DecisionTreeClassifier(min_samples_leaf=20, random_state=0)\nmodell_c.fit(X, y)\nprint(f'Score C (min_samples_leaf=20): {modell_c.score(X, y):.3f}')\n\n# Modell B hat vermutlich den höchsten Score (nahe 1.0) → Overfitting!","position":{"start":{"line":356,"column":1},"end":{"line":371,"column":1}},"key":"Cj7jHDwuY6"}],"class":"tip dropdown, dropdown","key":"dtJPA5dNy9"},{"type":"details","children":[{"type":"summary","children":[{"type":"text","value":"Video “How to Implement Decision Trees in Python / Scikit-Learn” von Misra Turp","position":{"start":{"line":374,"column":1},"end":{"line":374,"column":1}},"key":"q7B0KI4rpF"}],"key":"HMx1lwMSST"},{"type":"iframe","src":"https://www.youtube.com/embed/wxS5P7yDHRA?si=rawkRWRmUi0ZZAub","width":"100%","title":"YouTube video player","key":"V97YkjCAm0"}],"key":"rqRWdCETke"},{"type":"heading","depth":2,"position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"children":[{"type":"text","value":"Zusammenfassung und Ausblick","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"key":"fzgDM57sob"}],"identifier":"zusammenfassung-und-ausblick","label":"Zusammenfassung und Ausblick","html_id":"zusammenfassung-und-ausblick","implicit":true,"key":"XumM1DbwMm"},{"type":"paragraph","position":{"start":{"line":382,"column":1},"end":{"line":390,"column":1}},"children":[{"type":"text","value":"In diesem Kapitel haben wir die Tendenz der Entscheidungsbäume zum Overfitting\ndiskutiert. Um dem Problem des Overfittings zu begegnen, bietet Scikit-Learn die\nMöglichkeit des Prä-Prunings. Durch die Begrenzung der maximalen Baumtiefe oder\ndie Festlegung einer Mindestanzahl von Datenpunkten in Knoten oder Blättern kann\nOverfitting reduziert werden. Diese zusätzlichen Parameter des\nEntscheidungsbaums werden Hyperparameter genannt und müssen angepasst werden.\nEine weitere Alternative, das Overfitting von Entscheidungsbäumen zu minimieren,\nbieten die Random Forests, die wir in einem späteren Kapitel kennenlernen\nwerden.","position":{"start":{"line":382,"column":1},"end":{"line":382,"column":1}},"key":"tDS9kkOBHN"}],"key":"LjVg8sg4bK"}],"key":"rcht8HGvjX"}],"key":"c5uJpGaFli"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"6.2 Entscheidungsbäume visualisieren und trainieren","url":"/chapter06-sec02","group":"6. Entscheidungsbäume (Decision Trees)"},"next":{"title":"Übung","url":"/chapter06-sec04","group":"6. Entscheidungsbäume (Decision Trees)"}}},"domain":"http://localhost:3004"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-NC-SA-4.0","url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","name":"Creative Commons Attribution Non Commercial Share Alike 4.0 International","CC":true}},"title":"Maschinelles Lernen für Ingenieurwissenschaften","authors":[{"id":"Simone Gramsch","name":"Simone Gramsch"}],"github":"https://github.com/gramschs/book_ml4ing","id":"8312bbb5-c2ab-495b-accc-a6773ec93d28","toc":[{"file":"intro.md"},{"children":[{"file":"chapter01/chapter01_sec01.md"},{"file":"chapter01/chapter01_sec02.md"},{"file":"chapter01/chapter01_sec03.md"}],"title":"1. Grundbegriffe des maschinellen Lernens"},{"children":[{"file":"chapter02/chapter02_sec01.md"},{"file":"chapter02/chapter02_sec02.md"},{"file":"chapter02/chapter02_sec03.md"},{"file":"chapter02/chapter02_sec04.md"}],"title":"2. Crashkurs Python"},{"children":[{"file":"chapter03/chapter03_sec01.md"},{"file":"chapter03/chapter03_sec02.md"},{"file":"chapter03/chapter03_sec03.md"},{"file":"chapter03/chapter03_sec04.md"}],"title":"3. Pandas und Plotly anstatt Excel"},{"children":[{"file":"chapter04/chapter04_sec01.md"},{"file":"chapter04/chapter04_sec02.md"},{"file":"chapter04/chapter04_sec03.md"},{"file":"chapter04/chapter04_sec04.md"}],"title":"4. Tabellarische Daten"},{"children":[{"file":"chapter05/chapter05_sec01.md"},{"file":"chapter05/chapter05_sec02.md"},{"file":"chapter05/chapter05_sec03.md"},{"file":"chapter05/chapter05_sec04.md"}],"title":"5. Kategoriale Daten"},{"children":[{"file":"chapter06/chapter06_sec01.md"},{"file":"chapter06/chapter06_sec02.md"},{"file":"chapter06/chapter06_sec03.md"},{"file":"chapter06/chapter06_sec04.md"}],"title":"6. Entscheidungsbäume (Decision Trees)"},{"children":[{"file":"chapter07/chapter07_sec01.md"},{"file":"chapter07/chapter07_sec02.md"},{"file":"chapter07/chapter07_sec03.md"},{"file":"chapter07/chapter07_sec04.md"}],"title":"7. Lineare Regression"},{"children":[{"file":"chapter08/chapter08_sec01.md"},{"file":"chapter08/chapter08_sec02.md"},{"file":"chapter08/chapter08_sec03.md"},{"file":"chapter08/chapter08_sec04.md"}],"title":"8. ML-Workflow Datenvorverarbeitung"},{"children":[{"file":"chapter09/chapter09_sec01.md"},{"file":"chapter09/chapter09_sec02.md"},{"file":"chapter09/chapter09_sec03.md"},{"file":"chapter09/chapter09_sec04.md"}],"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"children":[{"file":"chapter10/chapter10_sec01.md"},{"file":"chapter10/chapter10_sec02.md"},{"file":"chapter10/chapter10_sec03.md"},{"file":"chapter10/chapter10_sec04.md"}],"title":"10. Support Vector Machines"},{"children":[{"file":"chapter11/chapter11_sec01.md"},{"file":"chapter11/chapter11_sec02.md"},{"file":"chapter11/chapter11_sec04.md"}],"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"children":[{"file":"chapter12/chapter12_sec01.md"},{"file":"chapter12/chapter12_sec02.md"},{"file":"chapter12/chapter12_sec03.md"}],"title":"12. Neuronale Netze"}],"exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"1. Grundbegriffe des maschinellen Lernens"},{"slug":"chapter01-sec01","title":"1.1 Was ist maschinelles Lernen?","description":"","date":"","thumbnail":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.png","thumbnailOptimized":"/book_ml4ing/build/ml_as_baking-ab1ed6253c3e386a9b929f0bef5c5e7e.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec02","title":"1.2 Überwachtes, unüberwachtes und verstärkendes Lernen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter01-sec03","title":"1.3 Technische Voraussetzungen","description":"","date":"","thumbnail":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.png","thumbnailOptimized":"/book_ml4ing/build/fig_chap01_sec02_jup-85175f2f1403315cfa4937479bc91220.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"2. Crashkurs Python"},{"slug":"chapter02-sec01","title":"2.1 Datentypen, Variablen und print()","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec02","title":"2.2 Listen und for-Schleifen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec03","title":"2.3 Dictionaries, Funktionen und Methoden","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter02-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"3. Pandas und Plotly anstatt Excel"},{"slug":"chapter03-sec01","title":"3.1 Pandas Series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec02","title":"3.2 Statistik mit Pandas","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec03","title":"3.3 Boxplots mit Plotly","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter03-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"4. Tabellarische Daten"},{"slug":"chapter04-sec01","title":"4.1 Datenstruktur DataFrame","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec02","title":"4.2 Arbeiten mit Tabellendaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec03","title":"4.3 Scatterplots und Scattermatrix","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter04-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"5. Kategoriale Daten"},{"slug":"chapter05-sec01","title":"5.1 Was sind kategoriale Daten?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec02","title":"5.2 Barplots und Histogramme","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec03","title":"5.3 Daten filtern und gruppieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter05-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"6. Entscheidungsbäume (Decision Trees)"},{"slug":"chapter06-sec01","title":"6.1 Was ist ein Entscheidungsbaum?","description":"","date":"","thumbnail":"/book_ml4ing/build/combined_decisiontre-828d24d00dcf41e5ebd76c64a833686d.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec02","title":"6.2 Entscheidungsbäume visualisieren und trainieren","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec03","title":"6.3 Entscheidungsbäume in der Praxis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter06-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"7. Lineare Regression"},{"slug":"chapter07-sec01","title":"7.1 Einfache lineare Regression","description":"","date":"","thumbnail":"/book_ml4ing/build/Linear_regression-b0a448b4378e9c4ed49a7896796e35b1.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec02","title":"7.2 Multiple lineare Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec03","title":"7.3 Polynomiale Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter07-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"8. ML-Workflow Datenvorverarbeitung"},{"slug":"chapter08-sec01","title":"8.1 Fehlende Daten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec02","title":"8.2 Trainings- und Testdaten","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec03","title":"8.3 Kodierung und Skalierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter08-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"9. Ensemble-Methoden (Random Forests und XGBoost)"},{"slug":"chapter09-sec01","title":"9.1 Grundideen der Ensemble-Methoden","description":"","date":"","thumbnail":"/book_ml4ing/build/concept_voting-aafee3ce5cf0e957148ec9b4ebfdf754.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec02","title":"9.2 Random Forests","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec03","title":"9.3 XGBoost","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter09-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"10. Support Vector Machines"},{"slug":"chapter10-sec01","title":"10.1 Maximiere den Rand, aber soft","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.pdf","thumbnailOptimized":"/book_ml4ing/build/fig10_01_annotated-d3343b711e9bd56aa48e08e8c3b23aae.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec02","title":"10.2 Training SVM mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec03","title":"10.3 Nichtlineare SVM","description":"","date":"","thumbnail":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.png","thumbnailOptimized":"/book_ml4ing/build/fig10_06_with_plane-04fe9209681b95392859613b7d5d984f.webp","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter10-sec04","title":"Übung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"11. ML-Workflow Modellbewertung und Auswahl"},{"slug":"chapter11-sec01","title":"11.1 Kreuzvalidierung","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec02","title":"11.2 Gittersuche","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter11-sec04","title":"Übungen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"12. Neuronale Netze"},{"slug":"chapter12-sec01","title":"12.1 Perzeptron = Grundbaustein neuronaler Netze","description":"","date":"","thumbnail":"/book_ml4ing/build/neuron_wikipedia-3eb6913313ac8930bf9e8f1c3c3de9b5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec02","title":"12.2 Mehrschichtiges Perzeptron","description":"","date":"","thumbnail":"/book_ml4ing/build/perceptron-b623483f7ef788fc968924c61cb9287b.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"chapter12-sec03","title":"12.3 Neuronale Netze mit Scikit-Learn","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/book_ml4ing/build/manifest-86A905A4.js";
import * as route0 from "/book_ml4ing/build/root-CXYA7X5D.js";
import * as route1 from "/book_ml4ing/build/routes/$-JRBPULBO.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/book_ml4ing/build/entry.client-PCJPW7TK.js");</script></body></html>