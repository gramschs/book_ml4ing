
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Das Bias-Varianz-Dilemma &#8212; Maschinelles Lernen f√ºr Studierende der Ingenieurwissenschaften</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myadmonitions.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Perzeptron" href="../chapter08/chapter08_sec00.html" />
    <link rel="prev" title="Modellvalidierung" href="chapter07_sec02.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Maschinelles Lernen f√ºr Studierende der Ingenieurwissenschaften</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Willkommen zu ML4ING
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting started...
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter01/chapter01_sec00.html">
   Zu Beginn ‚Ä¶
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter01/chapter01_sec01.html">
     Was ist maschinelles Lernen?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter01/chapter01_sec02.html">
     Technische Voraussetzungen: Python, Anaconda und JupyterLab
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter02/chapter02_sec00.html">
   Crashkurs Python (Teil 1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter02/chapter02_sec01.html">
     Datentypen, Variablen und Vergleiche
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter02/chapter02_sec02.html">
     Bool, Vergleiche und Programmverzweigung
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter02/chapter02_sec03.html">
     Digitale Logik und Schleife mit Bedingung
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter03/chapter03_sec00.html">
   Crashkurs Python (Teil 2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter03/chapter03_sec01.html">
     Liste und Z√§hlschleife
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter03/chapter03_sec02.html">
     Funktionen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter03/chapter03_sec03.html">
     Objektorientierung
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datenexploration
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter04/chapter04_sec00.html">
   Pandas anstatt Excel
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter04/chapter04_sec01.html">
     Series und DataFrame
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter04/chapter04_sec02.html">
     Arbeiten mit Tabellendaten
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter04/chapter04_sec03.html">
     Statistik mit Pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter05/chapter05_sec00.html">
   Daten visualisieren mit Matplotlib
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter05/chapter05_sec01.html">
     Das Modul NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter05/chapter05_sec02.html">
     Linien-, Balken- und Streudiagramme
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter05/chapter05_sec03.html">
     Visualisierung von DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter05/chapter05_sec04.html">
     Optional: Histogramme
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ML-Verfahren
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter06/chapter06_sec00.html">
   Lineare und polynomiale Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter06/chapter06_sec01.html">
     Lineare Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter06/chapter06_sec02.html">
     Training eines linearen Regressionsmodells
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter06/chapter06_sec03.html">
     Multiple lineare Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="chapter07_sec00.html">
   ML-Workflow
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="chapter07_sec01.html">
     Datenvorverarbeitung
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="chapter07_sec02.html">
     Modellvalidierung
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Das Bias-Varianz-Dilemma
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter08/chapter08_sec00.html">
   Perzeptron
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter08/chapter08_sec01.html">
     Grundbaustein neuronaler Netze
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter08/chapter08_sec02.html">
     Die Perzeptron-Lernregel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter08/chapter08_sec03.html">
     Training eines Perzeptrons mit Scikit-Learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter09/chapter09_sec00.html">
   Logistische Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter09/chapter09_sec01.html">
     Logistische Regression ersetzt Perzeptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter09/chapter09_sec02.html">
     Logistische Regression lernt mit Maximum-Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter09/chapter09_sec03.html">
     Logistische Regression mit Scikit-Learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter10/chapter10_section00.html">
   Support Vector Machine
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter10/chapter10_section01.html">
     Maximiere den Rand, aber soft
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/chapter07/chapter07_sec03.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/gramschs/book_ml4ing"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/gramschs/book_ml4ing/main?urlpath=lab/tree/docs/chapter07/chapter07_sec03.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lernziele">
   Lernziele
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#was-ist-das-bias-varianz-dilemma">
   Was ist das Bias-Varianz-Dilemma?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mit-validierungskurven-modell-wahlen">
   Mit Validierungskurven Modell w√§hlen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zusammenfassung">
   Zusammenfassung
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Das Bias-Varianz-Dilemma</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lernziele">
   Lernziele
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#was-ist-das-bias-varianz-dilemma">
   Was ist das Bias-Varianz-Dilemma?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mit-validierungskurven-modell-wahlen">
   Mit Validierungskurven Modell w√§hlen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zusammenfassung">
   Zusammenfassung
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="das-bias-varianz-dilemma">
<h1>Das Bias-Varianz-Dilemma<a class="headerlink" href="#das-bias-varianz-dilemma" title="Permalink to this headline">¬∂</a></h1>
<p>Mit der Aufteilung der Daten in Test- und Trainingsdaten k√∂nnen wir untersuchen,
ob ein Modell prinzipiell die Trainingsdaten gut erkl√§rt. Wie gut es neue Daten
prognostizieren kann, d.h. wie gut es verallgemeinert, beurteilen wir mit den
Testdaten. Was ist aber, wenn wir mit dem gew√§hlten Modell nicht zufrieden sind
und mit anderen Modellen vergleichen wollen? Nicht nur die Modellauswahl selbst
ist schwierig. Jedes Modell hat selbst noch Finetuning-Optionen. Die Parameter,
die zu einem Modell geh√∂ren und nichts mit den Daten zu tun haben, werden
<strong>Hyperparameter</strong> genannt. Vielleicht reicht das gew√§hlte Modell ja doch, aber
die Hyperparameter m√ºssen noch optimiert werden. Wie gehen wir da vor?</p>
<p>Die Wahl des Modells ist eine schwierige Kunst und h√§ngt vor allem von der
Qualit√§t der vorliegenden Daten ab. Im Folgenden besch√§ftigen wir uns mit dem
sogenannten <strong>Bias-Varianz-Dilemma</strong>, das bei der Modellauswahl auftritt.</p>
<div class="section" id="lernziele">
<h2>Lernziele<a class="headerlink" href="#lernziele" title="Permalink to this headline">¬∂</a></h2>
<div class="hint admonition">
<p class="admonition-title">Lernziele</p>
<ul class="simple">
<li><p>Sie wissen, was ein <strong>Hyperparameter</strong> ist.</p></li>
<li><p>Sie k√∂nnen das <strong>Bias-Varianz-Dilemma</strong> erkl√§ren.</p></li>
<li><p>Sie wissen, was <strong>Overfitting</strong> und <strong>Underfitting</strong> bedeutet.</p></li>
<li><p>Sie k√∂nnen erkl√§ren, wie mit Hilfe von <strong>Validierungskurven</strong> ein geeignetes Modell ausgew√§hlt wird.</p></li>
</ul>
</div>
</div>
<div class="section" id="was-ist-das-bias-varianz-dilemma">
<h2>Was ist das Bias-Varianz-Dilemma?<a class="headerlink" href="#was-ist-das-bias-varianz-dilemma" title="Permalink to this headline">¬∂</a></h2>
<p>Im letzten Abschnitt hatten wir k√ºnstlich generierte Messdaten. Auswendiglernen
ist kein sinnvolles ML-Modell, probieren wir es mit linearer Regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># styling of plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;bmh&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TeX Gyre Heros&#39;</span><span class="p">,</span> <span class="s1">&#39;sans-serif&#39;</span><span class="p">]</span>

<span class="c1"># artificial data: f(x) = ‚àí2ùë•^2 + 8ùë• + 15 + error</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.4384</span><span class="p">,</span> <span class="mf">14.3252</span><span class="p">,</span> <span class="mf">19.2451</span><span class="p">,</span> <span class="mf">23.3703</span><span class="p">,</span> <span class="mf">18.2885</span><span class="p">,</span> <span class="mf">13.8978</span><span class="p">,</span> <span class="mf">3.7586</span><span class="p">])</span>

<span class="c1"># preprocessing and training linear regression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2-score Trainingsdaten: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

<span class="c1"># prediction</span>
<span class="n">X_prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">)</span>

<span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainingsdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">,</span> <span class="n">y_prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Modell&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Ursache&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Wirkung&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;K√ºnstlich generierte Messdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2-score Trainingsdaten: 0.01
</pre></div>
</div>
<img alt="../_images/chapter07_sec03_3_1.png" src="../_images/chapter07_sec03_3_1.png" />
</div>
</div>
<p>Schon die Visualisierung zeigt, dass lineare Regression bei diesen Daten keine
gute Idee ist. Der R¬≤-Score ist auch bei 0.</p>
<p>Au√üer der linearen Modellfunktion gibt es ja noch Polynome h√∂heren Grades, also
quadratische Funktion oder kubische Funktionen. Wenn Sie in der Dokumentation
von Scikit-Learn nun nach einer Funktion zur polynomialen Regression suchen,
werden Sie nicht f√ºndig werden. Tats√§chlich brauchen wir auch keine
eigenst√§ndige Funktion, sondern k√∂nnen uns mit einem Trick weiterhelfen.</p>
<p>Das lineare Regressionsmodell, das wir eben ausprobiert haben, lautet
mathematisch formuliert folgenderma√üen:</p>
<div class="math notranslate nohighlight">
\[y^{(i)} = \omega_0 + \omega_1 \cdot x^{(i)}\]</div>
<p>mit nur einem Input <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Wenn wir eine quadratische Funktion als Modellfunktion w√§hlen m√∂chten, erzeugen
wir einfach eine zweite Eigenschaft. Wir nennen die bisherigen x-Werte <span class="math notranslate nohighlight">\(x^{(i)}\)</span> jetzt <span class="math notranslate nohighlight">\(x_1^{(i)}\)</span> und f√ºgen als zweiten Input die neue Eigenschaft</p>
<div class="math notranslate nohighlight">
\[x_2^{(i)} = \left( x_1^{(i)} \right)^2\]</div>
<p>hinzu.</p>
<p>Dieser Trick wird auch bei anderen ML-Verfahren angewandt. Aus einem Input, aus
einer Eigenschaft werden jetzt eine neue Eigenschaften erzeugt. Aus einem
eindimensionalen Input wird ein zweidimensionaler Input. Mathematisch gesehen
haben wir die Input-Daten in einen h√∂herdimensionalen Bereich projiziert. Diese
Methode nennt man <strong>Kernel-Trick</strong>. Es ist auch m√∂glich, andere Funktionen zu
benutzen, um die Daten in einen h√∂herdimensionalen Raum zu projizieren, z.B.
radiale Gau√üsche Basisfunktionen. Das nennt man dann <strong>Kernel-Methoden</strong>.</p>
<p>In dieser Vorlesung bleiben wir aber bei den Polynomen als Basisfunktion.
Scikit-Learn stellt auch hier passende Methoden bereit, siehe <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">Dokumentation
Scikit-Learn ‚Üí
PolynomialFeature</a>.
Wir erzeugen das PolynomialFeature-Objekt mit der Option <code class="docutils literal notranslate"><span class="pre">degree=2</span></code>, um die
Quadrate hinzuzuf√ºgen. Dann transformieren wir die Input-Daten, indem wir die
<code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code>-Methode auf den Input anwenden.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Original X:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

<span class="c1"># lade die Polynom-Transformator </span>
<span class="n">polynom_transformator</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># transformiere X</span>
<span class="n">X_transformiert</span> <span class="o">=</span>  <span class="n">polynom_transformator</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;transformiertes X:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">X_transformiert</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original X:
 [[-1]
 [ 0]
 [ 1]
 [ 2]
 [ 3]
 [ 4]
 [ 5]]
transformiertes X:
 [[ 1. -1.  1.]
 [ 1.  0.  0.]
 [ 1.  1.  1.]
 [ 1.  2.  4.]
 [ 1.  3.  9.]
 [ 1.  4. 16.]
 [ 1.  5. 25.]]
</pre></div>
</div>
</div>
</div>
<p>Aus dem Spaltenvektor macht Scikit-Learn eine Matrix, bei der in der 1. Spalte nur Einsen stehen, die 2. Spalte enth√§lt die urspr√ºnglichen x-Werte und die 3. Spalte nun die Quadrate der urspr√ºnglichen x-Werte.</p>
<p>Damit k√∂nnen wir nun ein multiples lineares Regressionsmodell trainieren, also die
Koeffizienten suchen, so dass</p>
<div class="math notranslate nohighlight">
\[y^{(i)} = \omega_0 + \omega_1 \cdot x_1^{(i)} + \omega_2 \cdot x_2^{(i)}\]</div>
<p>mit m√∂glichst kleinen Fehlern gilt. Hier der komplette Code inklusive Visualisierung:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># project data</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># preprocessing and training linear regression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2-score Trainingsdaten: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

<span class="c1"># prediction</span>
<span class="n">X_prediction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">)</span>

<span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainingsdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Modell&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Ursache&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Wirkung&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;K√ºnstlich generierte Messdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2-score Trainingsdaten: 0.98
</pre></div>
</div>
<img alt="../_images/chapter07_sec03_7_1.png" src="../_images/chapter07_sec03_7_1.png" />
</div>
</div>
<p>W√§re eine kubische Modellfunktion noch besser? Wir f√ºgen noch eine dritte Eigenschaft hinzu, n√§mlich</p>
<div class="math notranslate nohighlight">
\[x_3^{(i)} = \left( x_1^{(i)} \right)^{3}.\]</div>
<p>Nat√ºrlich lassen wir auch hier Scikit-Learn f√ºr uns arbeiten und sezten die Option <code class="docutils literal notranslate"><span class="pre">degree</span></code> diesmal auf den Wert 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># project data</span>
<span class="n">X3</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># preprocessing and training linear regression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2-score Trainingsdaten: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

<span class="c1"># prediction</span>
<span class="n">X_prediction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">)</span>

<span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X3</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainingsdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Modell&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Ursache&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Wirkung&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;K√ºnstlich generierte Messdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2-score Trainingsdaten: 0.98
</pre></div>
</div>
<img alt="../_images/chapter07_sec03_9_1.png" src="../_images/chapter07_sec03_9_1.png" />
</div>
</div>
<p>K√∂nnte tats√§chlich besser sein. Und ist vielleicht ein Polynom 4. Grades noch
besser? Wir betrachten den Polynomgrad als Hyperparameter des Modells
‚ÄúRegressionspolynom‚Äù und gehen einfach mal alle Regressionspolynome bis Grad 7
durch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainingsdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Ursache&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Wirkung&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;K√ºnstlich generierte Messdaten&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">X_transformiert</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformiert</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2-score f√ºr Grad </span><span class="si">{0}</span><span class="s1">: </span><span class="si">{1:.12f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_transformiert</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

    <span class="c1"># prediction</span>
    <span class="n">X_prediction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">y_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">)</span>

    <span class="n">label_string</span> <span class="o">=</span> <span class="s1">&#39;Polynomgrad </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_string</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2-score f√ºr Grad 4: 0.984687480835
R2-score f√ºr Grad 5: 0.985549560915
R2-score f√ºr Grad 6: 1.000000000000
R2-score f√ºr Grad 7: 1.000000000000
</pre></div>
</div>
<img alt="../_images/chapter07_sec03_11_1.png" src="../_images/chapter07_sec03_11_1.png" />
</div>
</div>
<p>Ab Grad 6 kann keine Verbesserung des R¬≤-Scores mehr erzielt werden (warum?).
Auch scheinen die Polynom mit Grad 6 und Grad 7 in den Intervallen <span class="math notranslate nohighlight">\([-1,0]\)</span> und
<span class="math notranslate nohighlight">\([4,5]\)</span> etwas schwankend. Vielleicht m√ºssen wir doch noch h√∂her gehen. Schauen
wir uns Grad 8 an:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainingsdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Ursache&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Wirkung&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;K√ºnstlich generierte Messdaten&#39;</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">X_transformiert</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformiert</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2-score f√ºr Grad </span><span class="si">{0}</span><span class="s1">: </span><span class="si">{1:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_transformiert</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

<span class="c1"># prediction</span>
<span class="n">X_prediction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">)</span>

<span class="n">label_string</span> <span class="o">=</span> <span class="s1">&#39;Polynomgrad </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_string</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2-score f√ºr Grad 8: 1.000000
</pre></div>
</div>
<img alt="../_images/chapter07_sec03_13_1.png" src="../_images/chapter07_sec03_13_1.png" />
</div>
</div>
<p>Tats√§chlich werden dadurch die Schwankungen im Intervall <span class="math notranslate nohighlight">\([4,5]\)</span> noch verst√§rkt.
F√ºr Grad 9 wird es noch schlimmer, doch diesmal geht es in die andere Richtung.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainingsdaten&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Ursache&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Wirkung&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;K√ºnstlich generierte Messdaten&#39;</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">X_transformiert</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_transformiert</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2-score f√ºr Grad </span><span class="si">{0}</span><span class="s1">: </span><span class="si">{1:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_transformiert</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

<span class="c1"># prediction</span>
<span class="n">X_prediction</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">)</span>

<span class="n">label_string</span> <span class="o">=</span> <span class="s1">&#39;Polynomgrad </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_prediction</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_string</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2-score f√ºr Grad 9: 1.000000
</pre></div>
</div>
<img alt="../_images/chapter07_sec03_15_1.png" src="../_images/chapter07_sec03_15_1.png" />
</div>
</div>
<p>Die Regression mit Polynomen unerschiedlichen Grades verdeutlicht das sogenannte
<strong>Bias-Varianz-Dilemma</strong>. Das lineare Regressionsmodell hat zwei Parameter,
Steigung und y-Achsenabschnitt. Scheinbar sind das zuwenige Modellparameter, um
die Messdaten gut zu erkl√§ren und zu prognostizieren. Wir sind sozusagen mit dem
Vorurteil in unsere Modellierung gestartet, dass diese zwei Modellparameter
ausreichen werden, um die Daten gut zu erkl√§ren. In der ML-Community sagt man,
dass ein gro√üer <strong>Bias</strong> vorliegt. Das Modell ist zu wenig an die Daten
angepasst oder anders ausgedr√ºckt, es liegt eine Unteranpassung an die Daten
vor. Daf√ºr ist auch in der deutschsprachigen Literatur das englische Wort
<strong>Underfitting</strong> sehr gebr√§uchlich.</p>
<p>Bei dem Polynom mit Grad 9 haben wir 10 Modellparameter. Offensichtlich sind
das zuviele Parameter (es liegen ja nur sieben Messwerte vor). Die <strong>Varianz</strong>
ist zu gro√ü. Bereits bei der gefundenen Modellfunktion beobachten wir gro√üe
Schwankungen, insbesondere im Intervall [4,5]. Aber auch durch die Hinzunahme
eines einzigen Datenpunktes w√ºrden wir eine komplett andere Modellfunktion
erhalten. Das Modell reagiert sehr sensibel selbst auf kleine √Ñnderungen. Das
nennen wir √úberanpassung oder <strong>Overfitting</strong>.</p>
<p>Bei der Modellwahl stehen wir stets vor dem Dilemma, ein Modell mit zu wenigen
Parametern oder eines mit zu vielen Parametern zu w√§hlen.</p>
</div>
<div class="section" id="mit-validierungskurven-modell-wahlen">
<h2>Mit Validierungskurven Modell w√§hlen<a class="headerlink" href="#mit-validierungskurven-modell-wahlen" title="Permalink to this headline">¬∂</a></h2>
<p>Wenn wir in der gl√ºcklichen Situation sind, die Komplexit√§t des Modells w√§hlen
zu k√∂nnen, hilft uns eine Analyse der sogenannten <strong>Validierungskurven</strong> weiter, um
dem Bias-Varianz-Dilemma zu begegnen.</p>
<p>Dazu starten wir bei dem einfachsten Modell (hier in unserem Beispiel mit
Polynomgrad 1) und berechnen den R¬≤-Score sowohl f√ºr die Test- als auch die
Trainingsdaten. Wenn das Modell zu einfach ist, werden beide Scores schlecht
ausfallen. Da wir das Modell mit den Trainingsdaten trainieren, sollte jedoch
der R¬≤-Score f√ºr die Trainingsdaten besser sein als f√ºr die Testdaten.</p>
<p>Nehmen wir mehr Modellparameter hinzu, sollten sich sowohl der Score f√ºr die
Trainingsdaten als auch der Score f√ºr die Testdaten verbessern. Je mehr
Modellparameter hinzukommen, desto besser wird der Score f√ºr die Trainingsdaten,
bis es irgendwann einfach nicht mehr besser geht. Bei unseren k√ºnstlich
generierten Daten haben wir bereits ab Polynomgrad 6 keine Verbesserung mehr
gesehen. Der R¬≤-Score lag ab da bei 1.</p>
<p>Anders hingegen verh√§lt es sich bei dem Score der Testdaten. W√ºrden wir
beispielsweise unser Modell mit Polynomgrad 9 im Intervall <span class="math notranslate nohighlight">\([4,5]\)</span> auswerten, so
w√ºrden negative Werte prognostiziert werden. Da wir hier mit k√ºnstlich erzeugten
Daten arbeiten, wissen wir aber, dass diese mit einer quadratischen Funktion
erzeugt wurden und in diesem Bereich positiv sein m√ºssen. Wir h√§tten daher einen
gro√üen Fehler und einen schlechten R¬≤-Score f√ºr die Testdaten.</p>
<p>Wenn wir nun den Score (das gilt nicht nur f√ºr den R¬≤-Score, sondern auch f√ºr
andere Bewertungskriterien, die wir noch kennenlernen werden) abh√§ngig von der
Komplexit√§t eines Modells auftragen, nennen wir die entstehende Kurve
<strong>Validierungskurve</strong>. Prinzipiell sehen die Validierungskurve f√ºr die
Trainings- und Testdaten folgenderma√üen aus:</p>
<div class="figure align-default" id="fig-validierungskurven">
<a class="reference internal image-reference" href="../_images/validierungskurven_annotated.pdf"><img alt="../_images/validierungskurven_annotated.pdf" src="../_images/validierungskurven_annotated.pdf" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Schematische Darstellung von typischen Validierungskurven der Test- und Trainingsdaten zur Wahl der geeigneten Modellkomplexit√§t</span><a class="headerlink" href="#fig-validierungskurven" title="Permalink to this image">¬∂</a></p>
</div>
</div>
<div class="section" id="zusammenfassung">
<h2>Zusammenfassung<a class="headerlink" href="#zusammenfassung" title="Permalink to this headline">¬∂</a></h2>
<p>In diesem Abschnitt haben wir das Bias-Varianz-Dilemma kennengelernt, das vor
allem bei der Auswahl eines geeigneten Modells auftritt. Wir haben auch gesehen,
wie prinzipiell anhand von Validierungskurven bewertet werden kann, ob das
Modell Overfitting oder Underfitting zeigt.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "gramschs/book_ml4ing",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapter07"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="chapter07_sec02.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Modellvalidierung</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../chapter08/chapter08_sec00.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Perzeptron</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Simone Gramsch<br/>
    
      <div class="extra_footer">
        <div>
<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img class="license" alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This book is licensed under a <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons BY-NC-SA 4.0 License</a>.
</div>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>