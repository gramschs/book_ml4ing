Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/site-packages/nbclient/client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/asyncio/base_events.py", line 685, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/python312/lib/python3.12/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from sklearn.model_selection import cross_validate, KFold, train_test_split
from sklearn.tree import DecisionTreeClassifier

X = daten[['Merkmal 1', 'Merkmal 2']]
y = daten['Wirkung']

X_train, X_test, y_train, y_test = train_test_split(X,y)

kfold = KFold(n_splits=10)

mean_scores = {}
for max_tiefe in [3, 4, 5, 6]:
    modell = DecisionTreeClassifier(max_depth=max_tiefe)
    cv_results_modell = cross_validate(modell, X_train, y_train, cv=kfold)
    test_scores = cv_results_modell['test_score']
    mean_scores[max_tiefe] = mean(test_scores)
    print(f'Mittelwert Testscores: {mean(test_scores):.2f}, Standardabweichung: {std(test_scores):.2f}')

# Ermitteln der besten Baumtiefe (argmax o.Ã¤. wÃ¤re einfacher)
tiefe = 3
score = mean_scores[3]
for t in [4,5,6]:
    if mean_scores[t] > score:
        tiefe = t
        score = s
print(f'WÃ¤hle Baumtiefe {tiefe} mit dem besten Score {score:.2f}.')

# Finale Modellauswahl, Training und Bewertung
finales_modell = DecisionTreeClassifier(max_depth=tiefe)
finales_modell.fit(X_train, y_train)
finaler_score = finales_modell.score(X_test, y_test)
print(f'\nTestscore finales Modell: {finaler_score:.2f}')
------------------

----- stdout -----
Mittelwert Testscores: 0.70, Standardabweichung: 0.16
Mittelwert Testscores: 0.69, Standardabweichung: 0.16
Mittelwert Testscores: 0.72, Standardabweichung: 0.17
Mittelwert Testscores: 0.75, Standardabweichung: 0.12
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
Cell [0;32mIn[4], line 25[0m
[1;32m     23[0m     [38;5;28;01mif[39;00m mean_scores[t] [38;5;241m>[39m score:
[1;32m     24[0m         tiefe [38;5;241m=[39m t
[0;32m---> 25[0m         score [38;5;241m=[39m [43ms[49m
[1;32m     26[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m'[39m[38;5;124mWÃ¤hle Baumtiefe [39m[38;5;132;01m{[39;00mtiefe[38;5;132;01m}[39;00m[38;5;124m mit dem besten Score [39m[38;5;132;01m{[39;00mscore[38;5;132;01m:[39;00m[38;5;124m.2f[39m[38;5;132;01m}[39;00m[38;5;124m.[39m[38;5;124m'[39m)
[1;32m     28[0m [38;5;66;03m# Finale Modellauswahl, Training und Bewertung[39;00m

[0;31mNameError[0m: name 's' is not defined

