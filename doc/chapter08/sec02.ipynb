{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d13a3ea-d609-480f-ab7f-48403dccb25c",
   "metadata": {},
   "source": [
    "# Die Perzeptron-Lernregel\n",
    "\n",
    "In dem Abschnitt über das Perzeptron waren die Gewichte und der Schwellenwert vorgegeben. Aber wie kommt man dazu? In diesem Abschnitt beschäftigen wir uns damit, wie die Gewichte und der Schwellenwert gewählt werden müssen, damit das Perzeptron seine binäre Klassifikationsaufgabe erfüllen kann. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3805c898",
   "metadata": {},
   "source": [
    "## Hebbsche Regel\n",
    "\n",
    "Kaum zu glauben, aber die Idee zum Lernen der Gewichte eines Perzeptrons stammt nicht von Informatiker:innen, sondern von einem Psychologen namens [Donald Olding Hebb](https://de.wikipedia.org/wiki/Donald_O._Hebb). Im Englischen wird seine Arbeit meist durch das Zitat \n",
    "\n",
    ">\"what fires together, wires together\" \n",
    "\n",
    "kurz zusammengefasst. Hebb hat die Veränderung der synaptischen Übertragung von Neuronen untersucht und dabei festgestellt, dass je häufiger zwei Neuronen gemeinsam aktiv sind, desto eher werden die beiden aufeinander reagieren.\n",
    "\n",
    "Die Hebbsche Regel wird beim maschinellen Lernen dadurch umgesetzt, dass der Lernprozess mit zufälligen Gewichten startet und dann der prognostizierte Output mit dem echten Output verglichen wird. Je nachdem, ob der echte Output erreicht wurde oder nicht, werden nun die Gewichte und damit der Einfluss eines einzelnen Inputs verstärkt oder nicht. Dieser Prozess - Vergleichen und Abändern der Gewichte - wird solange wiederholt, bis die passenden Gewichte gefunden sind. \n",
    "\n",
    "Als Formel wird die Lernregel folgendermaßen formuliert:\n",
    "\n",
    "$$\\omega_i^{\\text{neu}} = \\omega_i^{\\text{alt}} + \\alpha \\cdot(y - \\hat{y}^{\\text{alt}}) \\cdot x_i.$$\n",
    "\n",
    "Dabei gehen wir davon aus, dass das Perzeptron $m$ Inputs mit der Bezeichnung $x_i$ und eine Bias-Einheit $x_0=1$ hat. Der Output ist hier mit $y$ gekennzeichnet. Wir berechnen nun, welchen Output $\\hat{y}^{\\text{alt}}$ das Perzeptron mit den aktuellen Gewichten $(\\omega_0^{\\text{alt}}, \\omega_1^{\\text{alt}}, \\ldots, \\omega_m^{\\text{alt}})$ prognostizieren würde. Dann vergleichen wir diesen Output mit dem echten Output $y$. Wenn jetzt der echte Output größer ist als der Wert, den unser Perzeptron prognostiziert, dann ist $y - \\hat{y}^{\\text{alt}} > 0$. Indem wir nun zu den alten Gewichten den Term $ \\alpha \\cdot(y - \\hat{y}^{\\text{alt}})$ addieren, verstärken wir die alten Gewichte. Ist jedoch der echte Output $y$ kleiner als der prognostizierte Output, dann ist $y - \\hat{y}^{\\text{alt}} < 0$. Daher werden nun die alten Gewichte durch die Addition des negativen Terms $\\alpha \\cdot(y - \\hat{y}^{\\text{alt}})$ abgeschwächt. Damit die Schritte zwischen der Abschwächung und der Verstärkung nicht zu groß werden, werden sie noch mit einem Vorfaktor $\\alpha$ multipliziert, der zwischen 0 und 1 liegt. Ein typischer Wert von $\\alpha$ ist $0.0001$. Dieser Vorfaktor $\\alpha$ wird **Lernrate** genannt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58817d76-2770-4dbf-947f-60e4f90c5185",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1863971d65633e53ca5b74972b86a14fab6d597ce2ac84dc984546545d2d3a9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
